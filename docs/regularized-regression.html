<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Hands-on Machine Learning with R</title>
  <meta name="description" content="A Machine Learning Algorithmic Deep Dive Using R.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Hands-on Machine Learning with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A Machine Learning Algorithmic Deep Dive Using R." />
  <meta name="github-repo" content="bradleyboehmke/hands-on-machine-learning-with-r" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Hands-on Machine Learning with R" />
  
  <meta name="twitter:description" content="A Machine Learning Algorithmic Deep Dive Using R." />
  



<meta name="date" content="2018-08-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regression-performance.html">
<link rel="next" href="random-forest.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Hands-on Machine Learning with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-should-read-this"><i class="fa fa-check"></i>Who should read this</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-r"><i class="fa fa-check"></i>Why R</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#conventions-used-in-this-book"><i class="fa fa-check"></i>Conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#additional-resources"><i class="fa fa-check"></i>Additional resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#feedback"><i class="fa fa-check"></i>Feedback</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-information"><i class="fa fa-check"></i>Software information</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#supervised-learning"><i class="fa fa-check"></i><b>1.1</b> Supervised Learning</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#regression-problems"><i class="fa fa-check"></i><b>1.1.1</b> Regression problems</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#classification-problems"><i class="fa fa-check"></i><b>1.1.2</b> Classification problems</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#algorithm-comparison-guide"><i class="fa fa-check"></i><b>1.1.3</b> Algorithm Comparison Guide</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#unsupervised-learning"><i class="fa fa-check"></i><b>1.2</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#algorithm-decision-guide"><i class="fa fa-check"></i><b>1.2.1</b> Algorithm Decision Guide</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#machine-learning-interpretability"><i class="fa fa-check"></i><b>1.3</b> Machine learning interpretability</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#data"><i class="fa fa-check"></i><b>1.4</b> The data sets</a></li>
</ul></li>
<li class="part"><span><b>I Supervised Learning</b></span></li>
<li class="chapter" data-level="2" data-path="regression-performance.html"><a href="regression-performance.html"><i class="fa fa-check"></i><b>2</b> Preparing for Supervised Machine Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_prereq"><i class="fa fa-check"></i><b>2.1</b> Prerequisites</a></li>
<li class="chapter" data-level="2.2" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_split"><i class="fa fa-check"></i><b>2.2</b> Data splitting</a><ul>
<li class="chapter" data-level="2.2.1" data-path="regression-performance.html"><a href="regression-performance.html#spending-our-data-wisely"><i class="fa fa-check"></i><b>2.2.1</b> Spending our data wisely</a></li>
<li class="chapter" data-level="2.2.2" data-path="regression-performance.html"><a href="regression-performance.html#simple-random-sampling"><i class="fa fa-check"></i><b>2.2.2</b> Simple random sampling</a></li>
<li class="chapter" data-level="2.2.3" data-path="regression-performance.html"><a href="regression-performance.html#stratified-sampling"><i class="fa fa-check"></i><b>2.2.3</b> Stratified sampling</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_feat"><i class="fa fa-check"></i><b>2.3</b> Feature engineering</a><ul>
<li class="chapter" data-level="2.3.1" data-path="regression-performance.html"><a href="regression-performance.html#response-transformation"><i class="fa fa-check"></i><b>2.3.1</b> Response Transformation</a></li>
<li class="chapter" data-level="2.3.2" data-path="regression-performance.html"><a href="regression-performance.html#predictor-transformation"><i class="fa fa-check"></i><b>2.3.2</b> Predictor Transformation</a></li>
<li class="chapter" data-level="2.3.3" data-path="regression-performance.html"><a href="regression-performance.html#one-hot-encoding"><i class="fa fa-check"></i><b>2.3.3</b> One-hot encoding</a></li>
<li class="chapter" data-level="2.3.4" data-path="regression-performance.html"><a href="regression-performance.html#standardizing"><i class="fa fa-check"></i><b>2.3.4</b> Standardizing</a></li>
<li class="chapter" data-level="2.3.5" data-path="regression-performance.html"><a href="regression-performance.html#alternative-feature-transformation"><i class="fa fa-check"></i><b>2.3.5</b> Alternative Feature Transformation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_model"><i class="fa fa-check"></i><b>2.4</b> Basic model formulation</a></li>
<li class="chapter" data-level="2.5" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_tune"><i class="fa fa-check"></i><b>2.5</b> Model tuning</a></li>
<li class="chapter" data-level="2.6" data-path="regression-performance.html"><a href="regression-performance.html#cv"><i class="fa fa-check"></i><b>2.6</b> Cross Validation for Generalization</a></li>
<li class="chapter" data-level="2.7" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_eval"><i class="fa fa-check"></i><b>2.7</b> Model evaluation</a><ul>
<li class="chapter" data-level="2.7.1" data-path="regression-performance.html"><a href="regression-performance.html#regression-models"><i class="fa fa-check"></i><b>2.7.1</b> Regression models</a></li>
<li class="chapter" data-level="2.7.2" data-path="regression-performance.html"><a href="regression-performance.html#classification-models"><i class="fa fa-check"></i><b>2.7.2</b> Classification models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regularized-regression.html"><a href="regularized-regression.html"><i class="fa fa-check"></i><b>3</b> Regularized Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-req"><i class="fa fa-check"></i><b>3.1</b> Prerequisites</a></li>
<li class="chapter" data-level="3.2" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-pros-cons"><i class="fa fa-check"></i><b>3.2</b> Advantages &amp; Disadvantages</a></li>
<li class="chapter" data-level="3.3" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-why"><i class="fa fa-check"></i><b>3.3</b> The Idea</a><ul>
<li class="chapter" data-level="3.3.1" data-path="regularized-regression.html"><a href="regularized-regression.html#multicollinearity"><i class="fa fa-check"></i><b>3.3.1</b> 1. Multicollinearity</a></li>
<li class="chapter" data-level="3.3.2" data-path="regularized-regression.html"><a href="regularized-regression.html#insufficient-solution"><i class="fa fa-check"></i><b>3.3.2</b> 2. Insufficient solution</a></li>
<li class="chapter" data-level="3.3.3" data-path="regularized-regression.html"><a href="regularized-regression.html#interpretability"><i class="fa fa-check"></i><b>3.3.3</b> 3. Interpretability</a></li>
<li class="chapter" data-level="3.3.4" data-path="regularized-regression.html"><a href="regularized-regression.html#regularized_regress"><i class="fa fa-check"></i><b>3.3.4</b> Regularized Models</a><ul>
<li class="chapter" data-level="3.3.4.1" data-path="regularized-regression.html"><a href="regularized-regression.html#ridge"><i class="fa fa-check"></i><b>3.3.4.1</b> Ridge penalty</a></li>
<li class="chapter" data-level="3.3.4.2" data-path="regularized-regression.html"><a href="regularized-regression.html#lasso"><i class="fa fa-check"></i><b>3.3.4.2</b> Lasso penalty</a></li>
<li class="chapter" data-level="3.3.4.3" data-path="regularized-regression.html"><a href="regularized-regression.html#elastic"><i class="fa fa-check"></i><b>3.3.4.3</b> Elastic nets</a></li>
</ul></li>
<li class="chapter" data-level="3.3.5" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-tuning"><i class="fa fa-check"></i><b>3.3.5</b> Tuning</a></li>
<li class="chapter" data-level="3.3.6" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-pkg-implementation"><i class="fa fa-check"></i><b>3.3.6</b> Package implementation</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-regression"><i class="fa fa-check"></i><b>3.4</b> Implementation: Regression</a><ul>
<li class="chapter" data-level="3.4.1" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glm-glmnet"><i class="fa fa-check"></i><b>3.4.1</b> <code>glmnet</code></a><ul>
<li class="chapter" data-level="3.4.1.1" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glmnet-basic"><i class="fa fa-check"></i><b>3.4.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.4.1.2" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glmnet-tune"><i class="fa fa-check"></i><b>3.4.1.2</b> Tuning</a></li>
<li class="chapter" data-level="3.4.1.3" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glmnet-visualizing"><i class="fa fa-check"></i><b>3.4.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="3.4.1.4" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glmnet-predict"><i class="fa fa-check"></i><b>3.4.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="3.4.2" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-regularize-h2o"><i class="fa fa-check"></i><b>3.4.2</b> <code>h2o</code></a><ul>
<li class="chapter" data-level="3.4.2.1" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-h2o-basic"><i class="fa fa-check"></i><b>3.4.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.4.2.2" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-h2o-tune"><i class="fa fa-check"></i><b>3.4.2.2</b> Tuning</a></li>
<li class="chapter" data-level="3.4.2.3" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-h2o-viz"><i class="fa fa-check"></i><b>3.4.2.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="3.4.2.4" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-h2o-predict"><i class="fa fa-check"></i><b>3.4.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-binary-classification"><i class="fa fa-check"></i><b>3.5</b> Implementation: Binary Classification</a><ul>
<li class="chapter" data-level="3.5.1" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binary-glm-glmnet"><i class="fa fa-check"></i><b>3.5.1</b> <code>glmnet</code></a><ul>
<li class="chapter" data-level="3.5.1.1" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binary-glmnet-basic"><i class="fa fa-check"></i><b>3.5.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.5.1.2" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binaryglmnet-tune"><i class="fa fa-check"></i><b>3.5.1.2</b> Tuning</a></li>
<li class="chapter" data-level="3.5.1.3" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binary-glmnet-visualizing"><i class="fa fa-check"></i><b>3.5.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="3.5.1.4" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binary-glmnet-predict"><i class="fa fa-check"></i><b>3.5.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="3.5.2" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binaryglm-h2o"><i class="fa fa-check"></i><b>3.5.2</b> <code>h2o</code></a><ul>
<li class="chapter" data-level="3.5.2.1" data-path="regularized-regression.html"><a href="regularized-regression.html#h2o-glm-classification-binary-basic"><i class="fa fa-check"></i><b>3.5.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.5.2.2" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-binary-tune"><i class="fa fa-check"></i><b>3.5.2.2</b> Tuning</a></li>
<li class="chapter" data-level="3.5.2.3" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-binary-viz"><i class="fa fa-check"></i><b>3.5.2.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="3.5.2.4" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-binary-predict"><i class="fa fa-check"></i><b>3.5.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-multinomial-classification"><i class="fa fa-check"></i><b>3.6</b> Implementation: Multinomial Classification</a><ul>
<li class="chapter" data-level="3.6.1" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glm-glmnet"><i class="fa fa-check"></i><b>3.6.1</b> <code>glmnet</code></a><ul>
<li class="chapter" data-level="3.6.1.1" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glmnet-basic"><i class="fa fa-check"></i><b>3.6.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.6.1.2" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glmnet-tune"><i class="fa fa-check"></i><b>3.6.1.2</b> Tuning</a></li>
<li class="chapter" data-level="3.6.1.3" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glmnet-visualizing"><i class="fa fa-check"></i><b>3.6.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="3.6.1.4" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glmnet-predict"><i class="fa fa-check"></i><b>3.6.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="3.6.2" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multinomial-glm-h2o"><i class="fa fa-check"></i><b>3.6.2</b> <code>h2o</code></a><ul>
<li class="chapter" data-level="3.6.2.1" data-path="regularized-regression.html"><a href="regularized-regression.html#h2o-glm-classification-multinomial-basic"><i class="fa fa-check"></i><b>3.6.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.6.2.2" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-multinomial-tune"><i class="fa fa-check"></i><b>3.6.2.2</b> Tuning</a></li>
<li class="chapter" data-level="3.6.2.3" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-multinomial-viz"><i class="fa fa-check"></i><b>3.6.2.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="3.6.2.4" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-multinomial-predict"><i class="fa fa-check"></i><b>3.6.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-learning"><i class="fa fa-check"></i><b>3.7</b> Learning More</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>4</b> Random Forest</a><ul>
<li class="chapter" data-level="4.1" data-path="random-forest.html"><a href="random-forest.html#rf-requirements"><i class="fa fa-check"></i><b>4.1</b> Prerequisites</a></li>
<li class="chapter" data-level="4.2" data-path="random-forest.html"><a href="random-forest.html#rf-proscons"><i class="fa fa-check"></i><b>4.2</b> Advantages &amp; Disadvantages</a></li>
<li class="chapter" data-level="4.3" data-path="random-forest.html"><a href="random-forest.html#rf-idea"><i class="fa fa-check"></i><b>4.3</b> The Idea</a><ul>
<li class="chapter" data-level="4.3.1" data-path="random-forest.html"><a href="random-forest.html#rf-oob"><i class="fa fa-check"></i><b>4.3.1</b> OOB error vs. test set error</a></li>
<li class="chapter" data-level="4.3.2" data-path="random-forest.html"><a href="random-forest.html#rf-tune"><i class="fa fa-check"></i><b>4.3.2</b> Tuning</a></li>
<li class="chapter" data-level="4.3.3" data-path="random-forest.html"><a href="random-forest.html#rf-pkgs"><i class="fa fa-check"></i><b>4.3.3</b> Package implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="random-forest.html"><a href="random-forest.html#rf-regression"><i class="fa fa-check"></i><b>4.4</b> Implementation: Regression</a><ul>
<li class="chapter" data-level="4.4.1" data-path="random-forest.html"><a href="random-forest.html#ranger-regression"><i class="fa fa-check"></i><b>4.4.1</b> <code>ranger</code></a><ul>
<li class="chapter" data-level="4.4.1.1" data-path="random-forest.html"><a href="random-forest.html#ranger-regression-basic"><i class="fa fa-check"></i><b>4.4.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.4.1.2" data-path="random-forest.html"><a href="random-forest.html#ranger-regression-tune"><i class="fa fa-check"></i><b>4.4.1.2</b> Tuning</a></li>
<li class="chapter" data-level="4.4.1.3" data-path="random-forest.html"><a href="random-forest.html#ranger-regression-viz"><i class="fa fa-check"></i><b>4.4.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="4.4.1.4" data-path="random-forest.html"><a href="random-forest.html#ranger-regression-predic"><i class="fa fa-check"></i><b>4.4.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="4.4.2" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-regression"><i class="fa fa-check"></i><b>4.4.2</b> <code>h20</code></a><ul>
<li class="chapter" data-level="4.4.2.1" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-regression-basic"><i class="fa fa-check"></i><b>4.4.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.4.2.2" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-regression-tune"><i class="fa fa-check"></i><b>4.4.2.2</b> Tuning</a></li>
<li class="chapter" data-level="4.4.2.3" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-regression-viz"><i class="fa fa-check"></i><b>4.4.2.3</b> Visualizing results</a></li>
<li class="chapter" data-level="4.4.2.4" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-regression-predict"><i class="fa fa-check"></i><b>4.4.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="random-forest.html"><a href="random-forest.html#rf-binary-classification"><i class="fa fa-check"></i><b>4.5</b> Implementation: Binary Classification</a><ul>
<li class="chapter" data-level="4.5.1" data-path="random-forest.html"><a href="random-forest.html#ranger-rf-binary-classification"><i class="fa fa-check"></i><b>4.5.1</b> <code>ranger</code></a><ul>
<li class="chapter" data-level="4.5.1.1" data-path="random-forest.html"><a href="random-forest.html#ranger-binary-classification-basic"><i class="fa fa-check"></i><b>4.5.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.5.1.2" data-path="random-forest.html"><a href="random-forest.html#ranger-rf-binary-classification-tune"><i class="fa fa-check"></i><b>4.5.1.2</b> Tuning</a></li>
<li class="chapter" data-level="4.5.1.3" data-path="random-forest.html"><a href="random-forest.html#ranger-rf-binary-classification-viz"><i class="fa fa-check"></i><b>4.5.1.3</b> Visualizing results</a></li>
<li class="chapter" data-level="4.5.1.4" data-path="random-forest.html"><a href="random-forest.html#ranger-rf-binary-classification-predict"><i class="fa fa-check"></i><b>4.5.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="4.5.2" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-binary-classification"><i class="fa fa-check"></i><b>4.5.2</b> <code>h20</code></a><ul>
<li class="chapter" data-level="4.5.2.1" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-binary-classification-basic"><i class="fa fa-check"></i><b>4.5.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.5.2.2" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-multi-classification-tune"><i class="fa fa-check"></i><b>4.5.2.2</b> Tuning</a></li>
<li class="chapter" data-level="4.5.2.3" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-binary-classification-viz"><i class="fa fa-check"></i><b>4.5.2.3</b> Visualizing results</a></li>
<li class="chapter" data-level="4.5.2.4" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-binary-classification-predict"><i class="fa fa-check"></i><b>4.5.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="random-forest.html"><a href="random-forest.html#rf-multi"><i class="fa fa-check"></i><b>4.6</b> Implementation: Multinomial Classification</a><ul>
<li class="chapter" data-level="4.6.1" data-path="random-forest.html"><a href="random-forest.html#rf-ranger-multi"><i class="fa fa-check"></i><b>4.6.1</b> <code>ranger</code></a><ul>
<li class="chapter" data-level="4.6.1.1" data-path="random-forest.html"><a href="random-forest.html#ranger-multi-basic"><i class="fa fa-check"></i><b>4.6.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.6.1.2" data-path="random-forest.html"><a href="random-forest.html#ranger-multi-tune"><i class="fa fa-check"></i><b>4.6.1.2</b> Tuning</a></li>
<li class="chapter" data-level="4.6.1.3" data-path="random-forest.html"><a href="random-forest.html#ranger-multi-viz"><i class="fa fa-check"></i><b>4.6.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="4.6.1.4" data-path="random-forest.html"><a href="random-forest.html#ranger-multi-predict"><i class="fa fa-check"></i><b>4.6.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="4.6.2" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi"><i class="fa fa-check"></i><b>4.6.2</b> <code>h2o</code></a><ul>
<li class="chapter" data-level="4.6.2.1" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi-basic"><i class="fa fa-check"></i><b>4.6.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.6.2.2" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi-tune"><i class="fa fa-check"></i><b>4.6.2.2</b> Tuning</a></li>
<li class="chapter" data-level="4.6.2.3" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi-viz"><i class="fa fa-check"></i><b>4.6.2.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="4.6.2.4" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi-predict"><i class="fa fa-check"></i><b>4.6.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="random-forest.html"><a href="random-forest.html#rf-learn"><i class="fa fa-check"></i><b>4.7</b> Learning More</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Hands-on Machine Learning with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regularized-regression" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Regularized Regression</h1>
<p><img src="images/regularization_logo.png"  style="float:right; margin: 0px 0px 0px 0px; width: 50%; height: 50%;" /></p>
<p>Generalized linear models (GLMs) such as ordinary least squares regression and logistic regression are simple and fundamental approaches for supervised learning. Moreover, when the assumptions required by GLMs are met, the coefficients produced are unbiased and, of all unbiased linear techniques, have the lowest variance. However, in today’s world, data sets being analyzed typically have a large amount of features. As the number of features grow, our GLM assumptions typically break down and our models often overfit (aka have high variance) to the training sample, causing our out of sample error to increase. <strong><em>Regularization</em></strong> methods provide a means to control our coefficients, which can reduce the variance and decrease out of sample error.</p>
<div id="glm-req" class="section level2">
<h2><span class="header-section-number">3.1</span> Prerequisites</h2>
<div class="rmdwarning">
<p>
This chapter assumes you are familiary with basic idea behind linear and logistic regression. If not, two tutorials to get you up to speed include this <a href="http://uc-r.github.io/linear_regression">linear regression tutorial</a> and this <a href="http://uc-r.github.io/logistic_regression">logistic regression tutorial</a>.
</p>
</div>
<p>This chapter leverages the following packages. Some of these packages are playing a supporting role while the main emphasis will be on the <a href="https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html"><strong>glmnet</strong></a> <span class="citation">(Friedman, Hastie, and Tibshirani <a href="#ref-R-glmnet">2010</a>)</span> and <a href="http://docs.h2o.ai/?_ga=2.52641192.1255510165.1524074778-1013458140.1519825157"><strong>h2o</strong></a> <span class="citation">(Kraljevic <a href="#ref-R-h2o">2018</a>)</span> packages.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(glmnet)   <span class="co"># implementing regularized regression approaches</span>
<span class="kw">library</span>(h2o)      <span class="co"># implementing regularized regression approaches</span>
<span class="kw">library</span>(rsample)  <span class="co"># training vs testing data split</span>
<span class="kw">library</span>(dplyr)    <span class="co"># basic data manipulation procedures</span>
<span class="kw">library</span>(ggplot2)  <span class="co"># plotting</span></code></pre></div>
</div>
<div id="glm-pros-cons" class="section level2">
<h2><span class="header-section-number">3.2</span> Advantages &amp; Disadvantages</h2>
<p><strong>Advantages:</strong></p>
<ul>
<li>Normal GLM models require that you have more observations than variables (<span class="math inline">\(n&gt;p\)</span>); regularized regression allows you to model wide data where <span class="math inline">\(n&lt;p\)</span>.</li>
<li>Minimizes the impact of multicollinearity.</li>
<li>Provides automatic feature selection (at least when you apply a Lasso or elastic net penalty).</li>
<li>Minimal hyperparameters making it easy to tune.</li>
<li>Computationally efficient - relatively fast compared to other algorithms in this guide and does not require large memory.</li>
</ul>
<p><strong>Disdvantages:</strong></p>
<ul>
<li>Requires data pre-processing - requires all variables to be numeric (i.e. one-hot encode). However, <strong>h2o</strong> helps to automate this process.</li>
<li>Does not handle missing data - must impute or remove observations with missing values.</li>
<li>Not robust to outliers as they can still bias the coefficients.</li>
<li>Assumes relationships between predictors and response variable to be monotonic linear (always increasing or decreasing in a linear fashion).</li>
<li>Typically does not perform as well as more advanced methods that allow non-monotonic and non-linear relationships (i.e. random forests, gradient boosting machines, neural networks).</li>
</ul>
</div>
<div id="glm-why" class="section level2">
<h2><span class="header-section-number">3.3</span> The Idea</h2>
<p>The easiest way to understand regularized regression is to explain how it is applied to ordinary least squares regression (OLS). The objective of OLS regression is to find the plane that minimizes the sum of squared errors (SSE) between the observed and predicted response. Illustrated below, this means identifying the plane that minimizes the grey lines, which measure the distance between the observed (red dots) and predicted response (blue plane).</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="images/sq.errors-1.png" alt="Fitted regression line using Ordinary Least Squares."  />
<p class="caption">
Figure 2.1: Fitted regression line using Ordinary Least Squares.
</p>
</div>
<p>More formally, this objective function is written as:</p>
<p><span class="math display">\[\text{minimize} \bigg \{ SSE = \sum^n_{i=1} (y_i - \hat{y}_i)^2 \bigg \} \tag{1}\]</span></p>
<p>The OLS objective function performs quite well when our data align to the key assumptions of OLS regression:</p>
<ul>
<li>Linear relationship</li>
<li>Multivariate normality</li>
<li>No autocorrelation</li>
<li>Homoscedastic (constant variance in residuals)</li>
<li>There are more observations (<em>n</em>) than features (<em>p</em>) (<span class="math inline">\(n &gt; p\)</span>)</li>
<li>No or little multicollinearity</li>
</ul>
<p>However, for many real-life data sets we have very <em>wide</em> data, meaning we have a large number of features (<em>p</em>) that we believe are informative in predicting some outcome. As <em>p</em> increases, we can quickly violate some of the OLS assumptions and we require alternative approaches to provide predictive analytic solutions. Specifically, as <em>p</em> increases there are three main issues we most commonly run into:</p>
<div id="multicollinearity" class="section level3">
<h3><span class="header-section-number">3.3.1</span> 1. Multicollinearity</h3>
<p>As <em>p</em> increases we are more likely to capture multiple features that have some multicollinearity. When multicollinearity exists, we often see high variability in our coefficient terms. For example, in our Ames data, <code>Gr_Liv_Area</code> and <code>TotRms_AbvGrd</code> are two variables that have a correlation of 0.808 and both variables are strongly correlated to our response variable (<code>Sale_Price</code>). When we fit a model with both these variables we get a positive coefficient for <code>Gr_Liv_Area</code> but a negative coefficient for <code>TotRms_AbvGrd</code>, suggesting one has a positive impact to <code>Sale_Price</code> and the other a negative impact.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit with two strongly correlated variables</span>
<span class="kw">lm</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Gr_Liv_Area <span class="op">+</span><span class="st"> </span>TotRms_AbvGrd, <span class="dt">data =</span> ames)
## 
## Call:
## lm(formula = Sale_Price ~ Gr_Liv_Area + TotRms_AbvGrd, data = ames)
## 
## Coefficients:
##   (Intercept)    Gr_Liv_Area  TotRms_AbvGrd  
##       42767.6          139.4       -11025.9</code></pre></div>
<p>However, if we refit the model with each variable independently, they both show a positive impact. However, the <code>Gr_Liv_Area</code> effect is now smaller and the <code>TotRms_AbvGrd</code> is positive with a much larger magnitude.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit with just Gr_Liv_Area</span>
<span class="kw">lm</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Gr_Liv_Area, <span class="dt">data =</span> ames)
## 
## Call:
## lm(formula = Sale_Price ~ Gr_Liv_Area, data = ames)
## 
## Coefficients:
## (Intercept)  Gr_Liv_Area  
##     13289.6        111.7

<span class="co"># fit with just TotRms_Area</span>
<span class="kw">lm</span>(Sale_Price <span class="op">~</span><span class="st"> </span>TotRms_AbvGrd, <span class="dt">data =</span> ames)
## 
## Call:
## lm(formula = Sale_Price ~ TotRms_AbvGrd, data = ames)
## 
## Coefficients:
##   (Intercept)  TotRms_AbvGrd  
##         18665          25164</code></pre></div>
<p>This is a common result when collinearity exists. Coefficients for correlated features become over-inflated and can fluctuate significantly. One consequence of these large fluctuations in the coefficient terms is overfitting, which means we have high variance in the bias-variance tradeoff space. Although an analyst can use tools such as variance inflaction factors <span class="citation">(Myers <a href="#ref-myers1990classical">1990</a>)</span> to identify and remove those strongly correlated variables, it is not always clear which variable(s) to remove. Nor do we always wish to remove variables as this may be removing signal in our data.</p>
</div>
<div id="insufficient-solution" class="section level3">
<h3><span class="header-section-number">3.3.2</span> 2. Insufficient solution</h3>
<p>When the number of features exceed the number of observations (<span class="math inline">\(p &gt; n\)</span>), the OLS solution matrix is <em>not</em> invertible. This causes significant issues because it means: (1) The least-squares estimates are not unique. In fact, there are an infinite set of solutions available and most of these solutions overfit the data. (2) In many instances the result will be computationally infeasible.</p>
<p>Consequently, to resolve this issue an analyst can remove variables until <span class="math inline">\(p &lt; n\)</span> and then fit an OLS regression model. Although an analyst can use pre-processing tools to guide this manual approach (<a href="http://appliedpredictivemodeling.com/">Kuhn &amp; Johnson, 2013, pp. 43-47</a>), it can be cumbersome and prone to errors.</p>
</div>
<div id="interpretability" class="section level3">
<h3><span class="header-section-number">3.3.3</span> 3. Interpretability</h3>
<p>With a large number of features, we often would like to identify a smaller subset of these features that exhibit the strongest effects. In essence, we sometimes prefer techniques that provide feature selection. One approach to this is called <em>hard threshholding</em> feature selection, which can be performed with <a href="http://uc-r.github.io/model_selection">linear model selection</a> approaches. However, model selection approaches can be computationally inefficient, do not scale well, and they simply assume a feature as in or out. We may wish to use a <em>soft threshholding</em> approach that slowly pushes a feature’s effect towards zero. As will be demonstrated, this can provide additional understanding regarding predictive signals.</p>
</div>
<div id="regularized_regress" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Regularized Models</h3>
<p>When we experience these concerns, one alternative to OLS regression is to use regularized regression (also commonly referred to as <em>penalized</em> models or <em>shrinkage</em> methods) to control the parameter estimates. Regularized regression puts contraints on the magnitude of the coefficients and will progressively shrink them towards zero. This constraint helps to reduce the magnitude and fluctuations of the coefficients and will reduce the variance of our model.</p>
<p>The objective function of regularized regression methods is very similar to OLS regression; however, we add a penalty parameter (<em>P</em>).</p>
<p><span class="math display">\[\text{minimize} \big \{ SSE + P \big \} \tag{2}\]</span></p>
<p>This penalty parameter constrains the size of the coefficients such that the only way the coefficients can increase is if we experience a comparable decrease in the sum of squared errors (SSE).</p>
<div class="rmdcomment">
<p>
This concept generalizes to all GLM models. So far, we have be discussing OLS and the sum of squared errors. However, different models within the <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">GLM family</a> (i.e. logistic regression, Poisson regression) have different loss functions. Yet we can think of the penalty parameter all the same - it constrains the size of the coefficients such that the only way the coefficients can increase is if we experience a comparable decrease in the model’s loss function.
</p>
</div>
<p>There are three types of penalty parameters we can implement:</p>
<ol style="list-style-type: decimal">
<li>Ridge</li>
<li>Lasso</li>
<li>Elastic net, which is a combination of Ridge and Lasso</li>
</ol>
<div id="ridge" class="section level4">
<h4><span class="header-section-number">3.3.4.1</span> Ridge penalty</h4>
<p>Ridge regression <span class="citation">(Hoerl and Kennard <a href="#ref-hoerl1970ridge">1970</a>)</span> controls the coefficients by adding <font color="red"><span class="math inline">\(\lambda \sum^p_{j=1} \beta_j^2\)</span></font> to the objective function. This penalty parameter is also referred to as “<span class="math inline">\(L_2\)</span>” as it signifies a second-order penalty being used on the coefficients.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p><span class="math display">\[\text{minimize } \bigg \{ SSE + \lambda \sum^p_{j=1} \beta_j^2 \bigg \} \tag{3}\]</span></p>
<p>This penalty parameter can take on a wide range of values, which is controlled by the <em>tuning parameter</em> <span class="math inline">\(\lambda\)</span>. When <span class="math inline">\(\lambda = 0\)</span> there is no effect and our objective function equals the normal OLS regression objective function of simply minimizing SSE. However, as <span class="math inline">\(\lambda \rightarrow \infty\)</span>, the penalty becomes large and forces our coefficients to <em>near zero</em>. This is illustrated in Figure <a href="regularized-regression.html#fig:ridge-coef-example">3.1</a> where exemplar coefficients have been regularized with <span class="math inline">\(\lambda\)</span> ranging from 0 to over 8,000 (<span class="math inline">\(log(8103) = 9\)</span>).</p>
<div class="figure" style="text-align: center"><span id="fig:ridge-coef-example"></span>
<img src="images/ridge_coef.png" alt="Ridge regression coefficients as $\lambda$ grows from  $0 \rightarrow \infty$." width="75%" height="75%" />
<p class="caption">
Figure 3.1: Ridge regression coefficients as <span class="math inline">\(\lambda\)</span> grows from <span class="math inline">\(0 \rightarrow \infty\)</span>.
</p>
</div>
<p>Although these coefficients were scaled and centered prior to the analysis, you will notice that some are extremely large when <span class="math inline">\(\lambda \rightarrow 0\)</span>. Furthermore, you’ll notice the large negative parameter that fluctuates until <span class="math inline">\(log(\lambda) \approx 2\)</span> where it then continuously skrinks to zero. This is indicitive of multicollinearity and likely illustrates that constraining our coefficients with <span class="math inline">\(log(\lambda) &gt; 2\)</span> may reduce the variance, and therefore the error, in our model.</p>
<p>In essence, the ridge regression model pushes many of the correlated features towards each other rather than allowing for one to be wildly positive and the other wildly negative. Furthermore, many of the non-important features get pushed to near zero. This allows us to reduce the noise in our data, which provides us more clarity in identifying the true signals in our model.</p>
<p>However, a ridge model will retain <bold><font color="red">all</font></bold> variables. Therefore, a ridge model is good if you believe there is a need to retain all features in your model yet reduce the noise that less influential variables may create and minimize multicollinearity. However, a ridge model does not perform feature selection. If greater interpretation is necessary where you need to reduce the signal in your data to a smaller subset then a lasso or elastic net penalty may be preferable.</p>
</div>
<div id="lasso" class="section level4">
<h4><span class="header-section-number">3.3.4.2</span> Lasso penalty</h4>
<p>The <em>least absolute shrinkage and selection operator</em> (lasso) model <span class="citation">(Tibshirani <a href="#ref-tibshirani1996regression">1996</a>)</span> is an alternative to the ridge penalty that has a small modification to the penalty in the objective function. Rather than the <span class="math inline">\(L_2\)</span> penalty we use the following <span class="math inline">\(L_1\)</span> penalty <font color="red"><span class="math inline">\(\lambda \sum^p_{j=1} | \beta_j|\)</span></font> in the objective function.</p>
<p><span class="math display">\[\text{minimize } \bigg \{ SSE + \lambda \sum^p_{j=1} | \beta_j | \bigg \} \tag{4}\]</span></p>
<p>Whereas the ridge penalty approach pushes variables to <em>approximately but not equal to zero</em>, the lasso penalty will actually push coefficients to zero as illustrated in Figure <a href="regularized-regression.html#fig:lasso-coef-example">3.2</a>. Thus the lasso model not only improves the model with regularization but it also conducts automated feature selection.</p>
<div class="figure" style="text-align: center"><span id="fig:lasso-coef-example"></span>
<img src="03-regularized-glm-models_files/figure-html/lasso-coef-example-1.png" alt="Lasso regression coefficients as $\lambda$ grows from  $0 \rightarrow \infty$. Numbers on top axis illustrate how many non-zero coefficients remain." width="672" />
<p class="caption">
Figure 3.2: Lasso regression coefficients as <span class="math inline">\(\lambda\)</span> grows from <span class="math inline">\(0 \rightarrow \infty\)</span>. Numbers on top axis illustrate how many non-zero coefficients remain.
</p>
</div>
<p>In the figure above we see that when <span class="math inline">\(log(\lambda) = -5\)</span> all 15 variables are in the model, when <span class="math inline">\(log(\lambda) = -1\)</span> 12 variables are retained, and when <span class="math inline">\(log(\lambda) = 1\)</span> only 3 variables are retained. Consequently, when a data set has many features, lasso can be used to identify and extract those features with the largest (and most consistent) signal.</p>
</div>
<div id="elastic" class="section level4">
<h4><span class="header-section-number">3.3.4.3</span> Elastic nets</h4>
<p>A generalization of the ridge and lasso penalties is the <em>elastic net</em> penalty <span class="citation">(Zou and Hastie <a href="#ref-zou2005regularization">2005</a>)</span>, which combines the two penalties.</p>
<p><span class="math display">\[\text{minimize } \bigg \{ SSE + \lambda_1 \sum^p_{j=1} \beta_j^2 + \lambda_2 \sum^p_{j=1} | \beta_j | \bigg \} \tag{5}\]</span></p>
<p>Although lasso models perform feature selection, a result of their penalty parameter is that typically when two strongly correlated features are pushed towards zero, one may be pushed fully to zero while the other remains in the model. Furthermore, the process of one being in and one being out is not very systematic. In contrast, the ridge regression penalty is a little more effective in systematically reducing correlated features together. Consequently, the advantage of the elastic net penalty is that it enables effective regularization via the ridge penalty with the feature selection characteristics of the lasso penalty.</p>
</div>
</div>
<div id="glm-tuning" class="section level3">
<h3><span class="header-section-number">3.3.5</span> Tuning</h3>
<p>Regularized models are simple to tune as there are only two tuning parameters:</p>
<ul>
<li><strong>Size of penalty (<span class="math inline">\(\lambda\)</span>)</strong>: Controls how much we want to constrain our coefficients. Small penalties where <span class="math inline">\(\lambda\)</span> is close to zero allow our coefficients to be larger; however, larger values of <span class="math inline">\(\lambda\)</span> penalize our coefficients and forces them to take on smaller values. Hence, this parameter is often called the <em>shrinkage</em> parameter.</li>
<li><strong>Alpha</strong>: The <code>alpha</code> parameter tells our model to perform a ridge (<code>alpha = 0</code>), lasso (<code>alpha = 1</code>), or elastic net (<span class="math inline">\(0 &lt; alpha &lt; 1\)</span>).</li>
</ul>
</div>
<div id="glm-pkg-implementation" class="section level3">
<h3><span class="header-section-number">3.3.6</span> Package implementation</h3>
<p>There are a few packages that implement variants of regularized regression. You can find a comprehensive list on the <a href="https://cran.r-project.org/web/views/MachineLearning.html">CRAN Machine Learning Task View</a>. However, the most popular implementations which we will cover in this chapter include:</p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/glmnet/index.html">glmnet</a>: The original implementation of regularized regression in R. The <strong>glmnet</strong> R package provides an extremely efficient procedures for fitting the entire lasso or elastic-net regularization path for linear regression, logistic and multinomial regression models, Poisson regression and the Cox model. Two recent additions are the multiple-response Gaussian, and the grouped multinomial regression. A nice vignette is available <a href="https://cran.r-project.org/web/packages/glmnet/vignettes/glmnet_beta.pdf">here</a>. Features include<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>:
<ul>
<li>The code can handle sparse input-matrix formats, as well as range constraints on coefficients.</li>
<li>Automatically standardizes your feature set.</li>
<li>Built-in cross validation.</li>
<li>The core of glmnet is a set of fortran subroutines, which make for very fast execution.</li>
<li>The algorithms use coordinate descent with warm starts and active set iterations.</li>
<li>Supports the following distributions: “gaussian”,“binomial”,“poisson”,“multinomial”,“cox”,“mgaussian”</li>
</ul></li>
<li><a href="https://cran.r-project.org/web/packages/gamboostLSS/index.html">h2o</a>: The <strong>h2o</strong> R package is a powerful and efficient java-based interface that allows for local and cluster-based deployment. It comes with a fairly comprehensive <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html">online resource</a> that includes methodology and code documentation along with tutorials. Features include:
<ul>
<li>Fits both regularized and non-regularized GLMs.</li>
<li>Automated feature pre-processing (one-hot encode &amp; standardization).</li>
<li>Built-in cross validation.</li>
<li>Built-in grid search capabilities.</li>
<li>Supports the following distributions: “guassian”, “binomial”, “multinomial”, “ordinal”, “poisson”, “gamma”, “tweedie”.</li>
<li>Distributed and parallelized computation on either a single node or a multi-node cluster.</li>
<li>Automatic early stopping based on convergence of user-specified metrics to user-specified relative tolerance.</li>
</ul></li>
</ul>
</div>
</div>
<div id="glm-regression" class="section level2">
<h2><span class="header-section-number">3.4</span> Implementation: Regression</h2>
<p>To illustrate various regularization concepts for a regression problem we will use the Ames, IA housing data, where our intent is to predict <code>Sale_Price</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create training (70%) and test (30%) sets for the AmesHousing::make_ames() data.</span>
<span class="co"># Use set.seed for reproducibility</span>

<span class="kw">set.seed</span>(<span class="dv">123</span>)
ames_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(AmesHousing<span class="op">::</span><span class="kw">make_ames</span>(), <span class="dt">prop =</span> .<span class="dv">7</span>, <span class="dt">strata =</span> <span class="st">&quot;Sale_Price&quot;</span>)
ames_train &lt;-<span class="st"> </span><span class="kw">training</span>(ames_split)
ames_test  &lt;-<span class="st"> </span><span class="kw">testing</span>(ames_split)</code></pre></div>
<div id="regression-glm-glmnet" class="section level3">
<h3><span class="header-section-number">3.4.1</span> <code>glmnet</code></h3>
<p>The glmnet package is a fast implementation, but it requires some extra processing up-front to your data if it’s not already represented as a numeric matrix. <strong>glmnet</strong> does not use the formula method (<code>y ~ x</code>) so prior to modeling we need to create our feature and target set. Furthermore, we use the <code>model.matrix</code> function on our feature set (see <code>Matrix::sparse.model.matrix</code> for increased efficiency on large dimension data). We also Box Cox transform our response variable due to its skeweness.</p>
<div class="rmdtip">
<p>
The Box Cox transformation of the response variable is not required; however, parametric models such as regularized regression are sensitive to skewed values so it is always recommended to normalize your response variable.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create training and testing feature matrices</span>
<span class="co"># we use model.matrix(...)[, -1] to discard the intercept</span>
train_x &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(Sale_Price <span class="op">~</span><span class="st"> </span>., ames_train)[, <span class="op">-</span><span class="dv">1</span>]
test_x  &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(Sale_Price <span class="op">~</span><span class="st"> </span>., ames_test)[, <span class="op">-</span><span class="dv">1</span>]

<span class="co"># Create training and testing response vectors</span>
<span class="co"># transform y based on skewness of training data</span>
train_y &lt;-<span class="st"> </span><span class="kw">log</span>(ames_train<span class="op">$</span>Sale_Price)
test_y  &lt;-<span class="st"> </span><span class="kw">log</span>(ames_test<span class="op">$</span>Sale_Price)</code></pre></div>
<div id="regression-glmnet-basic" class="section level4">
<h4><span class="header-section-number">3.4.1.1</span> Basic implementation</h4>
<p>To apply a regularized model we can use the <code>glmnet::glmnet</code> function. The <code>alpha</code> parameter tells <strong>glmnet</strong> to perform a ridge (<code>alpha = 0</code>), lasso (<code>alpha = 1</code>), or elastic net (<span class="math inline">\(0 &lt; alpha &lt; 1\)</span>) model. Behind the scenes, <strong>glmnet</strong> is doing two things that you should be aware of:</p>
<ol style="list-style-type: decimal">
<li>It is essential that predictor variables are standardized when performing regularized regression. <strong>glmnet</strong> performs this for you. If you standardize your predictors prior to <strong>glmnet</strong> you can turn this argument off with <code>standardize = FALSE</code>.</li>
<li><strong>glmnet</strong> will perform ridge models across a wide range of <span class="math inline">\(\lambda\)</span> parameters, which are illustrated in the figure below.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Apply Ridge regression to attrition data</span>
ridge &lt;-<span class="st"> </span><span class="kw">glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">alpha =</span> <span class="dv">0</span>
)

<span class="kw">plot</span>(ridge, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ridge1"></span>
<img src="03-regularized-glm-models_files/figure-html/ridge1-1.png" alt="Coefficients for our ridge regression model as $\lambda$ grows from  $0 \rightarrow \infty$." width="672" />
<p class="caption">
Figure 3.3: Coefficients for our ridge regression model as <span class="math inline">\(\lambda\)</span> grows from <span class="math inline">\(0 \rightarrow \infty\)</span>.
</p>
</div>
<p>In fact, we can see the exact <span class="math inline">\(\lambda\)</span> values applied with <code>ridge$lambda</code>. Although you can specify your own <span class="math inline">\(\lambda\)</span> values, by default <strong>glmnet</strong> applies 100 <span class="math inline">\(\lambda\)</span> values that are data derived.</p>
<div class="rmdtip">
<p>
glmnet has built-in functions to auto-generate the appropriate <span class="math inline"><span class="math inline">\(\lambda\)</span></span> values based on the data so the vast majority of the time you will have little need to adjust the default <span class="math inline"><span class="math inline">\(\lambda\)</span></span> values.
</p>
</div>
<p>We can also directly access the coefficients for a model using <code>coef</code>. <strong>glmnet</strong> stores all the coefficients for each model in order of largest to smallest <span class="math inline">\(\lambda\)</span>. Due to the number of features, here I just peak at the two largest coefficients (<code>Latitude</code> &amp; <code>Overall_QualVery_Excellent</code>) features for the largest <span class="math inline">\(\lambda\)</span> (279.1035) and smallest <span class="math inline">\(\lambda\)</span> (0.02791035). You can see how the largest <span class="math inline">\(\lambda\)</span> value has pushed these coefficients to nearly 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># lambdas applied to penalty parameter</span>
ridge<span class="op">$</span>lambda <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()
## [1] 279.1035 254.3087 231.7166 211.1316 192.3752 175.2851

<span class="co"># small lambda results in large coefficients</span>
<span class="kw">coef</span>(ridge)[<span class="kw">c</span>(<span class="st">&quot;Latitude&quot;</span>, <span class="st">&quot;Overall_QualVery_Excellent&quot;</span>), <span class="dv">100</span>]
##                   Latitude Overall_QualVery_Excellent 
##                 0.60585376                 0.09800466

<span class="co"># large lambda results in small coefficients</span>
<span class="kw">coef</span>(ridge)[<span class="kw">c</span>(<span class="st">&quot;Latitude&quot;</span>, <span class="st">&quot;Overall_QualVery_Excellent&quot;</span>), <span class="dv">1</span>] 
##                   Latitude Overall_QualVery_Excellent 
##               6.228028e-36               9.372514e-37</code></pre></div>
<p>However, at this point, we do not understand how much improvement we are experiencing in our loss function across various <span class="math inline">\(\lambda\)</span> values.</p>
</div>
<div id="regression-glmnet-tune" class="section level4">
<h4><span class="header-section-number">3.4.1.2</span> Tuning</h4>
<p>Recall that <span class="math inline">\(\lambda\)</span> is a tuning parameter that helps to control our model from over-fitting to the training data. However, to identify the optimal <span class="math inline">\(\lambda\)</span> value we need to perform <a href="regression-performance.html#cv">cross-validation</a> (CV). <code>cv.glmnet</code> provides a built-in option to perform k-fold CV, and by default, performs 10-fold CV. Here we perform a CV glmnet model for both a ridge and lasso penalty.</p>
<div class="rmdtip">
<p>
By default, <code>cv.glmnet</code> uses MSE as the loss function but you can also use mean absolute error by changing the <code>type.measure</code> argument.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Apply CV Ridge regression to attrition data</span>
ridge &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">alpha =</span> <span class="dv">0</span>
)

<span class="co"># Apply CV Ridge regression to attrition data</span>
lasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">alpha =</span> <span class="dv">1</span>
)

<span class="co"># plot results</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(ridge, <span class="dt">main =</span> <span class="st">&quot;Ridge penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(lasso, <span class="dt">main =</span> <span class="st">&quot;Lasso penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ridge-lasso-cv-models"></span>
<img src="03-regularized-glm-models_files/figure-html/ridge-lasso-cv-models-1.png" alt="10-fold cross validation MSE for a ridge and lasso model. First dotted vertical line in each plot represents the $\lambda$ with the smallest MSE and the second represents the $\lambda$ with an MSE within one standard error of the minimum MSE." width="864" />
<p class="caption">
Figure 3.4: 10-fold cross validation MSE for a ridge and lasso model. First dotted vertical line in each plot represents the <span class="math inline">\(\lambda\)</span> with the smallest MSE and the second represents the <span class="math inline">\(\lambda\)</span> with an MSE within one standard error of the minimum MSE.
</p>
</div>
<p>Our plots above illustrate the 10-fold CV mean squared error (MSE) across the <span class="math inline">\(\lambda\)</span> values. In both models we see a slight improvement in the MSE as our penalty <span class="math inline">\(log(\lambda)\)</span> gets larger , suggesting that a regular OLS model likely overfits our data. But as we constrain it further (continue to increase the penalty), our MSE starts to increase. The numbers at the top of the plot refer to the number of variables in the model. Ridge regression does not force any variables to exactly zero so all features will remain in the model but we see the number of variables retained in the lasso model go down as our penalty increases.</p>
<p>The first and second vertical dashed lines represent the <span class="math inline">\(\lambda\)</span> value with the minimum MSE and the largest <span class="math inline">\(\lambda\)</span> value within one standard error of the minimum MSE.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Ridge model</span>
<span class="kw">min</span>(ridge<span class="op">$</span>cvm)       <span class="co"># minimum MSE</span>
## [1] 0.02147691
ridge<span class="op">$</span>lambda.min     <span class="co"># lambda for this min MSE</span>
## [1] 0.1236602

ridge<span class="op">$</span>cvm[ridge<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>ridge<span class="op">$</span>lambda.1se]  <span class="co"># 1 st.error of min MSE</span>
## [1] 0.02488411
ridge<span class="op">$</span>lambda.1se  <span class="co"># lambda for this MSE</span>
## [1] 0.6599372

<span class="co"># Lasso model</span>
<span class="kw">min</span>(lasso<span class="op">$</span>cvm)       <span class="co"># minimum MSE</span>
## [1] 0.02411134
lasso<span class="op">$</span>lambda.min     <span class="co"># lambda for this min MSE</span>
## [1] 0.003865266

lasso<span class="op">$</span>cvm[lasso<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>lasso<span class="op">$</span>lambda.1se]  <span class="co"># 1 st.error of min MSE</span>
## [1] 0.02819356
lasso<span class="op">$</span>lambda.1se  <span class="co"># lambda for this MSE</span>
## [1] 0.01560415</code></pre></div>
<p>We can assess this visually. Here we plot the coefficients across the <span class="math inline">\(\lambda\)</span> values and the dashed red line represents the <span class="math inline">\(\lambda\)</span> with the smallest MSE and the dashed blue line represents largest <span class="math inline">\(\lambda\)</span> that falls within one standard error of the minimum MSE. This shows you how much we can constrain the coefficients while still maximizing predictive accuracy.</p>
<div class="rmdtip">
<p>
Above, we saw that both ridge and lasso penalties provide similiar MSEs; however, these plots illustrate that ridge is still using all 299 variables whereas the lasso model can get a similar MSE by reducing our feature set from 299 down to 131. However, there will be some variability with this MSE and we can reasonably assume that we can achieve a similar MSE with a slightly more constrained model that uses only 63 features. Although this lasso model does not offer significant improvement over the ridge model, we get approximately the same accuracy by using only 63 features! If describing and interpreting the predictors is an important outcome of your analysis, this may significantly aid your endeavor.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Ridge model</span>
ridge_min &lt;-<span class="st"> </span><span class="kw">glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">alpha =</span> <span class="dv">0</span>
)

<span class="co"># Lasso model</span>
lasso_min &lt;-<span class="st"> </span><span class="kw">glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">alpha =</span> <span class="dv">1</span>
)

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="co"># plot ridge model</span>
<span class="kw">plot</span>(ridge_min, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Ridge penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(ridge<span class="op">$</span>lambda.min), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(ridge<span class="op">$</span>lambda.1se), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>)

<span class="co"># plot lasso model</span>
<span class="kw">plot</span>(lasso_min, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Lasso penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(lasso<span class="op">$</span>lambda.min), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(lasso<span class="op">$</span>lambda.1se), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ridge-lasso-cv-viz-results"></span>
<img src="03-regularized-glm-models_files/figure-html/ridge-lasso-cv-viz-results-1.png" alt="Coefficients for our ridge and lasso models. First dotted vertical line in each plot represents the $\lambda$ with the smallest MSE and the second represents the $\lambda$ with an MSE within one standard error of the minimum MSE." width="864" />
<p class="caption">
Figure 3.5: Coefficients for our ridge and lasso models. First dotted vertical line in each plot represents the <span class="math inline">\(\lambda\)</span> with the smallest MSE and the second represents the <span class="math inline">\(\lambda\)</span> with an MSE within one standard error of the minimum MSE.
</p>
</div>
<p>So far we’ve implemented a pure ridge and pure lasso model. However, we can implement an elastic net the same way as the ridge and lasso models, by adjusting the <code>alpha</code> parameter. Any <code>alpha</code> value between 0-1 will perform an elastic net. When <code>alpha = 0.5</code> we perform an equal combination of penalties whereas <code>alpha</code> <span class="math inline">\(\rightarrow 0\)</span> will have a heavier ridge penalty applied and <code>alpha</code> <span class="math inline">\(\rightarrow 1\)</span> will have a heavier lasso penalty.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lasso    &lt;-<span class="st"> </span><span class="kw">glmnet</span>(train_x, train_y, <span class="dt">alpha =</span> <span class="fl">1.0</span>) 
elastic1 &lt;-<span class="st"> </span><span class="kw">glmnet</span>(train_x, train_y, <span class="dt">alpha =</span> <span class="fl">0.25</span>) 
elastic2 &lt;-<span class="st"> </span><span class="kw">glmnet</span>(train_x, train_y, <span class="dt">alpha =</span> <span class="fl">0.75</span>) 
ridge    &lt;-<span class="st"> </span><span class="kw">glmnet</span>(train_x, train_y, <span class="dt">alpha =</span> <span class="fl">0.0</span>)

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>)
<span class="kw">plot</span>(lasso, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Lasso (Alpha = 1)</span><span class="ch">\n\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(elastic1, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Elastic Net (Alpha = .25)</span><span class="ch">\n\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(elastic2, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Elastic Net (Alpha = .75)</span><span class="ch">\n\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(ridge, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Ridge (Alpha = 0)</span><span class="ch">\n\n\n</span><span class="st">&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-elastic-comparison"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-elastic-comparison-1.png" alt="Coefficients for various penalty parameters." width="864" />
<p class="caption">
Figure 3.6: Coefficients for various penalty parameters.
</p>
</div>
<p>Often, the optimal model contains an <code>alpha</code> somewhere between 0-1, thus we want to tune both the <span class="math inline">\(\lambda\)</span> and the <code>alpha</code> parameters. To set up our tuning, we create a common <code>fold_id</code>, which just allows us to apply the same CV folds to each model. We then create a tuning grid that searches across a range of <code>alpha</code>s from 0-1, and empty columns where we’ll dump our model results into.</p>
<div class="rmdwarning">
<p>
Use caution when including <span class="math inline"><span class="math inline">\(\alpha = 0\)</span></span> or <span class="math inline"><span class="math inline">\(\alpha = 1\)</span></span> in the grid search. <span class="math inline"><span class="math inline">\(\alpha = 0\)</span></span> will produce a dense solution and it can be very slow (or even impossible) to compute in large <em>N</em> situations. <span class="math inline"><span class="math inline">\(\alpha = 1\)</span></span> has no <span class="math inline"><span class="math inline">\(\ell_2\)</span></span> penalty, so it is therefore less numerically stable and can be very slow as well due to slower convergence. If you experience slow computation, I recommend searching across <span class="math inline"><span class="math inline">\(\alpha\)</span></span> values of 0.1, .25, .5, .75, .9.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># maintain the same folds across all models</span>
fold_id &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">size =</span> <span class="kw">length</span>(train_y), <span class="dt">replace =</span> <span class="ot">TRUE</span>)

<span class="co"># search across a range of alphas</span>
tuning_grid &lt;-<span class="st"> </span>tibble<span class="op">::</span><span class="kw">tibble</span>(
  <span class="dt">alpha      =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> .<span class="dv">1</span>),
  <span class="dt">mse_min    =</span> <span class="ot">NA</span>,
  <span class="dt">mse_1se    =</span> <span class="ot">NA</span>,
  <span class="dt">lambda_min =</span> <span class="ot">NA</span>,
  <span class="dt">lambda_1se =</span> <span class="ot">NA</span>
)</code></pre></div>
<p>Now we can iterate over each <code>alpha</code> value, apply a CV elastic net, and extract the minimum and one standard error MSE values and their respective <span class="math inline">\(\lambda\)</span> values.</p>
<div class="rmdnote">
<p>
This grid search took 41 seconds to compute.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform grid search</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_along</span>(tuning_grid<span class="op">$</span>alpha)) {
  
  <span class="co"># fit CV model for each alpha value</span>
  fit &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(train_x, train_y, <span class="dt">alpha =</span> tuning_grid<span class="op">$</span>alpha[i], <span class="dt">foldid =</span> fold_id)
  
  <span class="co"># extract MSE and lambda values</span>
  tuning_grid<span class="op">$</span>mse_min[i]    &lt;-<span class="st"> </span>fit<span class="op">$</span>cvm[fit<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>fit<span class="op">$</span>lambda.min]
  tuning_grid<span class="op">$</span>mse_1se[i]    &lt;-<span class="st"> </span>fit<span class="op">$</span>cvm[fit<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>fit<span class="op">$</span>lambda.1se]
  tuning_grid<span class="op">$</span>lambda_min[i] &lt;-<span class="st"> </span>fit<span class="op">$</span>lambda.min
  tuning_grid<span class="op">$</span>lambda_1se[i] &lt;-<span class="st"> </span>fit<span class="op">$</span>lambda.1se
}

tuning_grid
## # A tibble: 11 x 5
##    alpha mse_min mse_1se lambda_min lambda_1se
##    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1   0    0.0230  0.0267    0.179       0.795 
##  2   0.1  0.0237  0.0285    0.0387      0.156 
##  3   0.2  0.0241  0.0289    0.0193      0.0856
##  4   0.3  0.0243  0.0295    0.0129      0.0627
##  5   0.4  0.0245  0.0295    0.00966     0.0470
##  6   0.5  0.0246  0.0295    0.00773     0.0376
##  7   0.6  0.0247  0.0301    0.00644     0.0344
##  8   0.7  0.0247  0.0302    0.00552     0.0295
##  9   0.8  0.0247  0.0302    0.00483     0.0258
## 10   0.9  0.0247  0.0302    0.00429     0.0229
## 11   1    0.0248  0.0304    0.00387     0.0206</code></pre></div>
<p>If we plot the MSE ± one standard error for the optimal <span class="math inline">\(\lambda\)</span> value for each <code>alpha</code> setting, we see that they all fall within the same level of accuracy. Consequently, we could select a full lasso model (<code>alpha = 1</code>) with <span class="math inline">\(\lambda = 0.003521887\)</span>, gain the benefits of its feature selection capability and reasonably assume no loss in accuracy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tuning_grid <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">se =</span> mse_1se <span class="op">-</span><span class="st"> </span>mse_min) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(alpha, mse_min)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymax =</span> mse_min <span class="op">+</span><span class="st"> </span>se, <span class="dt">ymin =</span> mse_min <span class="op">-</span><span class="st"> </span>se), <span class="dt">alpha =</span> .<span class="dv">25</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-grid-search-results"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-grid-search-results-1.png" alt="MSE ± one standard error for different alpha penalty parameters." width="384" />
<p class="caption">
Figure 3.7: MSE ± one standard error for different alpha penalty parameters.
</p>
</div>
</div>
<div id="regression-glmnet-visualizing" class="section level4">
<h4><span class="header-section-number">3.4.1.3</span> Visual interpretation</h4>
<p>Regularized regression <strong><em>assumes a monotonic linear relationship</em></strong> between the predictor variables and the response. The <em>linear</em> relationship part of that statement just means, for a given predictor variable, it assumes for every one unit change in a given predictor variable there is a constant change in the response. This constant change is given by the given coefficient for a predictor. The <em>monotonic</em> relationship means that a given predictor variable will always have a positive or negative relationship.</p>
<p>Consequently, this makes understanding variable relationships simple with regularized models. And since the predictors have all been standardized, comparing the coefficients against one another allows us to identify the most influential predictors. Those predictors with the largest positive coefficients have the largest positive impact on our response variable and those variables with really small negative coefficients have a very small negative impact on our response. Furthermore, there is no difference between the global and local model interpretation (see model interpretation chapter for details).</p>
<p>We’ll illustrate with the following models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(train_x, train_y, <span class="dt">alpha =</span> <span class="dv">1</span>) 
ridge &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(train_x, train_y, <span class="dt">alpha =</span> <span class="dv">0</span>)</code></pre></div>
<p>Our ridge model will retain <bold><font color="red">all</font></bold> variables. Therefore, a ridge model is good if you believe there is a need to retain all features in your model yet reduce the noise that less influential variables may create and minimize multicollinearity. However, a ridge model does not perform feature selection but it will typically push most variables to near zero and allow the most influential variables to be more prominent. The following extracts the coefficients of our ridge model and plots the top 100 most influential variables. You can see that many of the variables have coefficients closer to zero but there a handful of predictor variables that have noticable influence.</p>
<p>For example, properties with above average latitude (northern end of Ames), are in the Green Hills neighborhood (which is actually in the south part of Ames), or have 2 extra miscellaneous garage features will have a positive influence on the sales price. Alternatively, properties that are zoned agricultural, have a home functional code of “Sal” (salvage only) or “Sev” (severely damaged), or have a pool quality assessment of “Good” tend have a negative influence on the sales price.</p>
<div class="rmdwarning">
<p>
Keep in mind these coefficients are for the standardized variable values. Consequently, the interpretation of these coefficient values are not as clear. Basically, for every unit the <code>Latitude</code> variable is above the mean value, the reponse variable (which has been log transformed) has a 0.474 unit increase. <strong><em>The important insight is to identify those variables with the largest positive and negative impacts on the response variable.</em></strong>
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(ridge, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(row <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">100</span>, <span class="dt">wt =</span> <span class="kw">abs</span>(value)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(value, <span class="kw">reorder</span>(row, value), <span class="dt">color =</span> value <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Top 100 influential variables (ridge penalty)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Coefficient&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="ot">NULL</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-viz-ridge"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-viz-ridge-1.png" alt="A ridge penalty will retain all variables but push most coefficients to near zero.  Consequently, we retain any minor signals that all features provide but we can visualize those coefficients with the largest absolute values to identify the most influential predictors." width="672" />
<p class="caption">
Figure 3.8: A ridge penalty will retain all variables but push most coefficients to near zero. Consequently, we retain any minor signals that all features provide but we can visualize those coefficients with the largest absolute values to identify the most influential predictors.
</p>
</div>
<p>Similar to ridge, the lasso pushes many of the collinear features towards each other rather than allowing for one to be wildly positive and the other wildly negative. However, unlike ridge, the lasso will actually push coefficients to zero and perform feature selection. This simplifies and automates the process of identifying those features most influential to predictive accuracy. If we select the model with the minimum MSE and plot all variables in that model we see similar results to the ridge regarding the most influential variables.</p>
<div class="rmdnote">
<p>
Although the ordering typically differs, we often see some commonality between lasso and ridge models regarding the most influential variables.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(lasso, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(row <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(value, <span class="kw">reorder</span>(row, value), <span class="dt">color =</span> value <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Influential variables (lasso penalty)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Coefficient&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="ot">NULL</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-viz-lasso"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-viz-lasso-1.png" alt="A lasso penalty will perform feature selection by pushing most coefficients to zero.  Consequently, we can view all coefficients to see which features were selected; however, our objective usually is still to identify those features with the strongest signal (largest absolute coefficient values)." width="672" />
<p class="caption">
Figure 3.9: A lasso penalty will perform feature selection by pushing most coefficients to zero. Consequently, we can view all coefficients to see which features were selected; however, our objective usually is still to identify those features with the strongest signal (largest absolute coefficient values).
</p>
</div>
</div>
<div id="regression-glmnet-predict" class="section level4">
<h4><span class="header-section-number">3.4.1.4</span> Predicting</h4>
<p>Once you have identified your preferred model, you can simply use <code>predict</code> to predict the same model on a new data set. The only caveat is you need to supply <code>predict</code> an <code>s</code> parameter with the preferred models <span class="math inline">\(\lambda\)</span> value. For example, here we create a lasso model, which provides me a minimum MSE of 0.02398 (RMSE = 0.123). However, our response variable is log transformed so we must re-transform it to get an interpretable RMSE (our average generalized error is $25,156.77).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># optimal model</span>
cv_lasso   &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(train_x, train_y, <span class="dt">alpha =</span> <span class="fl">1.0</span>)
<span class="kw">min</span>(cv_lasso<span class="op">$</span>cvm)
## [1] 0.02529035

<span class="co"># predict and get RMSE</span>
pred &lt;-<span class="st"> </span><span class="kw">predict</span>(cv_lasso, <span class="dt">s =</span> cv_lasso<span class="op">$</span>lambda.min, test_x)
caret<span class="op">::</span><span class="kw">RMSE</span>(pred, test_y)
## [1] 0.1220084

<span class="co"># re-transform predicted values and get interpretable RMSE</span>
caret<span class="op">::</span><span class="kw">RMSE</span>(<span class="kw">exp</span>(pred), <span class="kw">exp</span>(test_y))
## [1] 24740.36</code></pre></div>
</div>
</div>
<div id="regression-regularize-h2o" class="section level3">
<h3><span class="header-section-number">3.4.2</span> <code>h2o</code></h3>
<p>To perform regularized regression with <strong>h2o</strong>, we first need to initiate our <strong>h2o</strong> session.</p>
<pre><code>## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     /var/folders/ws/qs4y2bnx1xs_4y9t0zbdjsvh0000gn/T//RtmpGOvEr1/h2o_bradboehmke_started_from_r.out
##     /var/folders/ws/qs4y2bnx1xs_4y9t0zbdjsvh0000gn/T//RtmpGOvEr1/h2o_bradboehmke_started_from_r.err
## 
## 
## Starting H2O JVM and connecting: .. Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         2 seconds 363 milliseconds 
##     H2O cluster timezone:       America/New_York 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.18.0.11 
##     H2O cluster version age:    2 months and 13 days  
##     H2O cluster name:           H2O_started_from_R_bradboehmke_fmw129 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   4.44 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.5.1 (2018-07-02)</code></pre>
<p>Next, we do not need to one-hot encode or standardize our variables as <strong>h2o</strong> will do this for us. However, we do want to normalize our response variable due to its skewness and then convert our training and test data to <strong>h2o</strong> objects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># convert training data to h2o object</span>
train_h2o &lt;-<span class="st"> </span>ames_train <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Sale_Price =</span> <span class="kw">log</span>(Sale_Price)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.h2o</span>()

<span class="co"># convert test data to h2o object</span>
test_h2o &lt;-<span class="st"> </span>ames_test <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Sale_Price =</span> <span class="kw">log</span>(Sale_Price)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.h2o</span>()

<span class="co"># set the response column to Sale_Price</span>
response &lt;-<span class="st"> &quot;Sale_Price&quot;</span>

<span class="co"># set the predictor names</span>
predictors &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(ames_train), response)</code></pre></div>
<div id="regression-h2o-basic" class="section level4">
<h4><span class="header-section-number">3.4.2.1</span> Basic implementation</h4>
<p><code>h2o.glm</code> allows us to perform a generalized linear model. If the response variable is continuous, <code>h2o.glm</code> will use a gaussian distribution (see <code>family</code> parameter <code>?h2o.glm</code>). By default, <code>h2o.glm</code> performs an elastic net model with <code>alpha = .5</code>. Similar to <strong>glmnet</strong>, <code>h2o.glm</code> will perform an automated search across internally generated lambda values.</p>
<div class="rmdtip">
<p>
You can override the automated lambda search by supplying different values to the <code>lambda</code> parameters in <code>h2o.glm</code> but this is not recommended as the default parameters typically perform best.
</p>
</div>
<p>The following performs a default <code>h2o.glm</code> model with <code>alpha = .5</code> and it performs a 10 fold cross validation (<code>nfolds = 10</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># train your model, where you specify alpha (performs 10-fold CV)</span>
h2o_fit1 &lt;-<span class="st"> </span><span class="kw">h2o.glm</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> train_h2o,
  <span class="dt">nfolds =</span> <span class="dv">10</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">alpha =</span> .<span class="dv">5</span>, 
  <span class="dt">family =</span> <span class="st">&quot;gaussian&quot;</span>
)

<span class="co"># print the MSE and RMSE for the validation data</span>
<span class="kw">h2o.mse</span>(h2o_fit1, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## [1] 0.0405933

<span class="kw">h2o.rmse</span>(h2o_fit1, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## [1] 0.2014778</code></pre></div>
<p>If we check out the summary results of our model we get a bunch of information. Below is truncated printout which provides important model information such as the alpha applied and the optimal lambda value identified (<span class="math inline">\(\lambda = 0.056\)</span>), the number of predictors retained with these penalty parameters (11), and performance results for the training and validation sets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(h2o_fit1)
## Model Details:
## ==============
## 
## H2ORegressionModel: glm
## Model Key:  GLM_model_R_1531935157122_1 
## GLM Model: summary
##     family     link                               regularization number_of_predictors_total number_of_active_predictors number_of_iterations                #training_frame
## 1 gaussian identity Elastic Net (alpha = 0.5, lambda = 0.05581 )                        345                          11                    2 file13d1f4ffcacf3_sid_be66_16
## 
## H2ORegressionMetrics: glm
## ** Reported on training data. **
## 
## MSE:  0.03800294
## RMSE:  0.1949434
## MAE:  0.1277845
## RMSLE:  0.01521899
## Mean Residual Deviance :  0.03800294
## R^2 :  0.7737851
## Null Deviance :345.0615
## Null D.o.F. :2053
## Residual Deviance :78.05805
## Residual D.o.F. :2042
## AIC :-861.7687
## 
## 
## 
## H2ORegressionMetrics: glm
## ** Reported on cross-validation data. **
## ** 10-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.0405933
## RMSE:  0.2014778
## MAE:  0.1310502
## RMSLE:  0.01567771
## Mean Residual Deviance :  0.0405933
## R^2 :  0.7583658
## Null Deviance :345.4348
## Null D.o.F. :2053
## Residual Deviance :83.37864
## Residual D.o.F. :2042
## AIC :-726.3293
## 
## truncated.....
##</code></pre></div>
</div>
<div id="regression-h2o-tune" class="section level4">
<h4><span class="header-section-number">3.4.2.2</span> Tuning</h4>
<p>As previously stated, a full grid search to identify the optimal alpha is not always necessary; changing its value to 0.5 (or 0 or 1 if we only want Ridge or Lasso, respectively) works in most cases. However, if a full grid search is desired then we need to supply our grid of alpha values in a list. We can then use <code>h2o.grid</code> to perform our grid search. The results show that <span class="math inline">\(\alpha = 0\)</span> (a full ridge penalty) performed best.</p>
<div class="rmdnote">
<p>
This grid search took 5 seconds to compute.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create hyperparameter grid</span>
hyper_params &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> .<span class="dv">1</span>))

<span class="co"># perform grid search</span>
grid &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> train_h2o, 
  <span class="dt">nfolds =</span> <span class="dv">10</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">algorithm =</span> <span class="st">&quot;glm&quot;</span>,
  <span class="dt">grid_id =</span> <span class="st">&quot;grid_search&quot;</span>, 
  <span class="dt">hyper_params =</span> hyper_params
)

<span class="co"># Sort the grid models by MSE</span>
sorted_grid &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(<span class="st">&quot;grid_search&quot;</span>, <span class="dt">sort_by =</span> <span class="st">&quot;mse&quot;</span>, <span class="dt">decreasing =</span> <span class="ot">FALSE</span>)
sorted_grid
## H2O Grid Details
## ================
## 
## Grid ID: grid_search 
## Used hyper parameters: 
##   -  alpha 
## Number of models: 11 
## Number of failed models: 0 
## 
## Hyper-Parameter Search Summary: ordered by increasing mse
##    alpha            model_ids                  mse
## 1  [0.0]  grid_search_model_0 0.022711429277773212
## 2  [0.6]  grid_search_model_6   0.0395992947950626
## 3  [0.7]  grid_search_model_7  0.03968294882574923
## 4  [1.0] grid_search_model_10  0.03983076501706063
## 5  [0.4]  grid_search_model_4    0.039850863900647
## 6  [0.8]  grid_search_model_8  0.03990607242146858
## 7  [0.3]  grid_search_model_3  0.04019054535587161
## 8  [0.5]  grid_search_model_5  0.04042328742741519
## 9  [0.9]  grid_search_model_9  0.04044324344598643
## 10 [0.2]  grid_search_model_2 0.041434990130949347
## 11 [0.1]  grid_search_model_1  0.04233746428242222</code></pre></div>
<p>We can check out more details of the best performing model. Our RMSE (0.1279) is an improvement on our default model (RMSE = 0.2015). Also, we can access the optimal model parameters, which show the optimal <span class="math inline">\(\lambda\)</span> value for our model was 0.0279.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># grab top model id</span>
best_h2o_model &lt;-<span class="st"> </span>sorted_grid<span class="op">@</span>model_ids[[<span class="dv">1</span>]]
best_model &lt;-<span class="st"> </span><span class="kw">h2o.getModel</span>(best_h2o_model)

<span class="co"># assess performance</span>
<span class="kw">h2o.mse</span>(best_model)
## [1] 0.0163625

<span class="kw">h2o.rmse</span>(best_model)
## [1] 0.127916

<span class="co"># get optimal parameters</span>
best_model<span class="op">@</span>parameters<span class="op">$</span>lambda
## [1] 0.02790355

best_model<span class="op">@</span>parameters<span class="op">$</span>alpha
## [1] 0</code></pre></div>
</div>
<div id="regression-h2o-viz" class="section level4">
<h4><span class="header-section-number">3.4.2.3</span> Visual interpretation</h4>
<p><strong>h2o</strong> provides a built-in function that plots variable importance. To compute variable importance for regularized models, <strong>h2o</strong> uses the standardized coefficient values (which is the same that we plotted in the <strong>glmnet</strong> example). You will notice that the the largest influential variables produced by this H2O model differ from the glmnet model. This is because we are assessing the ridge model here, where in the glmnet interpretation section we assessed the lasso and H2O and glmnet use differing approaches to generate the <span class="math inline">\(\lambda\)</span> search path. However, you will notice that both <code>Overall_Qual.Excellent</code> and <code>Overall_Cond.Fair</code> were also top influencers in the glmnet model suggesting they may have a strong signal regardless of the regularization penalty we use.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># get top 25 influential variables</span>
<span class="kw">h2o.varimp_plot</span>(best_model, <span class="dt">num_of_features =</span> <span class="dv">25</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:regress-h2o-vip-plot"></span>
<img src="images/regress-h2o-vip.png" alt="H2O's variable importance plot.  Provides the same output as plotting the standardized coefficients (`h2o.std_coef_plot`)." width="100%" height="100%" />
<p class="caption">
Figure 3.10: H2O’s variable importance plot. Provides the same output as plotting the standardized coefficients (<code>h2o.std_coef_plot</code>).
</p>
</div>
<p>Although H2O’s variable importance uses standardized coefficients, a convenient function of H2O is that you can extract the “normal” coefficients which are obtained from the standardized coefficients by reversing the data standardization process (de-scaled, with the intercept adjusted by an added offset) so that they can be applied to data in its original form (i.e. no standardization prior to scoring). For example, every one unit increase in pool size has a $1 decrease in sales price (since our response is log transformed we need to take the exponent <span class="math inline">\(e^{-0.000183} = 0.999817\)</span>).</p>
<div class="rmdwarning">
<p>
These are not the same as coefficients of a model built on non-standardized data.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">best_model<span class="op">@</span>model<span class="op">$</span>coefficients_table
## Coefficients: glm coefficients
##                              names coefficients standardized_coefficients
## 1                        Intercept   -47.473537                 11.713031
## 2 Neighborhood.Bloomington_Heights    -0.019249                 -0.019249
## 3             Neighborhood.Blueste     0.004638                  0.004638
## 4           Neighborhood.Briardale    -0.009169                 -0.009169
## 5           Neighborhood.Brookside     0.008538                  0.008538
## 
## ---
##         names coefficients standardized_coefficients
## 341 Pool_Area    -0.000183                 -0.005963
## 342  Misc_Val    -0.000038                 -0.022608
## 343   Mo_Sold     0.000444                  0.001224
## 344 Year_Sold    -0.007414                 -0.009728
## 345 Longitude    -0.303402                 -0.007786
## 346  Latitude     0.948544                  0.017592</code></pre></div>
<p>In the <strong>glmnet</strong> section we discussed how regularized regression assumes a monotonic linear relationship between the predictor variables and the response. The <em>linear</em> relationship part of that statement just means, for a given predictor variable, it assumes for every one unit change in a given predictor variable there is a constant change in the response. This constant change is given by the given coefficient for a predictor. The <em>monotonic</em> relationship means that a given predictor variable will always have a positive or negative relationship.</p>
<p>We can illustrate this with a partial dependence plot of the ground living area (square footage) variable. The PDP plot shows that the relationship is monotonic linear (assumes a constant increasing relationships). This PDP plot helps to show the typical values (and one standard error) of our response variable as the square footage of the ground floor living space increases.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># partial dependence plots for top 2 influential variables</span>
<span class="kw">h2o.partialPlot</span>(best_model, <span class="dt">data =</span> train_h2o, <span class="dt">cols =</span> <span class="st">&quot;Gr_Liv_Area&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:regress-h2o-pdp-plot"></span>
<img src="images/regress-h2o-pdp-living-area.png" alt="As the ground living area (square footage) of a home increases, we experience a constant increase in the mean predicted sale price." width="80%" height="80%" />
<p class="caption">
Figure 3.11: As the ground living area (square footage) of a home increases, we experience a constant increase in the mean predicted sale price.
</p>
</div>
<p>But what about the two most influential variables (<code>Overall_Qual.Excellent</code> and <code>Overall_Cond.Fair</code>)? These variables are a result of one-hot encoding the original overall quality (<code>Overall_Qual</code>) variable. We can assess a similar plot but must supply the original non-one-hot encoded variable name.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.partialPlot</span>(best_model, <span class="dt">data =</span> train_h2o, <span class="dt">cols =</span> <span class="st">&quot;Overall_Qual&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:regress-h2o-pdp-plot-2-output"></span>
<img src="images/regress-h2o-pdp-plot-2.png" alt="The mean predicted sale price for each level of the overall quality variable. Note how the plot does not align with the natural ordering of the predictor variable." width="90%" height="90%" />
<p class="caption">
Figure 3.12: The mean predicted sale price for each level of the overall quality variable. Note how the plot does not align with the natural ordering of the predictor variable.
</p>
</div>
<p>Unfortunately, H2O’s function plots the categorical levels in alphabetical order. Alternatively, we can extract the results and plot them in their proper level order to make inference more intuitive. The following shows the marginal effect of the overall quality variable on sales price. It illustrates an interesting finding - the highest and lowest categories do not have the largest marginal sales price effects. It also shows that a house with a <em>very good</em> overall quality has, on average, a $6K higher sale price than a house with only a <em>good</em> overall quality. Alternatively, homes with <em>below average</em> quality receive a substantially lower sale price than homes with <em>average</em> quality.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.partialPlot</span>(best_model, <span class="dt">data =</span> train_h2o, <span class="dt">cols =</span> <span class="st">&quot;Overall_Qual&quot;</span>, <span class="dt">plot =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">Overall_Qual =</span> <span class="kw">factor</span>(Overall_Qual, <span class="dt">levels =</span> <span class="kw">levels</span>(ames<span class="op">$</span>Overall_Qual)),
    <span class="dt">mean_response =</span> <span class="kw">exp</span>(mean_response)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(mean_response, Overall_Qual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">labels =</span> scales<span class="op">::</span>dollar) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Average response for each Overall Quality level&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:regress-h2o-pdp-plot-3-output"></span>
<img src="images/regress-h2o-pdp-plot-3.png" alt="The mean predicted sale price for each level of the overall quality variable. This plot now helps to illustrate how the mean predicted sale price changes based on the natural ordering of the overall quality predictor variable." width="100%" height="100%" />
<p class="caption">
Figure 3.13: The mean predicted sale price for each level of the overall quality variable. This plot now helps to illustrate how the mean predicted sale price changes based on the natural ordering of the overall quality predictor variable.
</p>
</div>
<div class="rmdnote">
<p>
See the model interpretation chapter for more details on variable importance and partial dependence plots.
</p>
</div>
</div>
<div id="regression-h2o-predict" class="section level4">
<h4><span class="header-section-number">3.4.2.4</span> Predicting</h4>
<p>Lastly, we can use <code>h2o.predict</code> and <code>h2o.performance</code> to predict and evaluate our models performance on our hold out test data. Similar to <strong>glmnet</strong>, we need to re-transform our predicted values to get a interpretable generalizable error. Our generalizable error is $24,147.60 which is about $1,000 lower than the <strong>glmnet</strong> model produced.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># make predictions</span>
pred &lt;-<span class="st"> </span><span class="kw">h2o.predict</span>(<span class="dt">object =</span> best_model, <span class="dt">newdata =</span> test_h2o)
<span class="kw">head</span>(pred)
##    predict
## 1 11.65765
## 2 11.48417
## 3 12.50938
## 4 12.32368
## 5 13.20056
## 6 12.69091

<span class="co"># assess performance</span>
<span class="kw">h2o.performance</span>(best_model, <span class="dt">newdata =</span> test_h2o)
## H2ORegressionMetrics: glm
## 
## MSE:  0.01364287
## RMSE:  0.1168027
## MAE:  0.0826363
## RMSLE:  0.009030871
## Mean Residual Deviance :  0.01364287
## R^2 :  0.915491
## Null Deviance :141.57
## Null D.o.F. :875
## Residual Deviance :11.95116
## Residual D.o.F. :530
## AIC :-582.0349

<span class="co"># convert predicted values to non-transformed</span>
caret<span class="op">::</span><span class="kw">RMSE</span>(<span class="kw">as.vector</span>(<span class="kw">exp</span>(pred)), ames_test<span class="op">$</span>Sale_Price)
## [1] 24147.6</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># shutdown h2o</span>
<span class="kw">h2o.removeAll</span>()
## [1] 0
<span class="kw">h2o.shutdown</span>(<span class="dt">prompt =</span> <span class="ot">FALSE</span>)
## [1] TRUE</code></pre></div>
</div>
</div>
</div>
<div id="glm-binary-classification" class="section level2">
<h2><span class="header-section-number">3.5</span> Implementation: Binary Classification</h2>
<p>To illustrate various regularization concepts for a binary classification problem we will use the employee attrition data, where the goal is to predict whether or not an employee attrits (“Yes” vs. “No”).</p>
<div class="rmdtip">
<p>
The easiest way to have consistent interpretable results is to recode the response as 1 for the positive class (“Yes”) and 0 for the other class (“No”).
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">attrition &lt;-<span class="st"> </span>rsample<span class="op">::</span>attrition <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Attrition =</span> <span class="kw">recode</span>(Attrition, <span class="st">&quot;Yes&quot;</span> =<span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;No&quot;</span> =<span class="st"> </span><span class="dv">0</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.ordered, factor, <span class="dt">ordered =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div id="classification-binary-glm-glmnet" class="section level3">
<h3><span class="header-section-number">3.5.1</span> <code>glmnet</code></h3>
<p>Similar to the regression application, for the classification data set we need to perfom some extra processing up-front to prepare for modeling with <strong>glmnet</strong>. First, many of the features are categorical; consequently, we need to either ordinal encode or one-hot encode these variables so that all features are numeric. Also, <strong>glmnet</strong> does not use the formula method (<code>y ~ x</code>) so prior to modeling we need to create our feature and target set and convert our features to a matrix.</p>
<div class="rmdtip">
<p>
Since our response variable is imbalanced, we use <code>rsample</code> and <code>strat</code> to perform stratified sampling so that both our training and testing data sets have similar proportion of response levels.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># one-hot encode our data with model.matrix</span>
one_hot &lt;-<span class="st"> </span><span class="kw">model.matrix</span>( <span class="op">~</span><span class="st"> </span>., attrition)[, <span class="op">-</span><span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()

<span class="co"># Create training and testing sets</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)
split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(one_hot, <span class="dt">prop =</span> .<span class="dv">8</span>, <span class="dt">strata =</span> <span class="st">&quot;Attrition&quot;</span>)
train &lt;-<span class="st"> </span><span class="kw">training</span>(split)
test  &lt;-<span class="st"> </span><span class="kw">testing</span>(split)

<span class="co"># separate features from response variable for glmnet</span>
train_x &lt;-<span class="st"> </span>train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Attrition) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()
train_y &lt;-<span class="st"> </span>train<span class="op">$</span>Attrition
test_x  &lt;-<span class="st"> </span>test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Attrition) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()
test_y  &lt;-<span class="st"> </span>test<span class="op">$</span>Attrition

<span class="co"># check that train &amp; test sets have common response ratio</span>
<span class="kw">table</span>(train_y) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">prop.table</span>()
## train_y
##         0         1 
## 0.8385726 0.1614274
<span class="kw">table</span>(test_y) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">prop.table</span>()
## test_y
##         0         1 
## 0.8395904 0.1604096</code></pre></div>
<div id="classification-binary-glmnet-basic" class="section level4">
<h4><span class="header-section-number">3.5.1.1</span> Basic implementation</h4>
<p>Similar to the regression problem, we apply a regularized classification model with <code>glmnet::glmnet()</code>. The primary difference is that for binary classification models we need to include <code>family = binomial</code>. Remember, the <code>alpha</code> parameter tells <strong>glmnet</strong> to perform a ridge (<code>alpha = 0</code>), lasso (<code>alpha = 1</code>), or elastic net (<span class="math inline">\(0 &lt; alpha &lt; 1\)</span>) model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Apply Ridge regression to attrition data</span>
ridge &lt;-<span class="st"> </span><span class="kw">glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
  <span class="dt">alpha =</span> <span class="dv">0</span>
)

<span class="kw">plot</span>(ridge, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-binary-class-ridge1"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-binary-class-ridge1-1.png" alt="Coefficients for our ridge regression model as $\lambda$ grows from  $0 \rightarrow \infty$." width="672" />
<p class="caption">
Figure 3.14: Coefficients for our ridge regression model as <span class="math inline">\(\lambda\)</span> grows from <span class="math inline">\(0 \rightarrow \infty\)</span>.
</p>
</div>
<p>We can also directly access the coefficients for a model using <code>coef</code> and tidy the output with <code>tidy</code>. Here, we check out the top 10 largest absolute coefficient terms when using the smallest and largest lambda values. We see that regardless of a large or small penalty parameter, working overtime and being a Sales Rep has the largest positive influence on the probability of attrition. Whereas being a Research Director and having high job involvement (among others) are the strongest influencers for reducing the probability of attrition.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># lambdas applied to penalty parameter</span>
ridge<span class="op">$</span>lambda <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()
## [1] 86.49535 78.81134 71.80996 65.43056 59.61789 54.32160

<span class="co"># small lambda results in large coefficients</span>
<span class="kw">coef</span>(ridge)[, <span class="dv">100</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(<span class="kw">abs</span>(x)))
## # A tibble: 58 x 2
##    names                                 x
##    &lt;chr&gt;                             &lt;dbl&gt;
##  1 OverTimeYes                       1.68 
##  2 JobInvolvementVery_High          -1.42 
##  3 JobRoleSales_Representative       1.35 
##  4 (Intercept)                       1.21 
##  5 BusinessTravelTravel_Frequently   1.17 
##  6 JobRoleResearch_Director         -1.05 
##  7 JobInvolvementHigh               -0.974
##  8 EnvironmentSatisfactionVery_High -0.951
##  9 JobSatisfactionVery_High         -0.932
## 10 WorkLifeBalanceBetter            -0.908
## # ... with 48 more rows

<span class="co"># large lambda results in small coefficients</span>
<span class="kw">coef</span>(ridge)[, <span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(<span class="kw">abs</span>(x))) 
## # A tibble: 58 x 2
##    names                                   x
##    &lt;chr&gt;                               &lt;dbl&gt;
##  1 (Intercept)                     -1.65e+ 0
##  2 JobRoleSales_Representative      2.62e-37
##  3 OverTimeYes                      1.95e-37
##  4 JobRoleResearch_Director        -1.55e-37
##  5 MaritalStatusSingle              1.39e-37
##  6 JobRoleManager                  -1.24e-37
##  7 BusinessTravelTravel_Frequently  1.16e-37
##  8 JobRoleLaboratory_Technician     9.16e-38
##  9 JobRoleManufacturing_Director   -8.95e-38
## 10 JobInvolvementVery_High         -7.66e-38
## # ... with 48 more rows</code></pre></div>
<p>However, at this point, we do not understand how much improvement we are experiencing in our loss function across various <span class="math inline">\(\lambda\)</span> values.</p>
</div>
<div id="classification-binaryglmnet-tune" class="section level4">
<h4><span class="header-section-number">3.5.1.2</span> Tuning</h4>
<p>Recall that <span class="math inline">\(\lambda\)</span> is a tuning parameter that helps to control our model from over-fitting to the training data. However, to identify the optimal <span class="math inline">\(\lambda\)</span> value we need to perform cross-validation with <code>cv.glmnet</code>. Here we perform a 10-fold CV glmnet model for both a ridge and lasso penalty.</p>
<div class="rmdnote">
<p>
By default, <code>cv.glmnet</code> uses deviance as the loss function for binomial classification but you could adjust <code>type.measure</code> to “auc”, “mse”, “mae”, or “class” (missclassification).
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Apply CV Ridge regression to attrition data</span>
ridge &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
  <span class="dt">alpha =</span> <span class="dv">0</span>
)

<span class="co"># Apply CV Ridge regression to attrition data</span>
lasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
  <span class="dt">alpha =</span> <span class="dv">1</span>
)

<span class="co"># plot results</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(ridge, <span class="dt">main =</span> <span class="st">&quot;Ridge penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(lasso, <span class="dt">main =</span> <span class="st">&quot;Lasso penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-binary-class-ridge-lasso-cv-models"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-binary-class-ridge-lasso-cv-models-1.png" alt="10-fold cross validation deviance for a ridge and lasso model. First dotted vertical line in each plot represents the $\lambda$ with the smallest deviance and the second represents the $\lambda$ with a deviance within one standard error of the minimum deviance." width="864" />
<p class="caption">
Figure 3.15: 10-fold cross validation deviance for a ridge and lasso model. First dotted vertical line in each plot represents the <span class="math inline">\(\lambda\)</span> with the smallest deviance and the second represents the <span class="math inline">\(\lambda\)</span> with a deviance within one standard error of the minimum deviance.
</p>
</div>
<p>Our plots above illustrate the 10-fold CV deviance across the <span class="math inline">\(\lambda\)</span> values. With the ridge model, we don’t see any improvement in the loss function as <span class="math inline">\(\lambda\)</span> increases but, with the lasso model, we see a slight improvement in the deviance as our penalty <span class="math inline">\(\lambda\)</span> gets larger, suggesting that a regular logistic regression model likely overfits our data. But as we constrain it further (continue to increase the penalty), our deviance starts to increase. The numbers at the top of the plot refer to the number of variables in the model. Ridge regression does not force any variables to exactly zero so all features will remain in the model but we see the number of variables retained in the lasso model go down as our penalty increases, with the optimal model containing between 38-48 predictor variables.</p>
<p>The first and second vertical dashed lines represent the <span class="math inline">\(\lambda\)</span> value with the minimum deviance and the largest <span class="math inline">\(\lambda\)</span> value within one standard error of the minimum deviance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Ridge model</span>
<span class="kw">min</span>(ridge<span class="op">$</span>cvm)       <span class="co"># minimum deviance</span>
## [1] 0.6483054
ridge<span class="op">$</span>lambda.min     <span class="co"># lambda for this min deviance</span>
## [1] 0.0104184

ridge<span class="op">$</span>cvm[ridge<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>ridge<span class="op">$</span>lambda.1se]  <span class="co"># 1 st.error of min deviance</span>
## [1] 0.6788463
ridge<span class="op">$</span>lambda.1se  <span class="co"># lambda for this deviance</span>
## [1] 0.04615997

<span class="co"># Lasso model</span>
<span class="kw">min</span>(lasso<span class="op">$</span>cvm)       <span class="co"># minimum deviance</span>
## [1] 0.6511349
lasso<span class="op">$</span>lambda.min     <span class="co"># lambda for this min deviance</span>
## [1] 0.001737893

lasso<span class="op">$</span>cvm[lasso<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>lasso<span class="op">$</span>lambda.1se]  <span class="co"># 1 st.error of min deviance</span>
## [1] 0.6737481
lasso<span class="op">$</span>lambda.1se  <span class="co"># lambda for this deviance</span>
## [1] 0.005307275</code></pre></div>
<p>We can assess this visually. Here we plot the coefficients across the <span class="math inline">\(\lambda\)</span> values and the dashed red line represents the <span class="math inline">\(\lambda\)</span> with the smallest deviance and the dashed blue line represents largest <span class="math inline">\(\lambda\)</span> that falls within one standard error of the minimum deviance. This shows you how much we can constrain the coefficients while still maximizing predictive accuracy.</p>
<div class="rmdtip">
<p>
Above, we saw that both ridge and lasso penalties provide similiar minimum deviance scores; however, these plots illustrate that ridge is still using all 57 variables whereas the lasso model can get a similar deviance by reducing our feature set from 57 down to 48. However, there will be some variability with this MSE and we can reasonably assume that we can achieve a similar MSE with a slightly more constrained model that uses only 38 features. Although this lasso model does not offer significant improvement over the ridge model, we get approximately the same accuracy by using only 38 features! If describing and interpreting the predictors is an important outcome of your analysis, this may significantly aid your endeavor.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Ridge model</span>
ridge_min &lt;-<span class="st"> </span><span class="kw">glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
  <span class="dt">alpha =</span> <span class="dv">0</span>
)

<span class="co"># Lasso model</span>
lasso_min &lt;-<span class="st"> </span><span class="kw">glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
  <span class="dt">alpha =</span> <span class="dv">1</span>
)

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="co"># plot ridge model</span>
<span class="kw">plot</span>(ridge_min, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Ridge penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(ridge<span class="op">$</span>lambda.min), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(ridge<span class="op">$</span>lambda.1se), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>)

<span class="co"># plot lasso model</span>
<span class="kw">plot</span>(lasso_min, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Lasso penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(lasso<span class="op">$</span>lambda.min), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(lasso<span class="op">$</span>lambda.1se), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-binary-class-ridge-lasso-cv-viz-results"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-binary-class-ridge-lasso-cv-viz-results-1.png" alt="Coefficients for our ridge and lasso models. First dotted vertical line in each plot represents the $\lambda$ with the smallest MSE and the second represents the $\lambda$ with an MSE within one standard error of the minimum MSE." width="864" />
<p class="caption">
Figure 3.16: Coefficients for our ridge and lasso models. First dotted vertical line in each plot represents the <span class="math inline">\(\lambda\)</span> with the smallest MSE and the second represents the <span class="math inline">\(\lambda\)</span> with an MSE within one standard error of the minimum MSE.
</p>
</div>
<p>So far we’ve implemented a pure ridge and pure lasso model. However, we can implement an elastic net the same way as the ridge and lasso models, by adjusting the <code>alpha</code> parameter. Any <code>alpha</code> value between 0-1 will perform an elastic net. When <code>alpha = 0.5</code> we perform an equal combination of penalties whereas <code>alpha</code> <span class="math inline">\(\rightarrow 0\)</span> will have a heavier ridge penalty applied and <code>alpha</code> <span class="math inline">\(\rightarrow 1\)</span> will have a heavier lasso penalty.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lasso    &lt;-<span class="st"> </span><span class="kw">glmnet</span>(train_x, train_y, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha =</span> <span class="fl">1.0</span>) 
elastic1 &lt;-<span class="st"> </span><span class="kw">glmnet</span>(train_x, train_y, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.25</span>) 
elastic2 &lt;-<span class="st"> </span><span class="kw">glmnet</span>(train_x, train_y, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.75</span>) 
ridge    &lt;-<span class="st"> </span><span class="kw">glmnet</span>(train_x, train_y, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.0</span>)

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>)
<span class="kw">plot</span>(lasso, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Lasso (Alpha = 1)</span><span class="ch">\n\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(elastic1, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Elastic Net (Alpha = .25)</span><span class="ch">\n\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(elastic2, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Elastic Net (Alpha = .75)</span><span class="ch">\n\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(ridge, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Ridge (Alpha = 0)</span><span class="ch">\n\n\n</span><span class="st">&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-binary-class-elastic-comparison"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-binary-class-elastic-comparison-1.png" alt="Coefficients for various penalty parameters." width="864" />
<p class="caption">
Figure 3.17: Coefficients for various penalty parameters.
</p>
</div>
<p>Often, the optimal model contains an <code>alpha</code> somewhere between 0-1, thus we want to tune both the <span class="math inline">\(\lambda\)</span> and the <code>alpha</code> parameters. As we did in the regression section, we create a common <code>fold_id</code>, which just allows us to apply the same CV folds to each model. We then create a tuning grid that searches across a range of <code>alpha</code>s from 0-1, and empty columns where we’ll dump our model results into.</p>
<div class="rmdwarning">
<p>
Use caution when including <span class="math inline"><span class="math inline">\(\alpha = 0\)</span></span> or <span class="math inline"><span class="math inline">\(\alpha = 1\)</span></span> in the grid search. <span class="math inline"><span class="math inline">\(\alpha = 0\)</span></span> will produce a dense solution and it can be very slow (or even impossible) to compute in large <em>N</em> situations. <span class="math inline"><span class="math inline">\(\alpha = 1\)</span></span> has no <span class="math inline"><span class="math inline">\(\ell_2\)</span></span> penalty, so it is therefore less numerically stable and can be very slow as well due to slower convergence. If you experience slow computation, we recommend searching across <span class="math inline"><span class="math inline">\(\alpha\)</span></span> values of 0.1, .25, .5, .75, .9.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># maintain the same folds across all models</span>
fold_id &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">size =</span> <span class="kw">length</span>(train_y), <span class="dt">replace=</span><span class="ot">TRUE</span>)

<span class="co"># search across a range of alphas</span>
tuning_grid &lt;-<span class="st"> </span>tibble<span class="op">::</span><span class="kw">tibble</span>(
  <span class="dt">alpha      =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> .<span class="dv">1</span>),
  <span class="dt">dev_min    =</span> <span class="ot">NA</span>,
  <span class="dt">dev_1se    =</span> <span class="ot">NA</span>,
  <span class="dt">lambda_min =</span> <span class="ot">NA</span>,
  <span class="dt">lambda_1se =</span> <span class="ot">NA</span>
)</code></pre></div>
<p>Now we can iterate over each <code>alpha</code> value, apply a CV elastic net, and extract the minimum and one standard error deviance values and their respective <span class="math inline">\(\lambda\)</span> values.</p>
<div class="rmdnote">
<p>
This grid search took 36 seconds.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Warning - this is not fast! See H2O section for faster approach</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_along</span>(tuning_grid<span class="op">$</span>alpha)) {
  
  <span class="co"># fit CV model for each alpha value</span>
  fit &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(
    train_x, 
    train_y, 
    <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
    <span class="dt">alpha =</span> tuning_grid<span class="op">$</span>alpha[i], 
    <span class="dt">foldid =</span> fold_id
    )
  
  <span class="co"># extract MSE and lambda values</span>
  tuning_grid<span class="op">$</span>dev_min[i]    &lt;-<span class="st"> </span>fit<span class="op">$</span>cvm[fit<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>fit<span class="op">$</span>lambda.min]
  tuning_grid<span class="op">$</span>dev_1se[i]    &lt;-<span class="st"> </span>fit<span class="op">$</span>cvm[fit<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>fit<span class="op">$</span>lambda.1se]
  tuning_grid<span class="op">$</span>lambda_min[i] &lt;-<span class="st"> </span>fit<span class="op">$</span>lambda.min
  tuning_grid<span class="op">$</span>lambda_1se[i] &lt;-<span class="st"> </span>fit<span class="op">$</span>lambda.1se
}

tuning_grid
## # A tibble: 11 x 5
##    alpha dev_min dev_1se lambda_min lambda_1se
##    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1   0     0.656   0.699    0.00949     0.0735
##  2   0.1   0.656   0.696    0.00685     0.0441
##  3   0.2   0.655   0.696    0.00599     0.0320
##  4   0.3   0.655   0.698    0.00481     0.0257
##  5   0.4   0.655   0.699    0.00434     0.0211
##  6   0.5   0.655   0.697    0.00381     0.0169
##  7   0.6   0.655   0.699    0.00349     0.0155
##  8   0.7   0.656   0.698    0.00299     0.0132
##  9   0.8   0.656   0.697    0.00287     0.0116
## 10   0.9   0.656   0.701    0.00255     0.0113
## 11   1     0.656   0.700    0.00230     0.0102</code></pre></div>
<p>If we plot the deviance ± one standard error for the optimal <span class="math inline">\(\lambda\)</span> value for each <code>alpha</code> setting, we see that they all fall within the same level of accuracy. Consequently, we could select a full lasso model (<code>alpha = 1</code>) with <span class="math inline">\(\lambda = 0.0023\)</span>, gain the benefits of its feature selection capability and reasonably assume no loss in accuracy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tuning_grid <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">se =</span> dev_1se <span class="op">-</span><span class="st"> </span>dev_min) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(alpha, dev_min)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymax =</span> dev_min <span class="op">+</span><span class="st"> </span>se, <span class="dt">ymin =</span> dev_min <span class="op">-</span><span class="st"> </span>se), <span class="dt">alpha =</span> .<span class="dv">25</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Deviance ± one standard error&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-binary-class-grid-search-results"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-binary-class-grid-search-results-1.png" alt="MSE ± one standard error for different alpha penalty parameters." width="384" />
<p class="caption">
Figure 3.18: MSE ± one standard error for different alpha penalty parameters.
</p>
</div>
</div>
<div id="classification-binary-glmnet-visualizing" class="section level4">
<h4><span class="header-section-number">3.5.1.3</span> Visual interpretation</h4>
<div id="variable-importance" class="section level5">
<h5><span class="header-section-number">3.5.1.3.1</span> Variable importance</h5>
<p>Similar to the regularized regression models, regularized classification models <strong><em>assume a monotonic linear relationship</em></strong> between the predictor variables and the response. The primary difference is in what the linear relationship means. For binary classification models, the linear relationship part of that statement just means, for a given predictor variable, it assumes for every one unit change in a given predictor variable there is a constant change in the <em>log-odds probability</em> of the response variable. This constant change is represented by the given coefficient for a predictor.</p>
<div class="rmdnote">
<p>
Log odds are an alternate way of expressing probabilities. The <em>odds</em> of a positive outcome are simply represented as <span class="math inline"><span class="math inline">\(\frac{prob(positive\_outcome)}{prob(negative\_outcome)}\)</span></span>. So if there is a .2 probability of an employee attriting, the odds ratio is <span class="math inline"><span class="math inline">\(.2 \div .8 = .25\)</span></span>. Consequently, the log odds for this employee is <span class="math inline"><span class="math inline">\(log(.25) = -1.386294\)</span></span>. An employee with 50% change of attriting has a log odds of <span class="math inline"><span class="math inline">\(log(.5 \div .5) = 0\)</span></span> so negative log odds means greater probability of not attriting and positive log odds means greater probability of attriting.
</p>
</div>
<p>Consequently, this makes understanding variable relationships simple with regularized models. Those variables with largest positive coefficients have the strongest influence on increasing the probability of attrition whereas those variables with the largest negative coefficients have the stongest influence on decreasing the probability of attrition.</p>
<p>I’ll illustrate with the following models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(train_x, train_y, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span>) 
ridge &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(train_x, train_y, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha =</span> <span class="dv">0</span>)</code></pre></div>
<p>Our ridge model will retain <bold><font color="red">all</font></bold> variables. Therefore, a ridge model is good if you believe there is a need to retain all features in your model yet reduce the noise that less influential variables may create and minimize multicollinearity. However, a ridge model does not perform feature selection but it will typically push most variables to near zero and allow the most influential variables to be more prominent. The following extracts the coefficients of our ridge model and plots predictor coefficients. You can see that some of the variables have coefficients closer to zero but there are also many variables that have a strong positive influence on the probability of attrition (i.e. <code>OverTimeYes</code>, <code>JobRoleSales_Representative</code>, <code>BusinessTravelTravel_Frequently</code>) and there are others that have a strong negative influence on the probability of attrition (i.e. <code>JobInvolvementVery_High</code>, <code>JobRoleResearch_Director</code>, <code>JobInvolvementHigh</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(ridge, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(row <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(value, <span class="kw">reorder</span>(row, value), <span class="dt">color =</span> value <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Influential variables (ridge penalty)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Coefficient&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="ot">NULL</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-binary-class-viz-ridge"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-binary-class-viz-ridge-1.png" alt="A ridge penalty will retain all variables but push many coefficients to near zero. Consequently, we retain any minor signals that all features provide but those coefficients with the largest absolute values represent the most influential predictors in our model." width="672" />
<p class="caption">
Figure 3.19: A ridge penalty will retain all variables but push many coefficients to near zero. Consequently, we retain any minor signals that all features provide but those coefficients with the largest absolute values represent the most influential predictors in our model.
</p>
</div>
<p>Similar to ridge, the lasso pushes many of the collinear features towards each other rather than allowing for one to be wildly positive and the other wildly negative. However, unlike ridge, the lasso will actually push coefficients to zero and perform feature selection. This simplifies and automates the process of identifying those features most influential to predictive accuracy. If we select the model with the minimum deviance and plot all variables in that model we see similar results to the ridge model regarding the most influential variables. However, the lasso model has pushed 9 variables to have zero coefficients and has retained the remaining 48, effectively performing automated feature selection.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(lasso, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(row <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(value, <span class="kw">reorder</span>(row, value), <span class="dt">color =</span> value <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Influential variables (lasso penalty)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Coefficient&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="ot">NULL</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-binary-classification-viz-lasso"></span>
<img src="03-regularized-glm-models_files/figure-html/glmnet-binary-classification-viz-lasso-1.png" alt="A lasso penalty will perform feature selection by pushing coefficients to zero. Consequently, we can view all coefficients to see which features were selected; however, our objective usually is still to identify those features with the strongest signal (largest absolute coefficient values)." width="672" />
<p class="caption">
Figure 3.20: A lasso penalty will perform feature selection by pushing coefficients to zero. Consequently, we can view all coefficients to see which features were selected; however, our objective usually is still to identify those features with the strongest signal (largest absolute coefficient values).
</p>
</div>
</div>
<div id="roc-curve" class="section level5">
<h5><span class="header-section-number">3.5.1.3.2</span> ROC curve</h5>
<p>We can visualize the ROC curve with the <code>ROCR</code> and <code>pROC</code> packages. Both packages compare the predicted log-odds output (<code>pred</code>) to the actual observed class. ROC curves become more interesting and useful when we compare multiple models, which we will see in later chapters.</p>
<div class="rmdwarning">
<p>
If you do not include <code>legacy.axes = TRUE</code> in the <code>plot()</code> call for the pROC curve, your x-axis will be reversed.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ROCR)
<span class="kw">library</span>(pROC)

<span class="co"># predict</span>
pred &lt;-<span class="st"> </span><span class="kw">predict</span>(ridge, <span class="dt">s =</span> ridge<span class="op">$</span>lambda.min, train_x)

<span class="co"># plot structure</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))

<span class="co"># ROCR plot</span>
<span class="kw">prediction</span>(pred, train_y) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">performance</span>(<span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>(<span class="dt">main =</span> <span class="st">&quot;ROCR ROC curve&quot;</span>)

<span class="co">#pROC plot</span>
<span class="kw">roc</span>(train_y, <span class="kw">as.vector</span>(pred)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>(<span class="dt">main =</span> <span class="st">&quot;pROC ROC curve&quot;</span>, <span class="dt">legacy.axes =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p><img src="03-regularized-glm-models_files/figure-html/glmnet-binary-classification-roc-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="classification-binary-glmnet-predict" class="section level4">
<h4><span class="header-section-number">3.5.1.4</span> Predicting</h4>
<p>Once you have identified your preferred model, you can simply use <code>predict</code> to predict the same model on a new data set. Two caveats:</p>
<ol style="list-style-type: decimal">
<li>You need to supply <code>predict</code> an <code>s</code> parameter with the preferred model’s <span class="math inline">\(\lambda\)</span> value. For example, here we create a lasso model, which provides me a minimum deviance of 0.648. We use the <span class="math inline">\(\lambda\)</span> for this model by specifying <code>s = cv_lasso$lambda.min</code>.</li>
<li>The default predicted values are the log odds. If you want the probability, include <code>type = &quot;response&quot;</code>.</li>
<li>If you want to predict the categorical response, include <code>type = &quot;class&quot;</code>.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># optimal model</span>
cv_lasso   &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(train_x, train_y, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha =</span> <span class="fl">1.0</span>)
<span class="kw">min</span>(cv_lasso<span class="op">$</span>cvm)
## [1] 0.6475805

<span class="co"># predict and get log-odds</span>
pred_log_odds &lt;-<span class="st"> </span><span class="kw">predict</span>(cv_lasso, <span class="dt">s =</span> cv_lasso<span class="op">$</span>lambda.min, test_x)
<span class="kw">head</span>(pred_log_odds)
##              1
## 2  -4.11789899
## 3   0.18751231
## 14 -3.26688392
## 25 -2.17385203
## 39  0.02202369
## 46 -4.44305986

<span class="co"># predict probability</span>
pred_probs &lt;-<span class="st"> </span><span class="kw">predict</span>(cv_lasso, <span class="dt">s =</span> cv_lasso<span class="op">$</span>lambda.min, test_x, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
<span class="kw">head</span>(pred_probs)
##             1
## 2  0.01601793
## 3  0.54674120
## 14 0.03672490
## 25 0.10212328
## 39 0.50550570
## 46 0.01162321

<span class="co"># predict and get predicted class</span>
pred_class &lt;-<span class="st"> </span><span class="kw">predict</span>(cv_lasso, <span class="dt">s =</span> cv_lasso<span class="op">$</span>lambda.min, test_x, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>)
<span class="kw">head</span>(pred_class)
##    1  
## 2  &quot;0&quot;
## 3  &quot;1&quot;
## 14 &quot;0&quot;
## 25 &quot;0&quot;
## 39 &quot;1&quot;
## 46 &quot;0&quot;</code></pre></div>
<p>Lastly, to assess various performance metrics on our test data we can use <code>caret::confusionMatrix</code>, which provides the majority of the performance measures we are typically concerned with in classification models. We can see that the no information rate is 0.8396. This represents the ratio of non-attrition to attrition rates. The goal is to increase prediction accuracy over and above this rate. We see that our overall accuracy is 0.887. The primary weakness in our model is that for many employees that attrit, we tend to predict non-attrit. This is illustrated by our low sensitivity.</p>
<div class="rmdtip">
<p>
The <code>positive</code> argument allows you to specify which value corresponds to the “positive” result. This will impact how you interpret certain metrics that are based on true positive and false negative results (i.e. sensitivity, specificity).
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(<span class="kw">factor</span>(pred_class), <span class="kw">factor</span>(test_y), <span class="dt">positive =</span> <span class="st">&quot;1&quot;</span>)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 238  25
##          1   8  22
##                                           
##                Accuracy : 0.8874          
##                  95% CI : (0.8455, 0.9212)
##     No Information Rate : 0.8396          
##     P-Value [Acc &gt; NIR] : 0.013017        
##                                           
##                   Kappa : 0.5102          
##  Mcnemar&#39;s Test P-Value : 0.005349        
##                                           
##             Sensitivity : 0.46809         
##             Specificity : 0.96748         
##          Pos Pred Value : 0.73333         
##          Neg Pred Value : 0.90494         
##              Prevalence : 0.16041         
##          Detection Rate : 0.07509         
##    Detection Prevalence : 0.10239         
##       Balanced Accuracy : 0.71778         
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre></div>
</div>
</div>
<div id="classification-binaryglm-h2o" class="section level3">
<h3><span class="header-section-number">3.5.2</span> <code>h2o</code></h3>
<p>To perform regularized logistic regression with <strong>h2o</strong>, we first need to initiate our <strong>h2o</strong> session.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">h2o<span class="op">::</span><span class="kw">h2o.no_progress</span>()
<span class="kw">h2o.init</span>(<span class="dt">max_mem_size =</span> <span class="st">&quot;5g&quot;</span>)
##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         3 seconds 203 milliseconds 
##     H2O cluster timezone:       America/New_York 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.18.0.11 
##     H2O cluster version age:    2 months and 13 days  
##     H2O cluster name:           H2O_started_from_R_bradboehmke_fmw129 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   4.44 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.5.1 (2018-07-02)</code></pre></div>
<p>Next, we do not need to one-hot encode or standardize our variables as <strong>h2o</strong> will do this for us. However, we do need to convert our training and test data to <strong>h2o</strong> objects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create training and testing sets</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)
split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(attrition, <span class="dt">prop =</span> .<span class="dv">8</span>, <span class="dt">strata =</span> <span class="st">&quot;Attrition&quot;</span>)
train &lt;-<span class="st"> </span><span class="kw">training</span>(split)
test  &lt;-<span class="st"> </span><span class="kw">testing</span>(split)

<span class="co"># convert training data to h2o object</span>
train_h2o &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(train)

<span class="co"># convert test data to h2o object</span>
test_h2o &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(test)

<span class="co"># set the response column to Attrition</span>
response &lt;-<span class="st"> &quot;Attrition&quot;</span>

<span class="co"># set the predictor names</span>
predictors &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(train), <span class="st">&quot;Attrition&quot;</span>)</code></pre></div>
<div id="h2o-glm-classification-binary-basic" class="section level4">
<h4><span class="header-section-number">3.5.2.1</span> Basic implementation</h4>
<p>Similar to our regression problem, we use <code>h2o.glm</code> to perform a regularized logistic regression model. The primary difference is that we need to set <code>family = &quot;binomial&quot;</code> to signal a binary classification problem. As before, by default, <code>h2o.glm</code> performs an elastic net model with <code>alpha = .5</code> and will perform an automated search across internally generated lambda values.</p>
<p>The following performs a default <code>h2o.glm</code> model with <code>alpha = .5</code> and it performs a 10 fold cross validation (<code>nfolds = 10</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># train your model, where you specify alpha (performs 10-fold CV)</span>
h2o_fit1 &lt;-<span class="st"> </span><span class="kw">h2o.glm</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> train_h2o,
  <span class="dt">nfolds =</span> <span class="dv">10</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">alpha =</span> .<span class="dv">5</span>, 
  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>
)

<span class="co"># print the MSE and AUC for the validation data</span>
<span class="kw">h2o.mse</span>(h2o_fit1, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## [1] 0.09739988

<span class="kw">h2o.auc</span>(h2o_fit1, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## [1] 0.8345038</code></pre></div>
<p>We can check out the cross-validated performance results of our model with <code>h2o.performance</code>. You can also get more results information using <code>summary(h2o_fit1)</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.performance</span>(h2o_fit1, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## H2OBinomialMetrics: glm
## ** Reported on cross-validation data. **
## ** 10-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.09739988
## RMSE:  0.3120895
## LogLoss:  0.3347975
## Mean Per-Class Error:  0.258244
## AUC:  0.8345038
## Gini:  0.6690076
## R^2:  0.2804837
## Residual Deviance:  788.1133
## AIC:  914.1133
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          0   1    Error       Rate
## 0      898  89 0.090172    =89/987
## 1       81 109 0.426316    =81/190
## Totals 979 198 0.144435  =170/1177
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold    value idx
## 1                       max f1  0.351656 0.561856 156
## 2                       max f2  0.127301 0.631939 267
## 3                 max f0point5  0.497019 0.608696 105
## 4                 max accuracy  0.728176 0.875106  54
## 5                max precision  0.989718 1.000000   0
## 6                   max recall  0.001056 1.000000 396
## 7              max specificity  0.989718 1.000000   0
## 8             max absolute_mcc  0.497019 0.478350 105
## 9   max min_per_class_accuracy  0.140575 0.757852 257
## 10 max mean_per_class_accuracy  0.234064 0.762571 209</code></pre></div>
</div>
<div id="glm-h2o-classification-binary-tune" class="section level4">
<h4><span class="header-section-number">3.5.2.2</span> Tuning</h4>
<p>Next, we’ll use <code>h2o.grid</code> to perform our grid search. The results show that <span class="math inline">\(\alpha = .1\)</span> performed best; however, the improvement is marginal.</p>
<div class="rmdnote">
<p>
This grid search took 7 seconds.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create hyperparameter grid</span>
hyper_params &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> .<span class="dv">1</span>))

<span class="co"># perform grid search</span>
grid &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> train_h2o, 
  <span class="dt">nfolds =</span> <span class="dv">10</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">algorithm =</span> <span class="st">&quot;glm&quot;</span>,
  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
  <span class="dt">grid_id =</span> <span class="st">&quot;grid_search_glm_classification&quot;</span>, 
  <span class="dt">hyper_params =</span> hyper_params
)

<span class="co"># Sort the grid models by MSE</span>
sorted_grid &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(<span class="st">&quot;grid_search_glm_classification&quot;</span>, <span class="dt">sort_by =</span> <span class="st">&quot;logloss&quot;</span>, <span class="dt">decreasing =</span> <span class="ot">FALSE</span>)
sorted_grid
## H2O Grid Details
## ================
## 
## Grid ID: grid_search_glm_classification 
## Used hyper parameters: 
##   -  alpha 
## Number of models: 11 
## Number of failed models: 0 
## 
## Hyper-Parameter Search Summary: ordered by increasing logloss
##    alpha                               model_ids            logloss
## 1  [0.1]  grid_search_glm_classification_model_1 0.32729191697214505
## 2  [0.4]  grid_search_glm_classification_model_4  0.3308752559420129
## 3  [0.2]  grid_search_glm_classification_model_2 0.33248215525410824
## 4  [0.8]  grid_search_glm_classification_model_8 0.33249327956862135
## 5  [0.7]  grid_search_glm_classification_model_7  0.3348307314321876
## 6  [0.5]  grid_search_glm_classification_model_5  0.3354479575686281
## 7  [1.0] grid_search_glm_classification_model_10 0.33563334658821187
## 8  [0.3]  grid_search_glm_classification_model_3 0.33779138839826356
## 9  [0.0]  grid_search_glm_classification_model_0   0.338497245432312
## 10 [0.6]  grid_search_glm_classification_model_6 0.33925009415446955
## 11 [0.9]  grid_search_glm_classification_model_9 0.33927152577597053</code></pre></div>
<p>We can check out more details of the best performing model. Our AUC (.84) is no better than our default cross-validated model. We can also extract other model parameters, which show the optimal <span class="math inline">\(\lambda\)</span> value for our model was 0.0006.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># grab top model id</span>
best_h2o_model &lt;-<span class="st"> </span>sorted_grid<span class="op">@</span>model_ids[[<span class="dv">1</span>]]
best_model &lt;-<span class="st"> </span><span class="kw">h2o.getModel</span>(best_h2o_model)

<span class="co"># assess performance</span>
<span class="kw">h2o.mse</span>(best_model, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## [1] 0.09538328

<span class="kw">h2o.auc</span>(best_model, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## [1] 0.8384072

<span class="co"># get optimal parameters</span>
best_model<span class="op">@</span>parameters<span class="op">$</span>lambda
## [1] 0.0006111815

best_model<span class="op">@</span>parameters<span class="op">$</span>alpha
## [1] 0.1</code></pre></div>
</div>
<div id="glm-h2o-classification-binary-viz" class="section level4">
<h4><span class="header-section-number">3.5.2.3</span> Visual Interpretation</h4>
<div id="variable-importance-1" class="section level5">
<h5><span class="header-section-number">3.5.2.3.1</span> Variable importance</h5>
<p>To identify the most influential variables we can use <strong>h2o</strong>’s variable importance plot. Recall that for a GLM model, variable importance is simply represented by the standardized coefficients. We see that <code>JobInvolvement.Low</code> and <code>JobRole.Sales_Representative</code> have the largest influence in increasing the probability of attrition whereas <code>JobRole.Research_Director</code> and <code>OverTime.No</code> have the largest influence in decreasing the probability of attrition.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># get top 25 influential variables</span>
<span class="kw">h2o.varimp_plot</span>(best_model, <span class="dt">num_of_features =</span> <span class="dv">25</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glm-h2o-classification-binary-vip-plot"></span>
<img src="images/binary-class-h2o-vip.png" alt="H2O's variable importance plot.  Provides the same output as plotting the standardized coefficients (`h2o.std_coef_plot`)." width="100%" height="100%" />
<p class="caption">
Figure 3.21: H2O’s variable importance plot. Provides the same output as plotting the standardized coefficients (<code>h2o.std_coef_plot</code>).
</p>
</div>
<p>To illustrate how the predicted response changes based on these influential variables, we can leverage the partial dependence inforamtion. For example, we can assess the partial dependence plots of the <code>JobInvolvement</code> predictor which shows up at the top of our variable importance plot. We see that mean predicted probability of attrition increases as job involvement decreases; but we can also see the significant increase in probability when an employee has a low job involvement.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># partial dependence plots for top 2 influential variables</span>
<span class="kw">h2o.partialPlot</span>(best_model, <span class="dt">data =</span> train_h2o, <span class="dt">cols =</span> <span class="st">&quot;JobInvolvement&quot;</span>, <span class="dt">plot =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">JobInvolvement =</span> <span class="kw">factor</span>(JobInvolvement, <span class="dt">levels =</span> <span class="kw">levels</span>(attrition<span class="op">$</span>JobInvolvement))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(JobInvolvement, mean_response)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Average predicted probability of attrition&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glm-h2o-classification-binary-pdp-plot"></span>
<img src="images/binary-class-h2o-pdp.png" alt="There is a significant increase in the predicted probability of attrition as an employee's level of job involvement decreases to a low level." width="80%" height="80%" />
<p class="caption">
Figure 3.22: There is a significant increase in the predicted probability of attrition as an employee’s level of job involvement decreases to a low level.
</p>
</div>
<p>Similarly, for a continuous variable, we can assess the PDP. For example, age is one of the few continuous predictor variables in this data set and we see that our regularized logistic regression model predicts a continuously decreasing probability of attrition as employees get older.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.partialPlot</span>(best_model, <span class="dt">data =</span> train_h2o, <span class="dt">cols =</span> <span class="st">&quot;Age&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glm-h2o-classification-binary-pdp-plot2"></span>
<img src="images/binary-class-h2o-pdp2.png" alt="As an employee gets older, the predicted probability of attrition decreases." width="100%" height="100%" />
<p class="caption">
Figure 3.23: As an employee gets older, the predicted probability of attrition decreases.
</p>
</div>
</div>
<div id="roc-curve-1" class="section level5">
<h5><span class="header-section-number">3.5.2.3.2</span> ROC curve</h5>
<p>Earlier, we saw that this model produced a 10-fold CV AUC of .84. We can visualize this by plotting the ROC curve using the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.performance</span>(best_model, <span class="dt">xval =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glm-h2o-classification-binary-roc-plot"></span>
<img src="images/glm-binary-class-h2o-roc.png" alt="ROC curve for our best performing regularized H2O GLM model." width="80%" height="80%" />
<p class="caption">
Figure 3.24: ROC curve for our best performing regularized H2O GLM model.
</p>
</div>
</div>
</div>
<div id="glm-h2o-classification-binary-predict" class="section level4">
<h4><span class="header-section-number">3.5.2.4</span> Predicting</h4>
<p>Lastly, we can use <code>h2o.predict</code> and <code>h2o.performance</code> to predict and evaluate our models performance on our hold out test data. Note how the <code>h2o.predict</code> function provides 3 columns - the predicted class and the probability of each class. We also produce our test set performance results with <code>h2o.performance</code>. If you compare the confusion matrix with the one produced by <strong>glmnet</strong> you will notice they produce very similar results. The <strong>h2o</strong> model does a slightly better job predicting true attrition but also does slightly worse in false positives.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># make predictions</span>
pred &lt;-<span class="st"> </span><span class="kw">h2o.predict</span>(<span class="dt">object =</span> best_model, <span class="dt">newdata =</span> test_h2o)
<span class="kw">head</span>(pred)
##   predict        p0          p1
## 1       0 0.9921441 0.007855913
## 2       1 0.4230720 0.576927982
## 3       0 0.9724310 0.027569028
## 4       0 0.9093784 0.090621612
## 5       1 0.4451610 0.554838982
## 6       0 0.9863366 0.013663436

<span class="co"># assess performance</span>
<span class="kw">h2o.performance</span>(best_model, <span class="dt">newdata =</span> test_h2o)
## H2OBinomialMetrics: glm
## 
## MSE:  0.0936628
## RMSE:  0.3060438
## LogLoss:  0.328802
## Mean Per-Class Error:  0.2543678
## AUC:  0.8418959
## Gini:  0.6837917
## R^2:  0.3045444
## Residual Deviance:  192.678
## AIC:  324.678
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          0  1    Error     Rate
## 0      236 10 0.040650  =10/246
## 1       22 25 0.468085   =22/47
## Totals 258 35 0.109215  =32/293
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold    value idx
## 1                       max f1  0.499766 0.609756  34
## 2                       max f2  0.215378 0.690299  79
## 3                 max f0point5  0.600664 0.677419  26
## 4                 max accuracy  0.600664 0.890785  26
## 5                max precision  0.991619 1.000000   0
## 6                   max recall  0.003581 1.000000 274
## 7              max specificity  0.991619 1.000000   0
## 8             max absolute_mcc  0.499766 0.555889  34
## 9   max min_per_class_accuracy  0.215378 0.787234  79
## 10 max mean_per_class_accuracy  0.215378 0.806219  79</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># shutdown h2o</span>
<span class="kw">h2o.removeAll</span>()
## [1] 0
<span class="kw">h2o.shutdown</span>(<span class="dt">prompt =</span> <span class="ot">FALSE</span>)</code></pre></div>
</div>
</div>
</div>
<div id="glm-multinomial-classification" class="section level2">
<h2><span class="header-section-number">3.6</span> Implementation: Multinomial Classification</h2>
<p>To illustrate various regularization concepts for a multinomial classification problem we will use the mnist data, where the goal is to predict handwritten numbers ranging from 0-9.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># import mnist training and testing data</span>
train &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(<span class="st">&quot;../data/mnist_train.csv&quot;</span>, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)
test &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(<span class="st">&quot;../data/mnist_test.csv&quot;</span>, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div id="classification-multi-glm-glmnet" class="section level3">
<h3><span class="header-section-number">3.6.1</span> <code>glmnet</code></h3>
<p>Since the mnist data contains all numeric predictors (darkness density ranging from 0-255), we do not need to one-hot encode our feature set. Consequently, we only need to convert our features into a matrix and seperate the response variable (<code>V785</code>). For a multinomial problem our response needs to be either discrete integer values or set as a factor. Since our response values are discrete integer values from 0-9 we can leave them as is.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># separate features from response variable for glmnet</span>
train_x &lt;-<span class="st"> </span>train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>V785) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()
train_y &lt;-<span class="st"> </span>train<span class="op">$</span>V785
test_x  &lt;-<span class="st"> </span>test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>V785) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()
test_y  &lt;-<span class="st"> </span>test<span class="op">$</span>V785

<span class="co"># check the response ratios across the train &amp; test sets</span>
<span class="kw">table</span>(train_y) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">prop.table</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)
## train_y
##    0    1    2    3    4    5    6    7    8    9 
## 0.10 0.11 0.10 0.10 0.10 0.09 0.10 0.10 0.10 0.10
<span class="kw">table</span>(test_y) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">prop.table</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)
## test_y
##    0    1    2    3    4    5    6    7    8    9 
## 0.10 0.11 0.10 0.10 0.10 0.09 0.10 0.10 0.10 0.10</code></pre></div>
<div id="classification-multi-glmnet-basic" class="section level4">
<h4><span class="header-section-number">3.6.1.1</span> Basic implementation</h4>
<p>To perform a regularized multinomial GLM, we simply change the <code>family</code> parameter to “multinomial”. In this example we perform a full ridge penalty (<code>alpha = 0</code>) model. One difference with a multinomial model is that when you plot the model results, rather than seeing only one plot with the coefficient values across the spectrum of <span class="math inline">\(\lambda\)</span> values, you will get an individual plot for the coefficients for each response category.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Apply Ridge regression to mnist data</span>
ridge &lt;-<span class="st"> </span><span class="kw">glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;multinomial&quot;</span>,
  <span class="dt">alpha =</span> <span class="dv">0</span>
)

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">5</span>))
<span class="kw">plot</span>(ridge, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-class-multi-ridge-coef"></span>
<img src="images/glmnet-class-multi-ridge-coef.png" alt="Coefficients for each multinomial response as $\lambda$ grows from  $0 \rightarrow \infty$." width="100%" height="100%" />
<p class="caption">
Figure 3.25: Coefficients for each multinomial response as <span class="math inline">\(\lambda\)</span> grows from <span class="math inline">\(0 \rightarrow \infty\)</span>.
</p>
</div>
<p>Also, the coefficients are stored in a list separated by the response category. We can access these coefficients in a similar manner as we did the regression and binary classification coefficients; however, we need to index for the response category of interest. For example, the following gets the coefficients for response category “9” (note the indexing: <code>coef(ridge)$<code>9</code></code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># coefficients for response &quot;9&quot; with small lambda penalty</span>
<span class="kw">coef</span>(ridge)<span class="op">$</span><span class="st">`</span><span class="dt">9</span><span class="st">`</span>[, <span class="dv">100</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(<span class="kw">abs</span>(x)))
## # A tibble: 785 x 2
##    names       x
##    &lt;chr&gt;   &lt;dbl&gt;
##  1 &quot;&quot;    -0.428 
##  2 V170  -0.0762
##  3 V753   0.0505
##  4 V703   0.0345
##  5 V780  -0.0317
##  6 V732   0.0264
##  7 V726   0.0246
##  8 V505   0.0220
##  9 V421  -0.0147
## 10 V225  -0.0139
## # ... with 775 more rows

<span class="co"># coefficients for response &quot;9&quot; with small lambda penalty</span>
<span class="kw">coef</span>(ridge)<span class="op">$</span><span class="st">`</span><span class="dt">9</span><span class="st">`</span>[, <span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(<span class="kw">abs</span>(x)))
## # A tibble: 785 x 2
##    names         x
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 &quot;&quot;    -7.12e- 3
##  2 V753   3.18e-38
##  3 V732   2.39e-38
##  4 V170  -1.69e-38
##  5 V16   -1.11e-38
##  6 V703   8.13e-39
##  7 V533  -6.68e-39
##  8 V505   6.46e-39
##  9 V33   -6.26e-39
## 10 V752   4.64e-39
## # ... with 775 more rows</code></pre></div>
</div>
<div id="classification-multi-glmnet-tune" class="section level4">
<h4><span class="header-section-number">3.6.1.2</span> Tuning</h4>
<p>Recall that <span class="math inline">\(\lambda\)</span> is a tuning parameter that helps to control our model from over-fitting to the training data. However, to identify the optimal <span class="math inline">\(\lambda\)</span> value we need to perform cross-validation with <code>cv.glmnet</code> as we did with the regression and binary classification examples. However, due to the magnitude of the data slowing <strong>glmnet</strong> down, rather than perform a full grid search across many alpha settings we only perform a 5-fold CV glmnet model for three alpha values: 1 (ridge), 0.5 (elastic net), and 2 (lasso).</p>
<div class="rmdwarning">
<p>
As your data set increases, <strong>glmnet</strong> begins to slow down considerably compared to <strong>h2o</strong>. Consequently, I reduced <em>k</em> to a 5-fold CV; however, to run a single 5-fold CV on this training set still took 109 minutes! If you parallelize the process with <code>parallel = TRUE</code> (which requires you to use <strong>doMC</strong> or some other parallelizer) you can achieve some speed improvements.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
<span class="co"># parallelize the process</span>
<span class="kw">library</span>(doMC)
<span class="kw">registerDoMC</span>(<span class="dt">cores =</span> <span class="dv">4</span>)

<span class="co"># Apply CV Ridge regression to mnist data</span>
ridge &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;multinomial&quot;</span>,
  <span class="dt">alpha =</span> <span class="dv">0</span>,
  <span class="dt">nfolds =</span> <span class="dv">5</span>,
  <span class="dt">parallel =</span> <span class="ot">TRUE</span>
)

<span class="co"># Apply CV elastic net regression to mnist data</span>
elastic &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;multinomial&quot;</span>,
  <span class="dt">alpha =</span> .<span class="dv">5</span>,
  <span class="dt">nfolds =</span> <span class="dv">5</span>,
  <span class="dt">parallel =</span> <span class="ot">TRUE</span>
)

<span class="co"># Apply CV lasso regression to mnist data</span>
lasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(
  <span class="dt">x =</span> train_x,
  <span class="dt">y =</span> train_y,
  <span class="dt">family =</span> <span class="st">&quot;multinomial&quot;</span>,
  <span class="dt">alpha =</span> <span class="dv">1</span>,
  <span class="dt">nfolds =</span> <span class="dv">5</span>,
  <span class="dt">parallel =</span> <span class="ot">TRUE</span>
)

<span class="co"># plot results</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))
<span class="kw">plot</span>(ridge, <span class="dt">main =</span> <span class="st">&quot;Ridge penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(elastic, <span class="dt">main =</span> <span class="st">&quot;Elastic net penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)
<span class="kw">plot</span>(lasso, <span class="dt">main =</span> <span class="st">&quot;Lasso penalty</span><span class="ch">\n\n</span><span class="st">&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-multi-class-ridge-lasso-cv-models-plot"></span>
<img src="images/multinomial-3way-deviance-plot.png" alt="5-fold cross validation deviance for a ridge, lasso, and elastic net model. First dotted vertical line in each plot represents the $\lambda$ with the smallest deviance and the second represents the $\lambda$ with a deviance within one standard error of the minimum deviance." width="100%" height="100%" />
<p class="caption">
Figure 3.26: 5-fold cross validation deviance for a ridge, lasso, and elastic net model. First dotted vertical line in each plot represents the <span class="math inline">\(\lambda\)</span> with the smallest deviance and the second represents the <span class="math inline">\(\lambda\)</span> with a deviance within one standard error of the minimum deviance.
</p>
</div>
<div class="rmdnote">
<p>
Note how the top of the ridge penalty deviance plot indicates only 717 of the 784 predictors are in the model. The reason for this is <strong>not</strong> because the ridge model pushed 67 coefficients to zero because a ridge model does not do that. Rather, there are 67 predictors that have zero variance so they are not included in the model (see this with <code>preProcess(train_x, “zv”)</code>).
</p>
</div>
<p>In the performance plots in Figure <a href="regularized-regression.html#fig:glmnet-multi-class-ridge-lasso-cv-models-plot">3.26</a> it is difficult to see if the models differ in their minimum error rate (multinomial deviance). But if we look at the minimum deviance (and the largest deviance within one standard error) in the below code chunk, we see that the elastic net provides the optimal performance. Consequently, it appears we could use between 250-300 of the 784 predictors and still achieve optimal performance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Ridge model</span>
<span class="kw">min</span>(ridge<span class="op">$</span>cvm)       <span class="co"># minimum deviance</span>
## [1] 0.6194693
ridge<span class="op">$</span>cvm[ridge<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>ridge<span class="op">$</span>lambda.1se]  <span class="co"># 1 st.error of min deviance</span>
## [1] 0.6194693

<span class="co"># Elastic net model</span>
<span class="kw">min</span>(elastic<span class="op">$</span>cvm)       <span class="co"># minimum deviance</span>
## [1] 0.5627915
elastic<span class="op">$</span>cvm[elastic<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>elastic<span class="op">$</span>lambda.1se]  <span class="co"># 1 st.error of min deviance</span>
## [1] 0.5682305

<span class="co"># Lasso model</span>
<span class="kw">min</span>(lasso<span class="op">$</span>cvm)       <span class="co"># minimum deviance</span>
## [1] 0.6557272
lasso<span class="op">$</span>cvm[lasso<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>lasso<span class="op">$</span>lambda.1se]  <span class="co"># 1 st.error of min deviance</span>
## [1] 0.6557272</code></pre></div>
<p>So the elastic net model is minimizing the multinomial deviance loss function, but how does this translate to the accuracy of this model? We can assess the confusion matrix for this data on the training data. At first glance, the confusion matrix is difficult to discern differences. However, looking at the class statistics and specifically the sensitivity and specificity we can extract some useful insights. First, the specificity is 0.99 across all numbers indicating that the model does well in classifying non-events (basically, no number has a significantly higher false positive rate than the other numbers).</p>
<p>Second, looking at the sensitivity, we can see that our model does the best at accurately predicting the numbers 0, 1, and 6. However, it does worst at accurately predicting the numbers 2, 3, 5, 8, and 9. The number 8 has the lowest sensitivity rate and when we look at the confusion matrix we can see that our model often classifies the number 8 as the numbers 5, 3, and 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_class &lt;-<span class="st"> </span><span class="kw">predict</span>(elastic, <span class="dt">s =</span> elastic<span class="op">$</span>lambda.min, train_x, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>)
caret<span class="op">::</span><span class="kw">confusionMatrix</span>(<span class="kw">factor</span>(pred_class), <span class="kw">factor</span>(test_y))
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1    2    3    4    5    6    7    8    9
##          0 5780    1   26   16   11   43   27   10   28   19
##          1    1 6580   48   28   27   20   15   25  115   25
##          2   16   33 5452  126   24   38   33   59   56   14
##          3    8   15   84 5547    9  145    0   19  125   78
##          4   10    6   65    8 5506   50   30   47   26  135
##          5   27   23   19  181    9 4882   69   10  129   36
##          6   34    3   57   17   45   80 5714    3   36    2
##          7    5   13   67   47   13   16    2 5911   15  157
##          8   36   58  120  114   31  109   26   15 5251   41
##          9    6   10   20   47  167   38    2  166   70 5442
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9344          
##                  95% CI : (0.9324, 0.9364)
##     No Information Rate : 0.1124          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9271          
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: 0 Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8 Class: 9
## Sensitivity           0.97586   0.9760  0.91507  0.90475  0.94249  0.90057  0.96553  0.94350  0.89745  0.91478
## Specificity           0.99665   0.9943  0.99262  0.99103  0.99304  0.99078  0.99488  0.99377  0.98984  0.99027
## Pos Pred Value        0.96964   0.9558  0.93181  0.91990  0.93592  0.90659  0.95376  0.94637  0.90519  0.91186
## Neg Pred Value        0.99735   0.9970  0.99066  0.98918  0.99379  0.99013  0.99622  0.99341  0.98893  0.99062
## Prevalence            0.09872   0.1124  0.09930  0.10218  0.09737  0.09035  0.09863  0.10442  0.09752  0.09915
## Detection Rate        0.09633   0.1097  0.09087  0.09245  0.09177  0.08137  0.09523  0.09852  0.08752  0.09070
## Detection Prevalence  0.09935   0.1147  0.09752  0.10050  0.09805  0.08975  0.09985  0.10410  0.09668  0.09947
## Balanced Accuracy     0.98625   0.9851  0.95384  0.94789  0.96776  0.94568  0.98020  0.96863  0.94365  0.95252</code></pre></div>
</div>
<div id="classification-multi-glmnet-visualizing" class="section level4">
<h4><span class="header-section-number">3.6.1.3</span> Visual interpretation</h4>
<p>Interpreting the underlying predictor mechanisms with a multinomial problem is much like the regression and binary classification problems but with a few extra nuances. The first thing to remember is that although we started with 784 predictors, our full ridge model only used 717 because 67 predictors had zero variance. This is not unique to multinomial problems but its important to understand which variables these are because, in an organizational situation, we can assess whether or not we should continue collecting this information. In this example, they primarily represent pixels along the very edge of the images.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># zero variance predictor variables that offer no potential signal</span>
<span class="kw">names</span>(<span class="kw">which</span>(<span class="kw">sapply</span>(train, var) <span class="op">==</span><span class="st"> </span><span class="dv">0</span>))
##  [1] &quot;V1&quot;   &quot;V2&quot;   &quot;V3&quot;   &quot;V4&quot;   &quot;V5&quot;   &quot;V6&quot;   &quot;V7&quot;   &quot;V8&quot;   &quot;V9&quot;   &quot;V10&quot;  &quot;V11&quot; 
## [12] &quot;V12&quot;  &quot;V17&quot;  &quot;V18&quot;  &quot;V19&quot;  &quot;V20&quot;  &quot;V21&quot;  &quot;V22&quot;  &quot;V23&quot;  &quot;V24&quot;  &quot;V25&quot;  &quot;V26&quot; 
## [23] &quot;V27&quot;  &quot;V28&quot;  &quot;V29&quot;  &quot;V30&quot;  &quot;V31&quot;  &quot;V32&quot;  &quot;V53&quot;  &quot;V54&quot;  &quot;V55&quot;  &quot;V56&quot;  &quot;V57&quot; 
## [34] &quot;V58&quot;  &quot;V83&quot;  &quot;V84&quot;  &quot;V85&quot;  &quot;V86&quot;  &quot;V112&quot; &quot;V113&quot; &quot;V141&quot; &quot;V142&quot; &quot;V169&quot; &quot;V477&quot;
## [45] &quot;V561&quot; &quot;V645&quot; &quot;V646&quot; &quot;V672&quot; &quot;V673&quot; &quot;V674&quot; &quot;V700&quot; &quot;V701&quot; &quot;V702&quot; &quot;V728&quot; &quot;V729&quot;
## [56] &quot;V730&quot; &quot;V731&quot; &quot;V755&quot; &quot;V756&quot; &quot;V757&quot; &quot;V758&quot; &quot;V759&quot; &quot;V760&quot; &quot;V781&quot; &quot;V782&quot; &quot;V783&quot;
## [67] &quot;V784&quot;</code></pre></div>
<p>However, in a multinomial problem, each response category will not always use <strong>all</strong> the predictors that have variance. In fact, the below code shows that the number zero only uses 189 predictors whereas the number 3 uses 296.</p>
<div class="rmdtip">
<p>
You can set <code>type.multinomial = “grouped”</code> within <code>cv.glmnet()</code> to force all predictors to be in or out together.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(elastic) <span class="op">%&gt;%</span>
<span class="st">  </span>purrr<span class="op">::</span><span class="kw">map</span>(tidy) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_rows</span>(<span class="dt">.id =</span> <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>(response)
## # A tibble: 10 x 2
##    Response     n
##    &lt;chr&gt;    &lt;int&gt;
##  1 0          189
##  2 1          206
##  3 2          281
##  4 3          296
##  5 4          272
##  6 5          264
##  7 6          267
##  8 7          278
##  9 8          228
## 10 9          283</code></pre></div>
<p>Moreover, each response category will use the predictors in different ways. Similar to the binary classification problem, the coefficients represent the change in log-odds probability of the response variable for a one unit change in the predictor. For example, below we see that for the response category “0”, a one unit increase in the darkness of the pixel represented by feature V41 causes a 0.0089 log odds increase that the response will be the number “0”. A 0.0089 log odds increase translates to <span class="math inline">\(\frac{e^{0.008912499}}{1+e^{0.008912499}} = 0.5022281\)</span> probability increase.</p>
<div class="rmdnote">
<p>
The below code chunk extracts the coefficients for each response category, combines them all into a single data frame, and removes the intercept (since we just care about the predictor coefficients).
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># tidy up the coefficients for downstream assessment</span>
vi &lt;-<span class="st"> </span><span class="kw">coef</span>(elastic) <span class="op">%&gt;%</span>
<span class="st">  </span>purrr<span class="op">::</span><span class="kw">map</span>(tidy) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_rows</span>(<span class="dt">.id =</span> <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(row <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(response, <span class="dt">feature =</span> row, <span class="dt">coefficient =</span> value)

<span class="kw">head</span>(vi)
##   response feature   coefficient
## 1        0     V41  8.912499e-03
## 2        0     V45  8.816906e-03
## 3        0     V60  8.381852e-02
## 4        0     V72 -2.083206e-04
## 5        0    V106 -1.630429e-03
## 6        0    V124  1.720361e-05</code></pre></div>
<p>Similar to the binary classification problem, one of our main concerns is to understand which predictors have the largest influence on each response category. The following identifies the top 10 predictors with the largest absolute coefficients. These predictors represent those that have the largest impact to the probability of that response. For example, as features <code>V60</code>, <code>V225</code>, and <code>V504</code> increase (those pixels become darker), they have the largest increase in the probability that the response will be “0”. Alternatively, as features <code>V719</code> and <code>V363</code> increase, they have the largest decrease in the probability that the response will be “0”.</p>
<div class="rmdnote">
<p>
Since a given predictor can have a different coefficient for each response category, each response category can have their own unique variable importance list.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vi <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(response) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">10</span>, <span class="dt">wt =</span> <span class="kw">abs</span>(coefficient)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predictor =</span> <span class="kw">paste</span>(response, feature, <span class="dt">sep =</span> <span class="st">&quot;: &quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(coefficient, <span class="kw">reorder</span>(predictor, coefficient), <span class="dt">color =</span> coefficient <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>response, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>, <span class="dt">ncol =</span> <span class="dv">5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="ot">NULL</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-multi-vip-plot"></span>
<img src="images/glmnet-multi-vip.png" alt="Top 10 most influential predictors for each multinomial response. Predictors with coefficients to the right of zero (blue) increase the probability of that response whereas predictors with coefficients to the left of zero (red) decrease the probability of that response." width="100%" height="100%" />
<p class="caption">
Figure 3.27: Top 10 most influential predictors for each multinomial response. Predictors with coefficients to the right of zero (blue) increase the probability of that response whereas predictors with coefficients to the left of zero (red) decrease the probability of that response.
</p>
</div>
<p>The above plot identifies thse variables most influential for each given response category. However, we also want to understand which variables are influential across all, or most, of the responses. The below identifies three predictors (<code>V375</code>, <code>V515</code>, <code>V572</code>) that have non-zero coefficients for all the response categories. Plotting these variables allows us to see how the strength and direction of the signal varies across the response categories. These features represent pixels in the images that are used by each handwritten number.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predictors that are influential across all or many of the responses</span>
vi <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">count</span>(feature) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))
## # A tibble: 653 x 2
##    feature     n
##    &lt;chr&gt;   &lt;int&gt;
##  1 V375       10
##  2 V515       10
##  3 V572       10
##  4 V402        9
##  5 V239        8
##  6 V268        8
##  7 V301        8
##  8 V324        8
##  9 V326        8
## 10 V353        8
## # ... with 643 more rows

vi <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(feature <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;V375&quot;</span>, <span class="st">&quot;V515&quot;</span>, <span class="st">&quot;V572&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(coefficient, feature, <span class="dt">fill =</span> coefficient <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>response, <span class="dt">ncol =</span> <span class="dv">5</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glmnet-multi-vip-all-plot"></span>
<img src="images/glmnet-multi-vip-all.png" alt="Three variables provide signals for all the response categories; however, the strength and direction of the signal can vary across the responses." width="100%" height="100%" />
<p class="caption">
Figure 3.28: Three variables provide signals for all the response categories; however, the strength and direction of the signal can vary across the responses.
</p>
</div>
<p>Similarly, certain predictors may only provide a signal for only one response category. We also want to assess these as they provide a unique signal for a particular response. For example, feature <code>V170</code> is only influential for response “3” and increases the probability by 0.525.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># only 82 predictors that play a role in just one response</span>
singles &lt;-<span class="st"> </span>vi <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">count</span>(feature) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(n <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>.<span class="op">$</span>feature

vi <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(feature <span class="op">%in%</span><span class="st"> </span>singles) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(<span class="kw">abs</span>(coefficient))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prob =</span> <span class="kw">exp</span>(coefficient) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(coefficient)))
##    response feature coefficient      prob
## 1         3    V170  0.10146013 0.5253433
## 2         0     V60  0.08381852 0.5209424
## 3         0    V225  0.07995005 0.5199769
## 4         7    V780  0.05972853 0.5149277
## 5         7    V534  0.03223708 0.5080586
## 6         7    V778  0.02278233 0.5056953
## 7         2    V392  0.02252209 0.5056303
## 8         2     V82  0.02225574 0.5055637
## 9         8    V335  0.01925485 0.5048136
## 10        6     V88  0.01859690 0.5046491</code></pre></div>
<div class="rmdnote">
<p>
Remember that these linear models assume a monotonic linear relationship between the predictors and the response; meaning that for a given response category, the relationship represented by the coefficient is constant. Therefore, global and local model interpreation will be the same. See more in the machine learning interpretability chapter.
</p>
</div>
</div>
<div id="classification-multi-glmnet-predict" class="section level4">
<h4><span class="header-section-number">3.6.1.4</span> Predicting</h4>
<p>Once you have identified your preferred model, you can simply use <code>predict</code> to predict the same model on a new data set. Similar to the binary classification problem:</p>
<ol style="list-style-type: decimal">
<li>You need to supply <code>predict</code> an <code>s</code> parameter with the preferred model’s <span class="math inline">\(\lambda\)</span> value.</li>
<li>The default predicted values are the log odds. If you want the probability, include <code>type = &quot;response&quot;</code>.</li>
<li>If you want to predict the categorical response, include <code>type = &quot;class&quot;</code>.</li>
</ol>
<p>Additionally, the predicted output is in the form of an array. Consequently, to assess the predicted values for the first five observations across all response categories, index with the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict and get log-odds</span>
pred_log_odds &lt;-<span class="st"> </span><span class="kw">predict</span>(elastic, <span class="dt">s =</span> elastic<span class="op">$</span>lambda.min, test_x)
pred_log_odds[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, , <span class="dv">1</span>]
##              0          1         2          3         4          5         6           7         8          9
## [1,] -5.432659  -1.339061 -2.333135  0.7305298 -3.606102  0.5498658 -6.628586  -6.8034856 6.3175820   0.353073
## [2,] -8.302420  -5.464651 -3.410668  7.5492386 -4.806773  3.3335312 -4.941261  -0.1618101 0.7612956   2.373736
## [3,]  7.266914  -8.224763  1.052633  1.6484586 -8.055438 -9.2497608  2.820177 -12.5006341 8.8967193 -10.473515
## [4,]  8.415969 -10.700918  1.233072 -5.6888200 -2.364087 -0.6202491  5.928128  -7.3944607 0.2065292  -5.634506
## [5,] -6.395731   7.228976  2.144250 -0.1299773 -4.381965 -2.0272380 -2.086397  -1.8958485 1.1838882  -2.138867

<span class="co"># predict probability</span>
pred_probs &lt;-<span class="st"> </span><span class="kw">predict</span>(elastic, <span class="dt">s =</span> elastic<span class="op">$</span>lambda.min, test_x, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
pred_probs[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, , <span class="dv">1</span>]
##                 0            1            2            3            4            5            6            7            8            9
## [1,] 7.808164e-06 4.681405e-04 0.0001732428 3.708412e-03 4.850791e-05 3.095470e-03 2.361373e-06 1.982470e-06 0.9899515761 2.542498e-03
## [2,] 1.277183e-07 2.181128e-06 0.0000170104 9.784562e-01 4.211081e-06 1.444385e-02 3.681174e-06 4.382031e-04 0.0011029991 5.531581e-03
## [3,] 1.633925e-01 3.056908e-08 0.0003268920 5.931549e-04 3.620925e-08 1.096811e-08 1.914428e-03 4.249083e-10 0.8337729101 3.225981e-09
## [4,] 9.222861e-01 4.597347e-09 0.0007004437 6.906115e-07 1.919319e-05 1.097706e-04 7.663202e-02 1.254537e-07 0.0002509293 7.291585e-07
## [5,] 1.198730e-06 9.905039e-01 0.0061317946 6.308170e-04 8.980257e-06 9.460923e-05 8.917459e-05 1.078935e-04 0.0023469721 8.461622e-05

<span class="co"># predict and get predicted class</span>
pred_class &lt;-<span class="st"> </span><span class="kw">predict</span>(elastic, <span class="dt">s =</span> elastic<span class="op">$</span>lambda.min, test_x, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>)
<span class="kw">head</span>(pred_class)
##      1  
## [1,] &quot;8&quot;
## [2,] &quot;3&quot;
## [3,] &quot;8&quot;
## [4,] &quot;0&quot;
## [5,] &quot;1&quot;
## [6,] &quot;5&quot;</code></pre></div>
<p>Lastly, to assess various performance metrics on our test data we can use <code>caret::confusionMatrix</code>, which provides the majority of the performance measures we are typically concerned with in classification models. We can see that the overall accuracy rate is 0.9281 and our model does well predicting “0”, “1”, and “6” but poorly predicting “2”, “3”, “5”, “8”, and “9”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(<span class="kw">factor</span>(pred_class), <span class="kw">factor</span>(test_y))
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1    2    3    4    5    6    7    8    9
##          0  959    0    7    3    1    8   10    2    6   10
##          1    0 1114    8    1    1    2    3    9    7    8
##          2    1    2  929   16    4    2    4   22    6    1
##          3    1    2   15  921    1   33    2    5   21   10
##          4    0    0    7    0  919   11    7    5   10   25
##          5    7    1    3   29    0  779   14    0   24    5
##          6    6    4   12    2   12   14  913    0    9    0
##          7    5    2   11   10    6    8    3  954   10   22
##          8    1   10   36   20    8   31    2    1  871    6
##          9    0    0    4    8   30    4    0   30   10  922
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9281          
##                  95% CI : (0.9229, 0.9331)
##     No Information Rate : 0.1135          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9201          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: 0 Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8 Class: 9
## Sensitivity            0.9786   0.9815   0.9002   0.9119   0.9358   0.8733   0.9530   0.9280   0.8943   0.9138
## Specificity            0.9948   0.9956   0.9935   0.9900   0.9928   0.9909   0.9935   0.9914   0.9873   0.9904
## Pos Pred Value         0.9533   0.9662   0.9412   0.9110   0.9339   0.9037   0.9393   0.9253   0.8834   0.9147
## Neg Pred Value         0.9977   0.9976   0.9886   0.9901   0.9930   0.9876   0.9950   0.9917   0.9886   0.9903
## Prevalence             0.0980   0.1135   0.1032   0.1010   0.0982   0.0892   0.0958   0.1028   0.0974   0.1009
## Detection Rate         0.0959   0.1114   0.0929   0.0921   0.0919   0.0779   0.0913   0.0954   0.0871   0.0922
## Detection Prevalence   0.1006   0.1153   0.0987   0.1011   0.0984   0.0862   0.0972   0.1031   0.0986   0.1008
## Balanced Accuracy      0.9867   0.9885   0.9469   0.9509   0.9643   0.9321   0.9733   0.9597   0.9408   0.9521</code></pre></div>
</div>
</div>
<div id="classification-multinomial-glm-h2o" class="section level3">
<h3><span class="header-section-number">3.6.2</span> <code>h2o</code></h3>
<p>To perform regularized multinomial logistic regression with <strong>h2o</strong>, we first need to initiate our <strong>h2o</strong> session.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">h2o<span class="op">::</span><span class="kw">h2o.no_progress</span>()
<span class="kw">h2o.init</span>(<span class="dt">max_mem_size =</span> <span class="st">&quot;5g&quot;</span>)
##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         3 seconds 740 milliseconds 
##     H2O cluster timezone:       America/New_York 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.18.0.11 
##     H2O cluster version age:    2 months and 13 days  
##     H2O cluster name:           H2O_started_from_R_bradboehmke_fmw129 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   4.44 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.5.1 (2018-07-02)</code></pre></div>
<p>Since our data is already split into a training test set, to prepare for modeling, we just need to convert our training and test data to <strong>h2o</strong> objects and identify the response and predictor variables.</p>
<div class="rmdwarning">
<p>
One key difference compared to prior classification procedures, to perform a multinomial modeling with <strong>h2o</strong> we need to convert the response variable to a factor.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># convert training data to h2o object</span>
train_h2o &lt;-<span class="st"> </span>train <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">V785 =</span> <span class="kw">factor</span>(V785)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.h2o</span>()

<span class="co"># convert test data to h2o object</span>
test_h2o &lt;-<span class="st"> </span>test <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">V785 =</span> <span class="kw">factor</span>(V785)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.h2o</span>()

<span class="co"># set the response column to V785</span>
response &lt;-<span class="st"> &quot;V785&quot;</span>

<span class="co"># set the predictor names</span>
predictors &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(train), response)</code></pre></div>
<div id="h2o-glm-classification-multinomial-basic" class="section level4">
<h4><span class="header-section-number">3.6.2.1</span> Basic implementation</h4>
<p>Similar to our regression and binary classification problem, we use <code>h2o.glm</code> to perform a regularized multinomial logistic regression model. The primary difference is that we need to set <code>family = &quot;multinomial&quot;</code> to signal a multinomial classification problem. As before, by default, <code>h2o.glm</code> performs an elastic net model with <code>alpha = .5</code> and will perform an automated search across internally generated lambda values.</p>
<p>The following performs a default multinomial <code>h2o.glm</code> model with <code>alpha = .5</code> and it performs a 5 fold cross validation (<code>nfolds = 10</code>).</p>
<div class="rmdtip">
<p>
When you are working with large data sets, <strong>h2o</strong> provides a far more efficient approach for regularized models. Whereas <strong>glmnet</strong> took over an hour to perform a 5-fold cross validated regularized model on the <strong>mnist</strong> data, <strong>h2o</strong> took less than 2.5 minutes!
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># train your model, where you specify alpha (performs 5-fold CV)</span>
h2o_fit1 &lt;-<span class="st"> </span><span class="kw">h2o.glm</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> train_h2o,
  <span class="dt">nfolds =</span> <span class="dv">5</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">alpha =</span> .<span class="dv">5</span>, 
  <span class="dt">family =</span> <span class="st">&quot;multinomial&quot;</span>
)</code></pre></div>
<p>We can check out the cross-validated performance results of our model with <code>h2o.performance</code>. You can also get more results information using <code>summary(h2o_fit1)</code>. One unique output worth discussing is the “Top-10 Hit Ratios” table. The first line of this table (k = 1, hit_ratio = 0.9213) represents the mean accuracy of our model across the 5-fold validated set. However, the second line tells us that when we take those missed predictions and use the second highest predicted probability we get a mean accuracy of 96.85% (we get an additional <span class="math inline">\((0.9685 - 0.9213) \times 60000 = 2832\)</span> observations correct.) After only 4 reapplications we are able to achieve 99% accuracy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.performance</span>(h2o_fit1, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## H2OMultinomialMetrics: glm
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## Cross-Validation Set Metrics: 
## =====================
## 
## Extract cross-validation frame with `h2o.getFrame(&quot;filea18f736ccac9_sid_8725_4&quot;)`
## MSE: (Extract with `h2o.mse`) 0.07378137
## RMSE: (Extract with `h2o.rmse`) 0.2716273
## Logloss: (Extract with `h2o.logloss`) 0.2843358
## Mean Per-Class Error: 0.07972688
## Null Deviance: (Extract with `h2o.nulldeviance`) 276156.9
## Residual Deviance: (Extract with `h2o.residual_deviance`) 34193.91
## R^2: (Extract with `h2o.r2`) 0.9911615
## AIC: (Extract with `h2o.aic`) NaN
## Hit Ratio Table: Extract with `h2o.hit_ratio_table(&lt;model&gt;,xval = TRUE)`
## =======================================================================
## Top-10 Hit Ratios: 
##     k hit_ratio
## 1   1  0.921300
## 2   2  0.968500
## 3   3  0.984300
## 4   4  0.991517
## 5   5  0.995133
## 6   6  0.997200
## 7   7  0.998400
## 8   8  0.999183
## 9   9  0.999800
## 10 10  1.000000</code></pre></div>
</div>
<div id="glm-h2o-classification-multinomial-tune" class="section level4">
<h4><span class="header-section-number">3.6.2.2</span> Tuning</h4>
<p>Since <strong>h2o</strong> is much faster than <strong>glmnet</strong>, we can perform a grid search across a wider range of alpha parameters. Here, I assess alphas equal to 0, 0.25, 0.5, 0.75, and 1 using <code>h2o.grid</code> to perform our grid search. The results show that <span class="math inline">\(\alpha = .25\)</span> performed best. The results also show that 4 out of 5 models have minor differences in the Log Loss loss function; however, <span class="math inline">\(\alpha = .0\)</span> (full ridge penalty) definitely performs the worst.</p>
<div class="rmdnote">
<p>
This grid search took 20 minutes.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create hyperparameter grid</span>
hyper_params &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> .<span class="dv">25</span>))

<span class="co"># perform grid search</span>
grid &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> train_h2o, 
  <span class="dt">nfolds =</span> <span class="dv">10</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">algorithm =</span> <span class="st">&quot;glm&quot;</span>,
  <span class="dt">family =</span> <span class="st">&quot;multinomial&quot;</span>,
  <span class="dt">grid_id =</span> <span class="st">&quot;grid_search_glm_multinomial&quot;</span>, 
  <span class="dt">hyper_params =</span> hyper_params
)

<span class="co"># Sort the grid models by MSE</span>
sorted_grid &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(<span class="st">&quot;grid_search_glm_multinomial&quot;</span>, <span class="dt">sort_by =</span> <span class="st">&quot;logloss&quot;</span>, <span class="dt">decreasing =</span> <span class="ot">FALSE</span>)
sorted_grid
## H2O Grid Details
## ================
## 
## Grid ID: grid_search_glm_multinomial 
## Used hyper parameters: 
##   -  alpha 
## Number of models: 5 
## Number of failed models: 0 
## 
## Hyper-Parameter Search Summary: ordered by increasing logloss
##    alpha                           model_ids             logloss
## 1 [0.25] grid_search_glm_multinomial_model_1  0.2826176758945207
## 2  [1.0] grid_search_glm_multinomial_model_4  0.2833413952701668
## 3 [0.75] grid_search_glm_multinomial_model_3  0.2834683548256082
## 4  [0.5] grid_search_glm_multinomial_model_2  0.2855257887768779
## 5  [0.0] grid_search_glm_multinomial_model_0 0.31518212134903734</code></pre></div>
<p>We can check out more details of the best performing model. Our AUC (.84) is no better than our default cross-validated model. We can also extract other model parameters, which show the optimal <span class="math inline">\(\lambda\)</span> value for our model was 0.0006.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># grab top model id</span>
best_h2o_model &lt;-<span class="st"> </span>sorted_grid<span class="op">@</span>model_ids[[<span class="dv">1</span>]]
best_model &lt;-<span class="st"> </span><span class="kw">h2o.getModel</span>(best_h2o_model)

<span class="co"># assess performance</span>
<span class="kw">h2o.mse</span>(best_model, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## [1] 0.0733229

<span class="kw">h2o.rmse</span>(best_model, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## [1] 0.270782

<span class="co"># get optimal parameters</span>
best_model<span class="op">@</span>parameters<span class="op">$</span>lambda
## [1] 0.000673668

best_model<span class="op">@</span>parameters<span class="op">$</span>alpha
## [1] 0.25</code></pre></div>
<p>We can also assess the confusion matrix for our optimal model. Our overall accuracy is 0.9146 (<span class="math inline">\(1-0.0854\)</span>), which is slightly less than the mean 5-fold CV accuracy produced by the <strong>glmnet</strong> model (0.9344). Similar to our <strong>glmnet</strong> results, our optimal model is doing a good job predicting “0”, “1”, and “6”, but is poorly predicting “2”, “3”, “5”, and “8”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.confusionMatrix</span>(best_model)
## Confusion Matrix: Row labels: Actual class; Column labels: Predicted class
##           0    1    2    3    4    5    6    7    8    9  Error             Rate
## 0      5776    1   14    9   10   28   36    6   38    5 0.0248 =    147 / 5,923
## 1         1 6581   32   15    6   26    3   14   55    9 0.0239 =    161 / 6,742
## 2        28   53 5449   85   64   16   57   67  121   18 0.0854 =    509 / 5,958
## 3        18   31  119 5553    7  180   16   49  109   49 0.0943 =    578 / 6,131
## 4        11   34   24    8 5504    7   44   12   30  168 0.0579 =    338 / 5,842
## 5        50   32   31  146   52 4855   78   17  121   39 0.1044 =    566 / 5,421
## 6        31   18   31    0   35   62 5710    4   25    2 0.0351 =    208 / 5,918
## 7        11   35   58   16   46    8    4 5905   12  170 0.0575 =    360 / 6,265
## 8        33  151   51  128   26  134   34   15 5211   68 0.1094 =    640 / 5,851
## 9        25   27   11   76  142   30    3  156   38 5441 0.0854 =    508 / 5,949
## Totals 5984 6963 5820 6036 5892 5346 5985 6245 5760 5969 0.0669 = 4,015 / 60,000</code></pre></div>
</div>
<div id="glm-h2o-classification-multinomial-viz" class="section level4">
<h4><span class="header-section-number">3.6.2.3</span> Visual Interpretation</h4>
<p>Similar to <strong>glmnet</strong>, we can extract useful information from our coefficients to interpret influential variables in our predictors. First, we need to do a little clean up of our coefficient table.</p>
<div class="rmdnote">
<p>
The coefficient table provides both the coefficient estimate and the standard error; however, what follows only focuses on the coefficient estimate.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># clean up coefficient information</span>
vi &lt;-<span class="st"> </span>best_model<span class="op">@</span>model<span class="op">$</span>coefficients_table <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span>
<span class="st">  </span>tidyr<span class="op">::</span><span class="kw">gather</span>(response, coefficient, <span class="op">-</span>names) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(
    names <span class="op">!=</span><span class="st"> &quot;Intercept&quot;</span>, 
    <span class="op">!</span>(stringr<span class="op">::</span><span class="kw">str_detect</span>(response, <span class="st">&quot;std&quot;</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">response =</span> stringr<span class="op">::</span><span class="kw">str_remove</span>(response, <span class="st">&quot;coefs_class_&quot;</span>))

<span class="kw">head</span>(vi)
##   names response  coefficient
## 1   V13        0 1.637796e-04
## 2   V14        0 2.447977e-05
## 3   V15        0 1.202897e-04
## 4   V16        0 2.886954e-03
## 5   V33        0 1.270802e-03
## 6   V34        0 3.842376e-04</code></pre></div>
<p>Unlike <strong>glmnet</strong>, <strong>h2o</strong> forces all predictors to be either in or out across all response categories (there are options to remove some of the collinear columns; however, this will still produce a consistent number of predictors across all response categories). Consequently, we see that all 717 features are present for each response.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">count</span>(vi, response)
## # A tibble: 10 x 2
##    response     n
##    &lt;chr&gt;    &lt;int&gt;
##  1 0          717
##  2 1          717
##  3 2          717
##  4 3          717
##  5 4          717
##  6 5          717
##  7 6          717
##  8 7          717
##  9 8          717
## 10 9          717</code></pre></div>
<p>Similar to <strong>glment</strong>, we can use this information to identify the top 10 predictors with the largest absolute coefficients for each response category. These predictors represent those that have the largest impact to the probability of that response. Comparing to the <strong>glmnet</strong> variable importance plots earlier, features <code>V60</code>, <code>V225</code>, and <code>V504</code> are the top 3 features that have the largest increase in the probability that the response will be “0” (although their ordering differs slightly). However, the features that have the largest decrease in the probability of response “0” differ from before. This may be a result of the different penalty parameter that this optimal model has compared to what we used with <strong>glmnet</strong> (<span class="math inline">\(\alpha=0.25\)</span> versus <span class="math inline">\(\alpha=0.5\)</span>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vi <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(response) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">10</span>, <span class="dt">wt =</span> <span class="kw">abs</span>(coefficient)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predictor =</span> <span class="kw">paste</span>(response, names, <span class="dt">sep =</span> <span class="st">&quot;: &quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(coefficient, <span class="kw">reorder</span>(predictor, coefficient), <span class="dt">color =</span> coefficient <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>response, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>, <span class="dt">ncol =</span> <span class="dv">5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="ot">NULL</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:glm-h2o-multi-vip-plot"></span>
<img src="images/glm-h2o-multi-vip.png" alt="Top 10 most influential predictors for each multinomial response. Predictors with coefficients to the right of zero (blue) increase the probability of that response whereas predictors with coefficients to the left of zero (red) decrease the probability of that response." width="100%" height="100%" />
<p class="caption">
Figure 3.29: Top 10 most influential predictors for each multinomial response. Predictors with coefficients to the right of zero (blue) increase the probability of that response whereas predictors with coefficients to the left of zero (red) decrease the probability of that response.
</p>
</div>
<div class="rmdnote">
<p>
Remember that these linear models assume a monotonic linear relationship between the predictors and the response; meaning that for a given response category, the relationship represented by the coefficient is constant. Therefore, global and local model interpreation will be the same. See more in the machine learning interpretability chapter.
</p>
</div>
</div>
<div id="glm-h2o-classification-multinomial-predict" class="section level4">
<h4><span class="header-section-number">3.6.2.4</span> Predicting</h4>
<p>Lastly, we can use <code>h2o.predict</code> and <code>h2o.performance</code> to predict and evaluate our models performance on our hold out test data. Note how the <code>h2o.predict</code> function provides 11 columns - the predicted class and the probability of each class. We also produce our test set performance results with <code>h2o.performance</code>. If you compare the confusion matrix with the one produced by <strong>glmnet</strong> you will notice they produce very similar results. The <strong>h2o</strong> model has an overall accuracy of 0.9254 (<span class="math inline">\(1-0.0746\)</span>) whereas the <strong>glmnet</strong> model achieved an accuracy of 0.9281 on the test set. And both models have about the same level of accuracy across individual response categories.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># make predictions</span>
pred &lt;-<span class="st"> </span><span class="kw">h2o.predict</span>(<span class="dt">object =</span> best_model, <span class="dt">newdata =</span> test_h2o)
<span class="kw">head</span>(pred)
##   predict           p0           p1           p2           p3           p4           p5           p6           p7           p8           p9
## 1       8 1.202141e-05 5.972906e-04 1.974938e-04 3.407596e-03 7.913304e-05 2.536697e-03 1.125671e-05 5.718130e-06 0.9905660926 2.586700e-03
## 2       3 3.049209e-07 2.484003e-05 5.767582e-06 9.805161e-01 6.366074e-06 1.372732e-02 8.326104e-06 4.850814e-04 0.0009518292 4.274033e-03
## 3       8 4.521685e-01 1.335448e-07 6.741594e-04 7.897412e-05 1.444127e-07 8.704872e-07 3.896986e-03 5.145982e-09 0.5431802637 3.238420e-09
## 4       0 8.901589e-01 4.027749e-07 9.102679e-04 5.754058e-07 3.002048e-05 1.979771e-04 1.081991e-01 1.176814e-06 0.0005003709 1.131257e-06
## 5       1 7.789492e-06 9.859295e-01 9.676005e-03 8.276910e-04 1.749899e-05 1.464323e-04 2.368448e-04 1.720208e-04 0.0029125347 7.370373e-05
## 6       5 1.597256e-06 2.661786e-08 1.713028e-08 8.928673e-11 4.543192e-05 9.399342e-01 1.337817e-06 3.112696e-07 0.0600170128 2.307191e-08

<span class="co"># assess performance</span>
<span class="kw">h2o.performance</span>(best_model, <span class="dt">newdata =</span> test_h2o)
## H2OMultinomialMetrics: glm
## 
## Test Set Metrics: 
## =====================
## 
## MSE: (Extract with `h2o.mse`) 0.06887707
## RMSE: (Extract with `h2o.rmse`) 0.2624444
## Logloss: (Extract with `h2o.logloss`) 0.2682622
## Mean Per-Class Error: 0.07570879
## Null Deviance: (Extract with `h2o.nulldeviance`) 46020.38
## Residual Deviance: (Extract with `h2o.residual_deviance`) 5365.243
## R^2: (Extract with `h2o.r2`) 0.9917859
## AIC: (Extract with `h2o.aic`) NaN
## Confusion Matrix: Extract with `h2o.confusionMatrix(&lt;model&gt;, &lt;data&gt;)`)
## =========================================================================
## Confusion Matrix: Row labels: Actual class; Column labels: Predicted class
##           0    1   2    3   4   5   6    7   8    9  Error           Rate
## 0       963    0   0    1   0   5   5    4   2    0 0.0173 =     17 / 980
## 1         0 1112   2    2   0   1   4    2  12    0 0.0203 =   23 / 1,135
## 2         7    9 926   17   9   3  13    9  36    3 0.1027 =  106 / 1,032
## 3         4    1  17  921   1  24   2   11  23    6 0.0881 =   89 / 1,010
## 4         1    3   3    2 919   0  14    3   7   30 0.0642 =     63 / 982
## 5         8    2   1   33  10 774  17   12  31    4 0.1323 =    118 / 892
## 6        11    3   6    1   7  15 910    3   2    0 0.0501 =     48 / 958
## 7         2    9  22    6   6   0   0  951   1   31 0.0749 =   77 / 1,028
## 8         7   12   6   19  11  24  11   12 861   11 0.1160 =    113 / 974
## 9        10    8   1   10  28   5   0   24   6  917 0.0912 =   92 / 1,009
## Totals 1013 1159 984 1012 991 851 976 1031 981 1002 0.0746 = 746 / 10,000
## 
## Hit Ratio Table: Extract with `h2o.hit_ratio_table(&lt;model&gt;, &lt;data&gt;)`
## =======================================================================
## Top-10 Hit Ratios: 
##     k hit_ratio
## 1   1  0.925400
## 2   2  0.970200
## 3   3  0.983900
## 4   4  0.991300
## 5   5  0.995600
## 6   6  0.997400
## 7   7  0.998600
## 8   8  0.999300
## 9   9  0.999700
## 10 10  1.000000</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># shutdown h2o</span>
<span class="kw">h2o.removeAll</span>()
## [1] 0
<span class="kw">h2o.shutdown</span>(<span class="dt">prompt =</span> <span class="ot">FALSE</span>)</code></pre></div>
</div>
</div>
</div>
<div id="glm-learning" class="section level2">
<h2><span class="header-section-number">3.7</span> Learning More</h2>
<p>This serves as an introduction to regularized regression; however, it just scrapes the surface. Regularized regression approaches have been extended to other parametric (i.e. Cox proportional hazard, poisson, support vector machines) and non-parametric (i.e. Least Angle Regression, the Bayesian Lasso, neural networks) models. The following are great resources to learn more (listed in order of complexity):</p>
<ul>
<li><a href="https://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn/dp/1461468485/ref=sr_1_1?ie=UTF8&amp;qid=1522246635&amp;sr=8-1&amp;keywords=applied+predictive+modelling">Applied Predictive Modeling</a></li>
<li><a href="https://www.amazon.com/Practical-Machine-Learning-H2O-Techniques/dp/149196460X">Practical Machine Learning with H2o</a></li>
<li><a href="https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370/ref=sr_1_2?ie=UTF8&amp;qid=1522246635&amp;sr=8-2&amp;keywords=applied+predictive+modelling">Introduction to Statistical Learning</a></li>
<li><a href="https://www.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576/ref=sr_1_3?ie=UTF8&amp;qid=1522246635&amp;sr=8-3&amp;keywords=applied+predictive+modelling">The Elements of Statistical Learning</a></li>
<li><a href="https://www.amazon.com/Statistical-Learning-Sparsity-Generalizations-Probability/dp/1498712169/ref=sr_1_1?ie=UTF8&amp;qid=1522246685&amp;sr=8-1&amp;keywords=statistical+learning+with+sparsity">Statistical Learning with Sparsity</a></li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-glmnet">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2010. <em>Regularization Paths for Generalized Linear Models via Coordinate Descent</em>. <em>Journal of Statistical Software</em>. Vol. 33. <a href="http://www.jstatsoft.org/v33/i01/" class="uri">http://www.jstatsoft.org/v33/i01/</a>.</p>
</div>
<div id="ref-R-h2o">
<p>Kraljevic, Tom. 2018. <em>H2o: R Interface for ’H2o’</em>. <a href="https://CRAN.R-project.org/package=h2o" class="uri">https://CRAN.R-project.org/package=h2o</a>.</p>
</div>
<div id="ref-myers1990classical">
<p>Myers, Raymond H. 1990. “Classical and Modern Regression with Applications.”</p>
</div>
<div id="ref-hoerl1970ridge">
<p>Hoerl, Arthur E, and Robert W Kennard. 1970. “Ridge Regression: Biased Estimation for Nonorthogonal Problems.” <em>Technometrics</em> 12 (1). Taylor &amp; Francis Group: 55–67.</p>
</div>
<div id="ref-tibshirani1996regression">
<p>Tibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>. JSTOR, 267–88.</p>
</div>
<div id="ref-zou2005regularization">
<p>Zou, Hui, and Trevor Hastie. 2005. “Regularization and Variable Selection via the Elastic Net.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 67 (2). Wiley Online Library: 301–20.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Note that our pentalty is only applied to our feature coefficients (<span class="math inline">\(\beta_1, \beta_2, \dots, \beta_p\)</span>) and not the intercept (<span class="math inline">\(\beta_0\)</span>).<a href="regularized-regression.html#fnref1">↩</a></p></li>
<li id="fn2"><p>The features highlighted for each package were originally identified by Erin LeDell in her <a href="https://github.com/ledell/useR-machine-learning-tutorial">useR! 2016 tutorial</a>.<a href="regularized-regression.html#fnref2">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-performance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="random-forest.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-regularized-glm-models.rmd",
"text": "Edit"
},
"download": ["hands-on-machine-learning-with-R.pdf", "hands-on-machine-learning-with-R.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
