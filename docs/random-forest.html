<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Hands-on Machine Learning with R</title>
  <meta name="description" content="A Machine Learning Algorithmic Deep Dive Using R.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Hands-on Machine Learning with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A Machine Learning Algorithmic Deep Dive Using R." />
  <meta name="github-repo" content="bradleyboehmke/hands-on-machine-learning-with-r" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Hands-on Machine Learning with R" />
  
  <meta name="twitter:description" content="A Machine Learning Algorithmic Deep Dive Using R." />
  



<meta name="date" content="2018-08-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regularized-regression.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Hands-on Machine Learning with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-should-read-this"><i class="fa fa-check"></i>Who should read this</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-r"><i class="fa fa-check"></i>Why R</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#conventions-used-in-this-book"><i class="fa fa-check"></i>Conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#additional-resources"><i class="fa fa-check"></i>Additional resources</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#feedback"><i class="fa fa-check"></i>Feedback</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-information"><i class="fa fa-check"></i>Software information</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#supervised-learning"><i class="fa fa-check"></i><b>1.1</b> Supervised Learning</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#regression-problems"><i class="fa fa-check"></i><b>1.1.1</b> Regression problems</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#classification-problems"><i class="fa fa-check"></i><b>1.1.2</b> Classification problems</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#algorithm-comparison-guide"><i class="fa fa-check"></i><b>1.1.3</b> Algorithm Comparison Guide</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#unsupervised-learning"><i class="fa fa-check"></i><b>1.2</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#algorithm-decision-guide"><i class="fa fa-check"></i><b>1.2.1</b> Algorithm Decision Guide</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#machine-learning-interpretability"><i class="fa fa-check"></i><b>1.3</b> Machine learning interpretability</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#data"><i class="fa fa-check"></i><b>1.4</b> The data sets</a></li>
</ul></li>
<li class="part"><span><b>I Supervised Learning</b></span></li>
<li class="chapter" data-level="2" data-path="regression-performance.html"><a href="regression-performance.html"><i class="fa fa-check"></i><b>2</b> Preparing for Supervised Machine Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_prereq"><i class="fa fa-check"></i><b>2.1</b> Prerequisites</a></li>
<li class="chapter" data-level="2.2" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_split"><i class="fa fa-check"></i><b>2.2</b> Data splitting</a><ul>
<li class="chapter" data-level="2.2.1" data-path="regression-performance.html"><a href="regression-performance.html#spending-our-data-wisely"><i class="fa fa-check"></i><b>2.2.1</b> Spending our data wisely</a></li>
<li class="chapter" data-level="2.2.2" data-path="regression-performance.html"><a href="regression-performance.html#simple-random-sampling"><i class="fa fa-check"></i><b>2.2.2</b> Simple random sampling</a></li>
<li class="chapter" data-level="2.2.3" data-path="regression-performance.html"><a href="regression-performance.html#stratified-sampling"><i class="fa fa-check"></i><b>2.2.3</b> Stratified sampling</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_feat"><i class="fa fa-check"></i><b>2.3</b> Feature engineering</a><ul>
<li class="chapter" data-level="2.3.1" data-path="regression-performance.html"><a href="regression-performance.html#response-transformation"><i class="fa fa-check"></i><b>2.3.1</b> Response Transformation</a></li>
<li class="chapter" data-level="2.3.2" data-path="regression-performance.html"><a href="regression-performance.html#predictor-transformation"><i class="fa fa-check"></i><b>2.3.2</b> Predictor Transformation</a></li>
<li class="chapter" data-level="2.3.3" data-path="regression-performance.html"><a href="regression-performance.html#one-hot-encoding"><i class="fa fa-check"></i><b>2.3.3</b> One-hot encoding</a></li>
<li class="chapter" data-level="2.3.4" data-path="regression-performance.html"><a href="regression-performance.html#standardizing"><i class="fa fa-check"></i><b>2.3.4</b> Standardizing</a></li>
<li class="chapter" data-level="2.3.5" data-path="regression-performance.html"><a href="regression-performance.html#alternative-feature-transformation"><i class="fa fa-check"></i><b>2.3.5</b> Alternative Feature Transformation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_model"><i class="fa fa-check"></i><b>2.4</b> Basic model formulation</a></li>
<li class="chapter" data-level="2.5" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_tune"><i class="fa fa-check"></i><b>2.5</b> Model tuning</a></li>
<li class="chapter" data-level="2.6" data-path="regression-performance.html"><a href="regression-performance.html#cv"><i class="fa fa-check"></i><b>2.6</b> Cross Validation for Generalization</a></li>
<li class="chapter" data-level="2.7" data-path="regression-performance.html"><a href="regression-performance.html#reg_perf_eval"><i class="fa fa-check"></i><b>2.7</b> Model evaluation</a><ul>
<li class="chapter" data-level="2.7.1" data-path="regression-performance.html"><a href="regression-performance.html#regression-models"><i class="fa fa-check"></i><b>2.7.1</b> Regression models</a></li>
<li class="chapter" data-level="2.7.2" data-path="regression-performance.html"><a href="regression-performance.html#classification-models"><i class="fa fa-check"></i><b>2.7.2</b> Classification models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regularized-regression.html"><a href="regularized-regression.html"><i class="fa fa-check"></i><b>3</b> Regularized Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-req"><i class="fa fa-check"></i><b>3.1</b> Prerequisites</a></li>
<li class="chapter" data-level="3.2" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-pros-cons"><i class="fa fa-check"></i><b>3.2</b> Advantages &amp; Disadvantages</a></li>
<li class="chapter" data-level="3.3" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-why"><i class="fa fa-check"></i><b>3.3</b> The Idea</a><ul>
<li class="chapter" data-level="3.3.1" data-path="regularized-regression.html"><a href="regularized-regression.html#multicollinearity"><i class="fa fa-check"></i><b>3.3.1</b> 1. Multicollinearity</a></li>
<li class="chapter" data-level="3.3.2" data-path="regularized-regression.html"><a href="regularized-regression.html#insufficient-solution"><i class="fa fa-check"></i><b>3.3.2</b> 2. Insufficient solution</a></li>
<li class="chapter" data-level="3.3.3" data-path="regularized-regression.html"><a href="regularized-regression.html#interpretability"><i class="fa fa-check"></i><b>3.3.3</b> 3. Interpretability</a></li>
<li class="chapter" data-level="3.3.4" data-path="regularized-regression.html"><a href="regularized-regression.html#regularized_regress"><i class="fa fa-check"></i><b>3.3.4</b> Regularized Models</a><ul>
<li class="chapter" data-level="3.3.4.1" data-path="regularized-regression.html"><a href="regularized-regression.html#ridge"><i class="fa fa-check"></i><b>3.3.4.1</b> Ridge penalty</a></li>
<li class="chapter" data-level="3.3.4.2" data-path="regularized-regression.html"><a href="regularized-regression.html#lasso"><i class="fa fa-check"></i><b>3.3.4.2</b> Lasso penalty</a></li>
<li class="chapter" data-level="3.3.4.3" data-path="regularized-regression.html"><a href="regularized-regression.html#elastic"><i class="fa fa-check"></i><b>3.3.4.3</b> Elastic nets</a></li>
</ul></li>
<li class="chapter" data-level="3.3.5" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-tuning"><i class="fa fa-check"></i><b>3.3.5</b> Tuning</a></li>
<li class="chapter" data-level="3.3.6" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-pkg-implementation"><i class="fa fa-check"></i><b>3.3.6</b> Package implementation</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-regression"><i class="fa fa-check"></i><b>3.4</b> Implementation: Regression</a><ul>
<li class="chapter" data-level="3.4.1" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glm-glmnet"><i class="fa fa-check"></i><b>3.4.1</b> <code>glmnet</code></a><ul>
<li class="chapter" data-level="3.4.1.1" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glmnet-basic"><i class="fa fa-check"></i><b>3.4.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.4.1.2" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glmnet-tune"><i class="fa fa-check"></i><b>3.4.1.2</b> Tuning</a></li>
<li class="chapter" data-level="3.4.1.3" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glmnet-visualizing"><i class="fa fa-check"></i><b>3.4.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="3.4.1.4" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-glmnet-predict"><i class="fa fa-check"></i><b>3.4.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="3.4.2" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-regularize-h2o"><i class="fa fa-check"></i><b>3.4.2</b> <code>h2o</code></a><ul>
<li class="chapter" data-level="3.4.2.1" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-h2o-basic"><i class="fa fa-check"></i><b>3.4.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.4.2.2" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-h2o-tune"><i class="fa fa-check"></i><b>3.4.2.2</b> Tuning</a></li>
<li class="chapter" data-level="3.4.2.3" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-h2o-viz"><i class="fa fa-check"></i><b>3.4.2.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="3.4.2.4" data-path="regularized-regression.html"><a href="regularized-regression.html#regression-h2o-predict"><i class="fa fa-check"></i><b>3.4.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-binary-classification"><i class="fa fa-check"></i><b>3.5</b> Implementation: Binary Classification</a><ul>
<li class="chapter" data-level="3.5.1" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binary-glm-glmnet"><i class="fa fa-check"></i><b>3.5.1</b> <code>glmnet</code></a><ul>
<li class="chapter" data-level="3.5.1.1" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binary-glmnet-basic"><i class="fa fa-check"></i><b>3.5.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.5.1.2" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binaryglmnet-tune"><i class="fa fa-check"></i><b>3.5.1.2</b> Tuning</a></li>
<li class="chapter" data-level="3.5.1.3" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binary-glmnet-visualizing"><i class="fa fa-check"></i><b>3.5.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="3.5.1.4" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binary-glmnet-predict"><i class="fa fa-check"></i><b>3.5.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="3.5.2" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-binaryglm-h2o"><i class="fa fa-check"></i><b>3.5.2</b> <code>h2o</code></a><ul>
<li class="chapter" data-level="3.5.2.1" data-path="regularized-regression.html"><a href="regularized-regression.html#h2o-glm-classification-binary-basic"><i class="fa fa-check"></i><b>3.5.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.5.2.2" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-binary-tune"><i class="fa fa-check"></i><b>3.5.2.2</b> Tuning</a></li>
<li class="chapter" data-level="3.5.2.3" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-binary-viz"><i class="fa fa-check"></i><b>3.5.2.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="3.5.2.4" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-binary-predict"><i class="fa fa-check"></i><b>3.5.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-multinomial-classification"><i class="fa fa-check"></i><b>3.6</b> Implementation: Multinomial Classification</a><ul>
<li class="chapter" data-level="3.6.1" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glm-glmnet"><i class="fa fa-check"></i><b>3.6.1</b> <code>glmnet</code></a><ul>
<li class="chapter" data-level="3.6.1.1" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glmnet-basic"><i class="fa fa-check"></i><b>3.6.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.6.1.2" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glmnet-tune"><i class="fa fa-check"></i><b>3.6.1.2</b> Tuning</a></li>
<li class="chapter" data-level="3.6.1.3" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glmnet-visualizing"><i class="fa fa-check"></i><b>3.6.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="3.6.1.4" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multi-glmnet-predict"><i class="fa fa-check"></i><b>3.6.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="3.6.2" data-path="regularized-regression.html"><a href="regularized-regression.html#classification-multinomial-glm-h2o"><i class="fa fa-check"></i><b>3.6.2</b> <code>h2o</code></a><ul>
<li class="chapter" data-level="3.6.2.1" data-path="regularized-regression.html"><a href="regularized-regression.html#h2o-glm-classification-multinomial-basic"><i class="fa fa-check"></i><b>3.6.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="3.6.2.2" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-multinomial-tune"><i class="fa fa-check"></i><b>3.6.2.2</b> Tuning</a></li>
<li class="chapter" data-level="3.6.2.3" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-multinomial-viz"><i class="fa fa-check"></i><b>3.6.2.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="3.6.2.4" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-h2o-classification-multinomial-predict"><i class="fa fa-check"></i><b>3.6.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="regularized-regression.html"><a href="regularized-regression.html#glm-learning"><i class="fa fa-check"></i><b>3.7</b> Learning More</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>4</b> Random Forest</a><ul>
<li class="chapter" data-level="4.1" data-path="random-forest.html"><a href="random-forest.html#rf-requirements"><i class="fa fa-check"></i><b>4.1</b> Prerequisites</a></li>
<li class="chapter" data-level="4.2" data-path="random-forest.html"><a href="random-forest.html#rf-proscons"><i class="fa fa-check"></i><b>4.2</b> Advantages &amp; Disadvantages</a></li>
<li class="chapter" data-level="4.3" data-path="random-forest.html"><a href="random-forest.html#rf-idea"><i class="fa fa-check"></i><b>4.3</b> The Idea</a><ul>
<li class="chapter" data-level="4.3.1" data-path="random-forest.html"><a href="random-forest.html#rf-oob"><i class="fa fa-check"></i><b>4.3.1</b> OOB error vs. test set error</a></li>
<li class="chapter" data-level="4.3.2" data-path="random-forest.html"><a href="random-forest.html#rf-tune"><i class="fa fa-check"></i><b>4.3.2</b> Tuning</a></li>
<li class="chapter" data-level="4.3.3" data-path="random-forest.html"><a href="random-forest.html#rf-pkgs"><i class="fa fa-check"></i><b>4.3.3</b> Package implementation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="random-forest.html"><a href="random-forest.html#rf-regression"><i class="fa fa-check"></i><b>4.4</b> Implementation: Regression</a><ul>
<li class="chapter" data-level="4.4.1" data-path="random-forest.html"><a href="random-forest.html#ranger-regression"><i class="fa fa-check"></i><b>4.4.1</b> <code>ranger</code></a><ul>
<li class="chapter" data-level="4.4.1.1" data-path="random-forest.html"><a href="random-forest.html#ranger-regression-basic"><i class="fa fa-check"></i><b>4.4.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.4.1.2" data-path="random-forest.html"><a href="random-forest.html#ranger-regression-tune"><i class="fa fa-check"></i><b>4.4.1.2</b> Tuning</a></li>
<li class="chapter" data-level="4.4.1.3" data-path="random-forest.html"><a href="random-forest.html#ranger-regression-viz"><i class="fa fa-check"></i><b>4.4.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="4.4.1.4" data-path="random-forest.html"><a href="random-forest.html#ranger-regression-predic"><i class="fa fa-check"></i><b>4.4.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="4.4.2" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-regression"><i class="fa fa-check"></i><b>4.4.2</b> <code>h20</code></a><ul>
<li class="chapter" data-level="4.4.2.1" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-regression-basic"><i class="fa fa-check"></i><b>4.4.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.4.2.2" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-regression-tune"><i class="fa fa-check"></i><b>4.4.2.2</b> Tuning</a></li>
<li class="chapter" data-level="4.4.2.3" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-regression-viz"><i class="fa fa-check"></i><b>4.4.2.3</b> Visualizing results</a></li>
<li class="chapter" data-level="4.4.2.4" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-regression-predict"><i class="fa fa-check"></i><b>4.4.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="random-forest.html"><a href="random-forest.html#rf-binary-classification"><i class="fa fa-check"></i><b>4.5</b> Implementation: Binary Classification</a><ul>
<li class="chapter" data-level="4.5.1" data-path="random-forest.html"><a href="random-forest.html#ranger-rf-binary-classification"><i class="fa fa-check"></i><b>4.5.1</b> <code>ranger</code></a><ul>
<li class="chapter" data-level="4.5.1.1" data-path="random-forest.html"><a href="random-forest.html#ranger-binary-classification-basic"><i class="fa fa-check"></i><b>4.5.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.5.1.2" data-path="random-forest.html"><a href="random-forest.html#ranger-rf-binary-classification-tune"><i class="fa fa-check"></i><b>4.5.1.2</b> Tuning</a></li>
<li class="chapter" data-level="4.5.1.3" data-path="random-forest.html"><a href="random-forest.html#ranger-rf-binary-classification-viz"><i class="fa fa-check"></i><b>4.5.1.3</b> Visualizing results</a></li>
<li class="chapter" data-level="4.5.1.4" data-path="random-forest.html"><a href="random-forest.html#ranger-rf-binary-classification-predict"><i class="fa fa-check"></i><b>4.5.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="4.5.2" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-binary-classification"><i class="fa fa-check"></i><b>4.5.2</b> <code>h20</code></a><ul>
<li class="chapter" data-level="4.5.2.1" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-binary-classification-basic"><i class="fa fa-check"></i><b>4.5.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.5.2.2" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-multi-classification-tune"><i class="fa fa-check"></i><b>4.5.2.2</b> Tuning</a></li>
<li class="chapter" data-level="4.5.2.3" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-binary-classification-viz"><i class="fa fa-check"></i><b>4.5.2.3</b> Visualizing results</a></li>
<li class="chapter" data-level="4.5.2.4" data-path="random-forest.html"><a href="random-forest.html#h2o-rf-binary-classification-predict"><i class="fa fa-check"></i><b>4.5.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="random-forest.html"><a href="random-forest.html#rf-multi"><i class="fa fa-check"></i><b>4.6</b> Implementation: Multinomial Classification</a><ul>
<li class="chapter" data-level="4.6.1" data-path="random-forest.html"><a href="random-forest.html#rf-ranger-multi"><i class="fa fa-check"></i><b>4.6.1</b> <code>ranger</code></a><ul>
<li class="chapter" data-level="4.6.1.1" data-path="random-forest.html"><a href="random-forest.html#ranger-multi-basic"><i class="fa fa-check"></i><b>4.6.1.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.6.1.2" data-path="random-forest.html"><a href="random-forest.html#ranger-multi-tune"><i class="fa fa-check"></i><b>4.6.1.2</b> Tuning</a></li>
<li class="chapter" data-level="4.6.1.3" data-path="random-forest.html"><a href="random-forest.html#ranger-multi-viz"><i class="fa fa-check"></i><b>4.6.1.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="4.6.1.4" data-path="random-forest.html"><a href="random-forest.html#ranger-multi-predict"><i class="fa fa-check"></i><b>4.6.1.4</b> Predicting</a></li>
</ul></li>
<li class="chapter" data-level="4.6.2" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi"><i class="fa fa-check"></i><b>4.6.2</b> <code>h2o</code></a><ul>
<li class="chapter" data-level="4.6.2.1" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi-basic"><i class="fa fa-check"></i><b>4.6.2.1</b> Basic implementation</a></li>
<li class="chapter" data-level="4.6.2.2" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi-tune"><i class="fa fa-check"></i><b>4.6.2.2</b> Tuning</a></li>
<li class="chapter" data-level="4.6.2.3" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi-viz"><i class="fa fa-check"></i><b>4.6.2.3</b> Visual interpretation</a></li>
<li class="chapter" data-level="4.6.2.4" data-path="random-forest.html"><a href="random-forest.html#rf-h2o-multi-predict"><i class="fa fa-check"></i><b>4.6.2.4</b> Predicting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="random-forest.html"><a href="random-forest.html#rf-learn"><i class="fa fa-check"></i><b>4.7</b> Learning More</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Hands-on Machine Learning with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-forest" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Random Forest</h1>
<p><img src="images/RF_icon.jpg"  style="float:right; margin: 0px 0px 0px 10px; width: 22%; height: 22%;" /> <strong><em>Random forests</em></strong> are a modification of decision trees and bagging that builds a large collection of <em>de-correlated</em> trees to reduce overfitting (aka variance). They have become a very popular “out-of-the-box” learning algorithm that enjoys good predictive performance and easy hyperparameter tuning. Many modern implementations of random forests algorithms exist; however, Leo Breiman’s algorithm <span class="citation">(Breiman <a href="#ref-breiman2001random">2001</a>)</span> has largely become the authoritative procedure. This chapter will cover the fundamentals of random forests.</p>
<div id="rf-requirements" class="section level2">
<h2><span class="header-section-number">4.1</span> Prerequisites</h2>
<div class="rmdwarning">
<p>
Any tutorial on random forests (RF) should also include a review of decision trees, as these are models that are ensembled together to create the random forest model – or put another way, the “trees that comprise the forest.” Much of the complexity and detail of the random forest algorithm occurs within the individual decision trees and therefore it’s important to understand decision trees to understand the RF algorithm as a whole. Therefore, before proceeding, it is recommended that you read through <a href="http://uc-r.github.io/regression_trees" class="uri">http://uc-r.github.io/regression_trees</a> prior to continuing.
</p>
</div>
<p>This chapter leverages the following packages. Some of these packages play a supporting role; however, the emphasis is on how to implement random forests with the <code>ranger</code> <span class="citation">(Wright and Ziegler <a href="#ref-R-ranger">2017</a>)</span> and <code>h2o</code> packages.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rsample)  <span class="co"># data splitting </span>
<span class="kw">library</span>(ranger)   <span class="co"># a fast c++ implementation of the random forest algorithm</span>
<span class="kw">library</span>(h2o)      <span class="co"># a java-based platform</span>
<span class="kw">library</span>(vip)      <span class="co"># visualize feature importance </span>
<span class="kw">library</span>(pdp)      <span class="co"># visualize feature effects</span>
<span class="kw">library</span>(ggplot2)  <span class="co"># supports visualization</span>
<span class="kw">library</span>(dplyr)    <span class="co"># basic data transformation</span></code></pre></div>
</div>
<div id="rf-proscons" class="section level2">
<h2><span class="header-section-number">4.2</span> Advantages &amp; Disadvantages</h2>
<p><strong>Advantages:</strong></p>
<ul>
<li>Typically have very good performance.</li>
<li>Remarkably good “out-of-the box” - very little tuning required.</li>
<li>Built-in validation set - don’t need to sacrifice data for extra validation.</li>
<li>Does not overfit.</li>
<li>No data pre-processing required - often works great with categorical and numerical values as is.</li>
<li>Robust to outliers.</li>
<li>Handles missing data - imputation not required.</li>
<li>Provide automatic feature selection.</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Can become slow on large data sets.</li>
<li>Although accurate, often cannot compete with the accuracy of advanced boosting algorithms.</li>
<li>Less interpretable although this is easily addressed with various tools (variable importance, partial dependence plots, LIME, etc.).</li>
</ul>
</div>
<div id="rf-idea" class="section level2">
<h2><span class="header-section-number">4.3</span> The Idea</h2>
<p>Random forests are built on the same fundamental principles as decision trees and bagging (check out this <a href="http://uc-r.github.io/regression_trees">tutorial</a> if you need a refresher on these techniques). Bagging trees introduces a random component in to the tree building process that reduces the variance of a single tree’s prediction and improves predictive performance. However, the trees in bagging are not completely independent of each other since all the original predictors are considered at every split of every tree. Rather, trees from different bootstrap samples typically have similar structure to each other (especially at the top of the tree) due to underlying relationships.</p>
<p>For example, if we create six decision trees with different bootstrapped samples of the <a href="(http://lib.stat.cmu.edu/datasets/boston)">Boston housing data</a> <span class="citation">(Harrison Jr and Rubinfeld <a href="#ref-harrison1978hedonic">1978</a>)</span>, we see that the top of the trees all have a very similar structure. Although there are 15 predictor variables to split on, all six trees have both <code>lstat</code> and <code>rm</code> variables driving the first few splits.</p>
<div class="figure" style="text-align: center"><span id="fig:boston-trees"></span>
<img src="images/Boston-6-trees.png" alt="Six decision trees based on different bootstrap samples." width="100%" height="100%" />
<p class="caption">
Figure 4.1: Six decision trees based on different bootstrap samples.
</p>
</div>
<p>This characteristic is known as <em>tree correlation</em> and prevents bagging from optimally reducing variance of the predictive values. In order to reduce variance further, we need to minimize the amount of correlation between the trees. This can be achieved by injecting more randomness into the tree-growing process. Random forests achieve this in two ways:</p>
<ol style="list-style-type: decimal">
<li><strong>Bootstrap</strong>: similar to bagging, each tree is grown to a bootstrap resampled data set, which makes them different and <em>somewhat</em> decorrelates them.</li>
<li><strong>Split-variable randomization</strong>: each time a split is to be performed, the search for the split variable is limited to a random subset of <em>m</em> of the <em>p</em> variables. Typical default values are <span class="math inline">\(m = \frac{p}{3}\)</span> (regression trees) and <span class="math inline">\(m = \sqrt{p}\)</span> (classification trees) but this should be considered a tuning parameter. When <span class="math inline">\(m = p\)</span>, the randomization amounts to using only step 1 and is the same as <em>bagging</em>.</li>
</ol>
<p>The basic algorithm for a regression or classification random forest can be generalized to the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span>.  Given training data set
<span class="dv">2</span>.  Select number of trees to <span class="kw">build</span> (ntrees)
<span class="dv">3</span>.  <span class="cf">for</span> i =<span class="st"> </span><span class="dv">1</span> to ntrees do
<span class="dv">4</span>.  <span class="op">|</span><span class="st">  </span>Generate a bootstrap sample of the original data
<span class="dv">5</span>.  <span class="op">|</span><span class="st">  </span>Grow a regression or classification tree to the bootstrapped data
<span class="dv">6</span>.  <span class="op">|</span><span class="st">  </span><span class="cf">for</span> each split do
<span class="dv">7</span>.  <span class="op">|</span><span class="st">  </span><span class="er">|</span><span class="st"> </span>Select m variables at random from all p variables
<span class="dv">8</span>.  <span class="op">|</span><span class="st">  </span><span class="er">|</span><span class="st"> </span>Pick the best variable<span class="op">/</span>split<span class="op">-</span>point among the m
<span class="dv">9</span>.  <span class="op">|</span><span class="st">  </span><span class="er">|</span><span class="st"> </span>Split the node into two child nodes
<span class="dv">10</span>. <span class="op">|</span><span class="st">  </span>end
<span class="dv">11</span>. <span class="op">|</span><span class="st"> </span>Use typical tree model stopping criteria to determine when a tree is <span class="kw">complete</span> (but do not prune)
<span class="dv">12</span>. end</code></pre></div>
<p>Since the algorithm randomly selects a bootstrap sample to train on <strong><em>and</em></strong> predictors to use at each split, tree correlation will be lessened beyond bagged trees.</p>
<div id="rf-oob" class="section level3">
<h3><span class="header-section-number">4.3.1</span> OOB error vs. test set error</h3>
<p>Similar to bagging, a natural benefit of the bootstrap resampling process is that random forests have an out-of-bag (OOB) sample that provides an efficient and reasonable approximation of the test error. This provides a built-in validation set without any extra work on your part, and you do not need to sacrifice any of your training data to use for validation. This makes identifying the number of trees required to stablize the error rate during tuning more efficient; however, as illustrated below some difference between the OOB error and test error are expected.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="images/OOB_error.png" alt="Random forest out-of-bag error versus validation error." width="100%" height="100%" />
<p class="caption">
Figure 2.1: Random forest out-of-bag error versus validation error.
</p>
</div>
<p>Furthermore, many packages do not keep track of which observations were part of the OOB sample for a given tree and which were not. If you are comparing multiple models to one-another, you’d want to score each on the same validation set to compare performance. Also, although technically it is possible to compute certain metrics such as root mean squared logarithmic error (RMSLE) on the OOB sample, it is not built in to all packages. So if you are looking to compare multiple models or use a slightly less traditional loss function you will likely want to still perform cross validation.</p>
</div>
<div id="rf-tune" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Tuning</h3>
<p>Random forests are fairly easy to tune since there are only a handful of tuning parameters. Typically, the primary concern when starting out is tuning the number of candidate variables to select from at each split. However, there are a few additional hyperparameters that we should be aware of. Although the argument names may differ across packages, these hyperparameters should be present:</p>
<ul>
<li><strong>Number of trees</strong>_: We want enough trees to stabalize the error but using too many trees is unncessarily inefficient, especially when using large data sets.</li>
<li><strong>Number of variables to randomly sample as candidates at each split</strong> (often referred to as <code>mtry</code>): When <code>mtry</code> <span class="math inline">\(=p\)</span> the model equates to bagging. When <code>mtry</code> <span class="math inline">\(=1\)</span> the split variable is completely random, so all variables get a chance but can lead to overly biased results. A common suggestion is to start with 5 values evenly spaced across the range from 2 to <em>p</em>.</li>
<li><strong>Sample size</strong>: the number of samples to train on. The default value is 63.25% of the training set since this is the expected value of unique observations in the bootstrap sample. Lower sample sizes can reduce the training time but may introduce more bias than necessary. Increasing the sample size can increase performance but at the risk of overfitting because it introduces more variance. Typically, when tuning this parameter we stay near the 60-80% range.</li>
<li><strong>Node size</strong>: minimum number of samples within the terminal nodes. Controls the complexity of the trees. Smaller node size allows for deeper, more complex trees and a larger node size results in shallower trees. This is another bias-variance tradeoff where deeper trees introduce more variance (risk of overfitting) and shallower trees introduce more bias (risk of not fully capturing unique patters and relatonships in the data).</li>
<li><strong>Number of terminal nodes</strong>: Another way to control the complexity of the trees. More nodes equates to deeper, more complex trees and less nodes result in shallower trees.</li>
</ul>
</div>
<div id="rf-pkgs" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Package implementation</h3>
<p>There are over 20 random forest packages in R.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> The oldest and most well known implementation of the Random Forest algorithm in R is the <code>randomForest</code> package.</p>
<div class="rmdwarning">
<p>
<code>randomForest</code> is not a recommended package because as your data sets grow in size <code>randomForest</code> does not scale well (although you can parallelize with <code>foreach</code>). Instead, we recommend you use the <code>ranger</code> and <code>h2o</code> packages.
</p>
</div>
<p>Since <code>randomForest</code> does not scale well to many of the data set sizes that organizations analyze, we will demonstrate how to implement the random forest algorithm with two fast, efficient, and highly recommended packages:</p>
<ul>
<li><a href="https://github.com/imbs-hl/ranger"><code>ranger</code></a>: a C++ implementation of Brieman’s random forest algorithm and particularly well suited for high dimensional data. The original paper describing <code>ranger</code> and providing benchmarking to other packages can be found <a href="http://arxiv.org/pdf/1508.04409v1.pdf">here</a>. Features include<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>:
<ul>
<li>Classification, regression, probability estimation and survival forests are supported.</li>
<li>Multi-threaded capabilities for optimal speed.</li>
<li>Excellent speed and support for high-dimensional or wide data.</li>
<li>Not as fast for “tall &amp; skinny” data (many rows, few columns).</li>
<li>GPL-3 licensed.</li>
</ul></li>
<li><a href="https://cran.r-project.org/web/packages/gamboostLSS/index.html"><code>h2o</code></a>: The <code>h2o</code> R package is a powerful and efficient java-based interface that allows for local and cluster-based deployment. It comes with a fairly comprehensive <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html">online resource</a> that includes methodology and code documentation along with tutorials. Features include:
<ul>
<li>Automated feature pre-processing (one-hot encode &amp; standardization).</li>
<li>Built-in cross validation.</li>
<li>Built-in grid search capabilities.</li>
<li>Provides automatic early stopping for faster grid searches.</li>
<li>Supports the following distributions: “guassian”, “binomial”, “multinomial”, “poisson”, “gamma”, “tweedie”.</li>
<li>Uses histogram approximations of continuous variables for speedup on “long data” (many rows).</li>
<li>Distributed and parallelized computation on either a single node or a multi-node cluster.</li>
<li>Model export in plain Java code for deployment in production environments.</li>
</ul></li>
</ul>
</div>
</div>
<div id="rf-regression" class="section level2">
<h2><span class="header-section-number">4.4</span> Implementation: Regression</h2>
<p>To illustrate various regularization concepts for a regression problem we will use the Ames, IA housing data, where our intent is to predict <code>Sale_Price</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create training (70%) and test (30%) sets for the AmesHousing::make_ames() data.</span>
<span class="co"># Use set.seed for reproducibility</span>

<span class="kw">set.seed</span>(<span class="dv">123</span>)
ames_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(AmesHousing<span class="op">::</span><span class="kw">make_ames</span>(), <span class="dt">prop =</span> .<span class="dv">7</span>, <span class="dt">strata =</span> <span class="st">&quot;Sale_Price&quot;</span>)
ames_train &lt;-<span class="st"> </span><span class="kw">training</span>(ames_split)
ames_test  &lt;-<span class="st"> </span><span class="kw">testing</span>(ames_split)</code></pre></div>
<div class="rmdtip">
<p>
Tree-based algorithms typically perform very well without preprocessing the data (i.e. one-hot encoding, normalizing, standardizing).
</p>
</div>
<div id="ranger-regression" class="section level3">
<h3><span class="header-section-number">4.4.1</span> <code>ranger</code></h3>
<div id="ranger-regression-basic" class="section level4">
<h4><span class="header-section-number">4.4.1.1</span> Basic implementation</h4>
<p><code>ranger::ranger</code> uses the formula method for specifying our model. Below we apply the default <code>ranger</code> model specifying to model <code>Sale_Price</code> as a function of all features in our data set. The key arguments to the <code>ranger</code> call are:</p>
<ul>
<li><code>formula</code>: formula specification</li>
<li><code>data</code>: training data</li>
<li><code>num.trees</code>: number of trees in the forest</li>
<li><code>mtry</code>: randomly selected predictor variables at each split. Default is <span class="math inline">\(\texttt{floor}(\sqrt{\texttt{number of features}})\)</span>; however, for regression problems the preferred <code>mtry</code> to start with is <span class="math inline">\(\texttt{floor}(\frac{\texttt{number of features}}{3}) = \texttt{floor}(\frac{92}{3}) = 30\)</span></li>
<li><code>respect.unordered.factors</code>: specifies how to treat unordered factor variables. We recommend setting this to “order” for regression. See <span class="citation">Friedman, Hastie, and Tibshirani (<a href="#ref-esl">2001</a>)</span>, chapter 9.2.4 for details.</li>
<li><code>seed</code>: because this is a random algorithm, you will set the seed to get reproducible results</li>
</ul>
<div class="rmdnote">
<p>
By default, <code>ranger</code> will provide the computation status and estimated remaining time; however, to reduce output in this tutorial this is turned off with <code>verbose = FALSE</code>.
</p>
</div>
<p>As the model results show, averaging across all 500 trees provides an OOB <span class="math inline">\(MSE = 615848303\)</span> (<span class="math inline">\(RMSE \approx 24816\)</span>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># number of features</span>
features &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">names</span>(ames_train), <span class="st">&quot;Sale_Price&quot;</span>)

<span class="co"># perform basic random forest model</span>
m1_ranger &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula    =</span> Sale_Price <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data       =</span> ames_train, 
  <span class="dt">num.trees  =</span> <span class="dv">500</span>,
  <span class="dt">mtry       =</span> <span class="kw">floor</span>(<span class="kw">length</span>(features) <span class="op">/</span><span class="st"> </span><span class="dv">3</span>),
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose    =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed       =</span> <span class="dv">123</span>
  )

<span class="co"># look at results</span>
m1_ranger
## Ranger result
## 
## Call:
##  ranger(formula = Sale_Price ~ ., data = ames_train, num.trees = 500,      mtry = floor(length(features)/3), respect.unordered.factors = &quot;order&quot;,      verbose = FALSE, seed = 123) 
## 
## Type:                             Regression 
## Number of trees:                  500 
## Sample size:                      2054 
## Number of independent variables:  80 
## Mtry:                             26 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       615848303 
## R squared (OOB):                  0.9013317

<span class="co"># compute RMSE (RMSE = square root of MSE)</span>
<span class="kw">sqrt</span>(m1_ranger<span class="op">$</span>prediction.error)
## [1] 24816.29</code></pre></div>
<p>One of the benefits of tree-based methods is they do not require preprocessing steps such as normalization and standardization of the response and/or predictor variables. However, because these methods do not require these steps does not mean you should not assess their impact. Sometimes normalizing and standardizing the data can improve performance. In the following code we compare a basic random forest model on unprocessed data to one on processed data (normalized, standardized, and zero variance features removded).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create validation set</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)
split2 &lt;-<span class="st"> </span><span class="kw">initial_split</span>(ames_train, <span class="dt">prop =</span> .<span class="dv">8</span>, <span class="dt">strata =</span> <span class="st">&quot;Sale_Price&quot;</span>)
train_tran &lt;-<span class="st"> </span><span class="kw">training</span>(split2)
validation &lt;-<span class="st"> </span><span class="kw">testing</span>(split2)


<span class="co">#-------------------------Unprocessed variables-------------------------#</span>

<span class="co"># number of features in unprocessed data</span>
m &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">setdiff</span>(<span class="kw">names</span>(train_tran), <span class="st">&quot;Sale_Price&quot;</span>))

<span class="co"># perform basic random forest model on unprocessed data</span>
m1_ranger_unprocessed &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula    =</span> Sale_Price <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data       =</span> train_tran, 
  <span class="dt">num.trees  =</span> <span class="dv">500</span>,
  <span class="dt">mtry       =</span> m,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose    =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed       =</span> <span class="dv">123</span>
  )


<span class="co">#--------------------------Processed variables--------------------------#</span>

<span class="co"># preprocess features</span>
feature_process &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">preProcess</span>(
  train_tran[, features],
  <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;YeoJohnson&quot;</span>, <span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>, <span class="st">&quot;zv&quot;</span>)
)

train_tran &lt;-<span class="st"> </span><span class="kw">predict</span>(feature_process, train_tran)

<span class="co"># preprocess response</span>
train_tran<span class="op">$</span>Sale_Price &lt;-<span class="st"> </span><span class="kw">log</span>(train_tran<span class="op">$</span>Sale_Price) 

<span class="co"># number of features in processed data</span>
m &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">setdiff</span>(<span class="kw">names</span>(train_tran), <span class="st">&quot;Sale_Price&quot;</span>))

<span class="co"># perform basic random forest model on processed data</span>
m1_ranger_processed &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula    =</span> Sale_Price <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data       =</span> train_tran, 
  <span class="dt">num.trees  =</span> <span class="dv">500</span>,
  <span class="dt">mtry       =</span> m,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose    =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed       =</span> <span class="dv">123</span>
  )</code></pre></div>
<p>We can now apply each model to the validation set. For the second (preprocessed) model, we re-transform our predicted values back to the normal units and we compute the RMSE for both. Now we see that our original model on unpreprocessed data is performing just as well as, if not better than, the second model on the processed data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># apply unpreprocessed model</span>
m1_pred &lt;-<span class="st"> </span><span class="kw">predict</span>(m1_ranger_unprocessed, validation)
caret<span class="op">::</span><span class="kw">RMSE</span>(m1_pred<span class="op">$</span>predictions, validation<span class="op">$</span>Sale_Price)
## [1] 22302.02

<span class="co"># preprocess features</span>
valid_tran &lt;-<span class="st"> </span><span class="kw">predict</span>(feature_process, validation)

<span class="co"># apply preprocessed model</span>
m1_tran_pred &lt;-<span class="st"> </span><span class="kw">predict</span>(m1_ranger_processed, valid_tran)
m1_processed_pred &lt;-<span class="st"> </span><span class="kw">expm1</span>(m1_tran_pred<span class="op">$</span>predictions)
caret<span class="op">::</span><span class="kw">RMSE</span>(m1_processed_pred, validation<span class="op">$</span>Sale_Price)
## [1] 24281.47</code></pre></div>
</div>
<div id="ranger-regression-tune" class="section level4">
<h4><span class="header-section-number">4.4.1.2</span> Tuning</h4>
<p>With the <code>ranger</code> function we can tune various hyperparameters mentioned in the general <a href="random-forest.html#rf-tune">tuning</a> section. For example, the following model adjusts:</p>
<ul>
<li><code>num.trees</code>: increase number of trees to 750</li>
<li><code>mtry</code>: reduce number of predictor variables to randomly select at each split to 20</li>
<li><code>min.node.size</code>: reduce minimum node size to 3 (default is 5 for regression)</li>
<li><code>sample.fraction</code>: increase training set to 70%</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2_ranger &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> Sale_Price <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> ames_train, 
  <span class="dt">num.trees       =</span> <span class="dv">750</span>,
  <span class="dt">mtry            =</span> <span class="dv">20</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">3</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">70</span>
  )

<span class="co"># RMSE</span>
<span class="kw">sqrt</span>(m2_ranger<span class="op">$</span>prediction.error)
## [1] 25298.61

<span class="co"># model results</span>
m2_ranger
## Ranger result
## 
## Call:
##  ranger(formula = Sale_Price ~ ., data = ames_train, num.trees = 750,      mtry = 20, respect.unordered.factors = &quot;order&quot;, verbose = FALSE,      seed = 123, min.node.size = 3, sample.fraction = 0.7) 
## 
## Type:                             Regression 
## Number of trees:                  750 
## Sample size:                      2054 
## Number of independent variables:  80 
## Mtry:                             20 
## Target node size:                 3 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       640019634 
## R squared (OOB):                  0.8974591</code></pre></div>
<p>We can continue to adjust these settings individually to identify the optimal combination; however, this becomes tedious when you want to explore a larger grid search. To perform a larger grid search across several hyperparameters we’ll need to create a grid and loop through each hyperparameter combination and evaluate the model. First we want to construct our grid of hyperparameters. We’re going to search across 80 different models with varying number of trees, <code>mtry</code>, minimum node size, and sample size.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># hyperparameter grid search</span>
hyper_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(
  <span class="dt">num.trees  =</span> <span class="kw">seq</span>(<span class="dv">250</span>, <span class="dv">500</span>, <span class="dv">750</span>),
  <span class="dt">mtry       =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">40</span>, <span class="dt">by =</span> <span class="dv">5</span>),
  <span class="dt">node_size  =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dt">by =</span> <span class="dv">3</span>),
  <span class="dt">sample_size =</span> <span class="kw">c</span>(.<span class="dv">55</span>, .<span class="dv">632</span>, .<span class="dv">70</span>, .<span class="dv">80</span>),
  <span class="dt">OOB_RMSE   =</span> <span class="dv">0</span>
)

<span class="co"># total number of combinations</span>
<span class="kw">nrow</span>(hyper_grid)
## [1] 80

<span class="co"># hyperparameter grid</span>
<span class="kw">head</span>(hyper_grid)
##   num.trees mtry node_size sample_size OOB_RMSE
## 1       250   20         1        0.55        0
## 2       250   25         1        0.55        0
## 3       250   30         1        0.55        0
## 4       250   35         1        0.55        0
## 5       250   40         1        0.55        0
## 6       250   20         4        0.55        0</code></pre></div>
<p>We can now loop through each hyperparameter combination. Note that we set the random number generator seed. This allows us to consistently sample the same observations for each sample size and make it more clear the impact that each change makes.</p>
<div class="rmdtip">
<p>
This full grid search ran for about <strong>2.5</strong> minutes before completing. Larger grid searches like these can become time consuming as your data set increases in dimensions. The <code>h2o</code> package provides alternative approaches to search through larger grid spaces.
</p>
</div>
<p>Our OOB RMSE ranges between ~25021-26089. Our top 10 performing models all have RMSE values in the low 25000 range and the results show that we can use a smaller number of trees than the default and models with slighly larger sample size appear to perform best. At first glance, no definitive evidence suggests that altering <code>mtry</code> or <code>node_size</code> have a sizable impact.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(hyper_grid)) {
  
  <span class="co"># train model</span>
  model &lt;-<span class="st"> </span><span class="kw">ranger</span>(
    <span class="dt">formula         =</span> Sale_Price <span class="op">~</span><span class="st"> </span>., 
    <span class="dt">data            =</span> ames_train,
    <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
    <span class="dt">seed            =</span> <span class="dv">123</span>,
    <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
    <span class="dt">mtry            =</span> hyper_grid<span class="op">$</span>mtry[i],
    <span class="dt">min.node.size   =</span> hyper_grid<span class="op">$</span>node_size[i],
    <span class="dt">sample.fraction =</span> hyper_grid<span class="op">$</span>sample_size[i]
  )
  
  <span class="co"># add OOB error to grid</span>
  hyper_grid<span class="op">$</span>OOB_RMSE[i] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(model<span class="op">$</span>prediction.error)
}

hyper_grid <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">arrange</span>(OOB_RMSE) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>(<span class="dv">10</span>)
##    num.trees mtry node_size sample_size OOB_RMSE
## 1        250   35         1       0.800 25020.85
## 2        250   35         4       0.800 25044.19
## 3        250   25         4       0.700 25093.52
## 4        250   25         1       0.700 25117.58
## 5        250   20         4       0.800 25122.44
## 6        250   40         4       0.800 25133.63
## 7        250   40         1       0.800 25134.92
## 8        250   40         7       0.800 25140.17
## 9        250   30         1       0.800 25152.47
## 10       250   40         4       0.632 25159.07</code></pre></div>
<p>The above grid search helps to focus where we can further refine our model tuning. As a next step, we would perform additional grid searches that focus in on a refined grid space for sample size and also try a few additional settings of <code>mtry</code> and <code>min.node.size</code> to rule out their effects on performance. However, for brevity we will leave this as an exercise for the reader.</p>
</div>
<div id="ranger-regression-viz" class="section level4">
<h4><span class="header-section-number">4.4.1.3</span> Visual interpretation</h4>
<p>Whereas regularized regression assumes a monotonic linear relationship between features and the response, random forests make no such assumption. Moreover, random forests do not have coefficients to base these relationships on. Consequently, with random forests we can understand the relationship between the features and the response using variable importance plots and partial dependence plots.</p>
<div class="rmdtip">
<p>
Additional model interpretability approaches will be discussed in the <strong><em>Model Interpretability</em></strong> chapter.
</p>
</div>
<div id="ranger-rf-regression-vip" class="section level5">
<h5><span class="header-section-number">4.4.1.3.1</span> Variable importance</h5>
<p>Whereas regularized models used the standardized coefficients to signal importance, random forests have, historically, applied two different approaches to measure variable importance.</p>
<ol style="list-style-type: decimal">
<li><strong>Impurity</strong>: At each split in each tree, compute the improvement in the split-criterion (MSE for regression). Then average the improvement made by each variable across all the trees that the variable is used. The variables with the largest average decrease in MSE are considered most important.</li>
<li><strong>Permutation</strong>: For each tree, the OOB sample is passed down the tree and the prediction accuracy is recorded. Then the values for each variable (one at a time) are randomly permuted and the accuracy is again computed. The decrease in accuracy as a result of this randomly “shaking up” of variable values is averaged over all the trees for each variable. The variables with the largest average decrease in accuracy are considered most important.</li>
</ol>
<p>To compute these variable importance measures with <strong>ranger</strong>, you must include the <code>importance</code> argument.</p>
<div class="rmdtip">
<p>
Once you’ve identified the optimal parameter values from the grid search, you will want to re-run your model with these hyperparameter values.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># re-run model with impurity-based variable importance</span>
m3_ranger_impurity &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> Sale_Price <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> ames_train, 
  <span class="dt">num.trees       =</span> <span class="dv">250</span>,
  <span class="dt">mtry            =</span> <span class="dv">35</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">1</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">80</span>,
  <span class="dt">importance =</span> <span class="st">&#39;impurity&#39;</span>
  )

<span class="co"># re-run model with permutation-based variable importance</span>
m3_ranger_permutation &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> Sale_Price <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> ames_train, 
  <span class="dt">num.trees       =</span> <span class="dv">250</span>,
  <span class="dt">mtry            =</span> <span class="dv">35</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">1</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">80</span>,
  <span class="dt">importance =</span> <span class="st">&#39;permutation&#39;</span>
  )</code></pre></div>
<p>For both options, you can directly access the variable importance values with <code>model_name$variable.importance</code>. However, here we will plot the variable importance using the <code>vip</code> package. Typically, you will not see the same variable importance order between the two options; however, you will often see similar variables at the top of the plots. Consquently, in this example, we can comfortably state that there appears to be enough evidence to suggest that three variables stand out as most influential:</p>
<ul>
<li><code>Overall_Qual</code></li>
<li><code>Gr_Liv_Area</code></li>
<li><code>Neighborhood</code></li>
</ul>
<p>Looking at the next ~10 variables in both plots, you will also see some commonality in influential variables (i.e. <code>Garage_Cars</code>, <code>Bsmt_Qual</code>, <code>Year_Built</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p1 &lt;-<span class="st"> </span><span class="kw">vip</span>(m3_ranger_impurity, <span class="dt">num_features =</span> <span class="dv">25</span>, <span class="dt">bar =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Impurity-based variable importance&quot;</span>)
p2 &lt;-<span class="st"> </span><span class="kw">vip</span>(m3_ranger_permutation, <span class="dt">num_features =</span> <span class="dv">25</span>, <span class="dt">bar =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Permutation-based variable importance&quot;</span>)

gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p1, p2, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:vip-plots"></span>
<img src="04-random-forest_files/figure-html/vip-plots-1.png" alt="Top 25 most important variables based on impurity (left) and permutation (right)." width="864" />
<p class="caption">
Figure 4.2: Top 25 most important variables based on impurity (left) and permutation (right).
</p>
</div>
</div>
<div id="ranger-rf-regression-pdp" class="section level5">
<h5><span class="header-section-number">4.4.1.3.2</span> Partial dependence plots</h5>
<p>After the most relevant variables have been identified, the next step is to attempt to understand how the response variable changes based on these variables. Unlike linear approaches, random forests do not assume a linear relationship. Consequently, we can use partial dependence plots (PDPs) and individual conditional expectation (ICE) curves.</p>
<p>PDPs plot the change in the average predicted value as specified feature(s) vary over their marginal distribution. For example, consider the <code>Gr_Liv_Area</code> variable. In the <strong>h20</strong> regularized regression section (<a href="regularized-regression.html#regression-h2o-viz">3.4.2.3</a>), we saw that the linear model assumed a continously increasing relationship between <code>Gr_Liv_Area</code> and <code>Sale_Price</code>. However, the PDP plot below displays a non-linear relationship where <code>Sale_Price</code> appears to not be influenced by <code>Gr_Liv_Area</code> values below 750 sqft or above 3500 sqft.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># partial dependence of Sale_Price on Gr_Liv_Area</span>
m3_ranger_impurity <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Gr_Liv_Area&quot;</span>, <span class="dt">grid.resolution =</span> <span class="dv">50</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> ames_train)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pdp-GrLiv-Area"></span>
<img src="04-random-forest_files/figure-html/pdp-GrLiv-Area-1.png" alt="The mean predicted sale price as the above ground living area increases." width="384" />
<p class="caption">
Figure 4.3: The mean predicted sale price as the above ground living area increases.
</p>
</div>
<p>Additionally, if we assess the relationship between the <code>Overall_Qual</code> predictor and <code>Sale_Price</code>, we see a continual increase as the overall quality increases. This is more intutive than the results we saw in the regularized regression section (<a href="regularized-regression.html#regression-h2o-viz">3.4.2.3</a>). This may be an indication that the coefficients were biased in the regularized regression models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># partial dependence of Sale_Price on Overall_Qual</span>
m3_ranger_impurity <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Overall_Qual&quot;</span>, <span class="dt">train =</span> <span class="kw">as.data.frame</span>(ames_train)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pdp-Overall-Qual"></span>
<img src="04-random-forest_files/figure-html/pdp-Overall-Qual-1.png" alt="The mean predicted sale price for each level of the overall quality variable." width="768" />
<p class="caption">
Figure 4.4: The mean predicted sale price for each level of the overall quality variable.
</p>
</div>
<p>Individual conditional expectation (ICE) curves <span class="citation">(Goldstein et al. <a href="#ref-goldstein2015peeking">2015</a>)</span> are an extension of PDP plots but, rather than plot the <em>average</em> marginal effect on the response variable, we plot the change in the predicted response variable <strong><em>for each observation</em></strong> as we vary each predictor variable. Below shows the regular ICE curve plot (left) and the centered ICE curves (right). When the curves have a wide range of intercepts and are consequently “stacked” on each other, heterogeneity in the response variable values due to marginal changes in the predictor variable of interest can be difficult to discern. The centered ICE can help draw these inferences out and can highlight any strong heterogeneity in our results.</p>
<p>The plots below show that marginal changes in <code>Gr_Liv_Area</code> have a fairly homogenous effect on our response variable. As <code>Gr_Liv_Area</code> increases, the vast majority of observations show a similar increasing effect on the predicted <code>Sale_Price</code> value. The primary differences is in the magnitude of the increasing effect. However, in the centered ICE plot you see evidence of a few observations that display a different pattern. These observations would be worth looking at more closely.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ice curves of Sale_Price on Gr_Liv_Area</span>
ice1 &lt;-<span class="st"> </span>m3_ranger_impurity <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Gr_Liv_Area&quot;</span>, <span class="dt">grid.resolution =</span> <span class="dv">50</span>, <span class="dt">ice =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> ames_train, <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Non-centered ICE plot&quot;</span>)

ice2 &lt;-<span class="st"> </span>m3_ranger_impurity <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Gr_Liv_Area&quot;</span>, <span class="dt">grid.resolution =</span> <span class="dv">50</span>, <span class="dt">ice =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> ames_train, <span class="dt">alpha =</span> <span class="fl">0.2</span>, <span class="dt">center =</span> <span class="ot">TRUE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Centered ICE plot&quot;</span>)

gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(ice1, ice2, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ice-Gr-Liv-Area"></span>
<img src="04-random-forest_files/figure-html/ice-Gr-Liv-Area-1.png" alt="Non-centered (left) and centered (right) individual conditional expectation curve plots illustrate how changes in above ground square footage influences predicted sale price for all observations." width="864" />
<p class="caption">
Figure 4.5: Non-centered (left) and centered (right) individual conditional expectation curve plots illustrate how changes in above ground square footage influences predicted sale price for all observations.
</p>
</div>
<p>Both PDPs and ICE curves should be assessed for the most influential variables as they help to explain the underlying patterns in the data that the random forest model is picking up.</p>
<div class="rmdnote">
<p>
Check out the <strong><em>Model Interpretation</em></strong> chapter to learn more about visualizing your machine learning models.
</p>
</div>
</div>
</div>
<div id="ranger-regression-predic" class="section level4">
<h4><span class="header-section-number">4.4.1.4</span> Predicting</h4>
<p>Once you’ve found your optimal model, predicting new observations with the <code>ranger</code> model follows the same procedure as most R models. We can apply the <code>predict</code> function and supply it the optimal model and the new data set we’d like to predict on. The result is a list object that includes several attributes about the model used to predict (i.e. number of trees &amp; predictor variables, sample size, tree type). The predicted values we are most concerned with are contained in the <code>predict_object$predictions</code> list item.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict on test set</span>
predict_ranger &lt;-<span class="st"> </span><span class="kw">predict</span>(m3_ranger_impurity, ames_test)

<span class="co"># predict object</span>
<span class="kw">str</span>(predict_ranger)
## List of 5
##  $ predictions              : num [1:876] 130020 157044 224076 251814 376064 ...
##  $ num.trees                : num 250
##  $ num.independent.variables: num 80
##  $ num.samples              : int 876
##  $ treetype                 : chr &quot;Regression&quot;
##  - attr(*, &quot;class&quot;)= chr &quot;ranger.prediction&quot;

<span class="co"># predicted values</span>
<span class="kw">head</span>(predict_ranger<span class="op">$</span>predictions)
## [1] 130020.1 157044.1 224076.1 251813.8 376064.3 365273.1</code></pre></div>
<p>We can use these predicted values to assess the final generalization error, which is slightly lower than our models OOB sample RMSE:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># final model OOB RMSE</span>
<span class="kw">sqrt</span>(m3_ranger_impurity<span class="op">$</span>prediction.error)
## [1] 25197.67

<span class="co"># generalization error</span>
caret<span class="op">::</span><span class="kw">RMSE</span>(predict_ranger<span class="op">$</span>predictions, ames_test<span class="op">$</span>Sale_Price)
## [1] 25148.62</code></pre></div>
</div>
</div>
<div id="h2o-rf-regression" class="section level3">
<h3><span class="header-section-number">4.4.2</span> <code>h20</code></h3>
<p>To perform a random forest model with <strong>h2o</strong>, we first need to initiate our <strong>h2o</strong> session.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.no_progress</span>()
<span class="kw">h2o.init</span>(<span class="dt">max_mem_size =</span> <span class="st">&quot;5g&quot;</span>)
## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     /var/folders/ws/qs4y2bnx1xs_4y9t0zbdjsvh0000gn/T//RtmpF70TJP/h2o_bradboehmke_started_from_r.out
##     /var/folders/ws/qs4y2bnx1xs_4y9t0zbdjsvh0000gn/T//RtmpF70TJP/h2o_bradboehmke_started_from_r.err
## 
## 
## Starting H2O JVM and connecting: .. Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         2 seconds 255 milliseconds 
##     H2O cluster timezone:       America/New_York 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.18.0.11 
##     H2O cluster version age:    2 months and 13 days  
##     H2O cluster name:           H2O_started_from_R_bradboehmke_ply740 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   4.44 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.5.1 (2018-07-02)</code></pre></div>
<p>Next, we need to convert our training and test data to <strong>h2o</strong> objects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># convert training data to h2o object</span>
train_h2o &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(ames_train)

<span class="co"># convert test data to h2o object</span>
test_h2o &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(ames_test)

<span class="co"># set the response column to Sale_Price</span>
response &lt;-<span class="st"> &quot;Sale_Price&quot;</span>

<span class="co"># set the predictor names</span>
predictors &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(ames_train), response)</code></pre></div>
<div id="rf-h2o-regression-basic" class="section level4">
<h4><span class="header-section-number">4.4.2.1</span> Basic implementation</h4>
<p>To perform a random forest model with <code>h2o</code> we use <code>h2o::h2o.randomForest</code>. Keep in mind that <code>h2o</code> uses the name method for specifying our model. Below we apply the default <code>h2o.randomForest</code> model specifying to model <code>Sale_Price</code> as a function of all features in our data set. <code>h2o.randomForest</code> has many arguments that can be adjusted; however, often the default settings perform very well. To start with, a few key arguments in <code>h2o.randomForest</code> to understand include:</p>
<ul>
<li><code>x</code>: names of the predictor variables</li>
<li><code>y</code>: name of the response variable</li>
<li><code>training_frame</code>: training data</li>
<li><code>ntrees</code>: number of trees in the forest (default is 50)</li>
<li><code>mtries</code>: randomly selected predictor variables at each split. Default is <span class="math inline">\(\texttt{floor}(\frac{\texttt{number of features}}{3}) = \texttt{floor}(\frac{92}{3}) = 30\)</span> for regression.</li>
<li><code>categorical_encoding</code>: Decides the encoding scheme for categorical variables. Typically choose one of “Enum” or “SortByResponse” (<code>categorical_encoding = 'SortByResponse'</code> performs similar procedure as <code>respect.unordered.factors = 'order'</code>). For these data we do not see any difference in performance between the two.</li>
<li><code>seed</code>: because this is a random algorithm, you will set the seed to get reproducible results</li>
</ul>
<div class="rmdnote">
<p>
<code>h2o</code> can provide the computation status; however, this feature is turned off by default but can be turned on with <code>verbose = FALSE</code>.
</p>
</div>
<p>As the model results show, averaging across all 250 trees provides an OOB <span class="math inline">\(RMSE \approx 24541\)</span>). These are pretty similar to what we found with the default <code>ranger</code> model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform basic random forest model</span>
m1_h2o &lt;-<span class="st"> </span><span class="kw">h2o.randomForest</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response,
  <span class="dt">training_frame =</span> train_h2o, 
  <span class="dt">ntrees =</span> <span class="dv">250</span>,
  <span class="dt">seed =</span> <span class="dv">123</span>
  )

<span class="co"># look at results</span>
## m1_h2o
## Model Details:
## ==============
## 
## H2ORegressionModel: drf
## Model ID:  DRF_model_R_1532981766487_1 
## Model Summary: 
## 
## 
## H2ORegressionMetrics: drf
## ** Reported on training data. **
## ** Metrics reported on Out-Of-Bag training samples **
## 
## MSE:  602273377
## RMSE:  24541.26
## MAE:  15060.85
## RMSLE:  0.1406867
## Mean Residual Deviance :  602273377</code></pre></div>
<p>One of the benefits of <code>h2o</code> is it allows us to include <code>stopping_</code> arguments, which will stop the modeling automatically once the RMSE metric on the OOB samples stops improving by a certain value (say 1%) for a specified number of consecutive trees. This helps us to identify the number of trees required to stabilize our error metric. Below we see that 49 trees are sufficient.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform basic random forest model</span>
m2_h2o &lt;-<span class="st"> </span><span class="kw">h2o.randomForest</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response,
  <span class="dt">training_frame =</span> train_h2o, 
  <span class="dt">ntrees =</span> <span class="dv">500</span>,
  <span class="dt">seed =</span> <span class="dv">123</span>,
  <span class="dt">stopping_metric =</span> <span class="st">&quot;RMSE&quot;</span>,     <span class="co"># stopping mechanism</span>
  <span class="dt">stopping_rounds =</span> <span class="dv">10</span>,         <span class="co"># number of rounds</span>
  <span class="dt">stopping_tolerance =</span> <span class="fl">0.005</span>    <span class="co"># looking for 0.5% improvement</span>
  )

<span class="co"># look at results</span>
m2_h2o
## Model Details:
## ==============
## 
## H2ORegressionModel: drf
## Model ID:  DRF_model_R_1532981766487_2 
## Model Summary: 
##   number_of_trees number_of_internal_trees model_size_in_bytes min_depth max_depth mean_depth min_leaves max_leaves mean_leaves
## 1              49                       49              758326        20        20   20.00000       1175       1273  1226.34690
## 
## 
## H2ORegressionMetrics: drf
## ** Reported on training data. **
## ** Metrics reported on Out-Of-Bag training samples **
## 
## MSE:  670676969
## RMSE:  25897.43
## MAE:  15741.89
## RMSLE:  0.1434247
## Mean Residual Deviance :  670676969</code></pre></div>
</div>
<div id="rf-h2o-regression-tune" class="section level4">
<h4><span class="header-section-number">4.4.2.2</span> Tuning</h4>
<p><code>h2o.randomForest</code> provides <strong><em>many</em></strong> tuning options. The more common tuning options can be categorized into three purposes:</p>
<ol style="list-style-type: decimal">
<li>Controlling how big your random forest will be:
<ul>
<li><code>ntrees</code>: how many trees in the forest</li>
<li><code>max_depth</code>: maximum depth to which each tree will be built (default is 20)</li>
</ul></li>
<li>Controlling the random components of the model:
<ul>
<li><code>mtries</code>: number of predictor variables to randomly select at each split</li>
<li><code>sample_rate</code>: Row sample rate per tree (default is 63.2%)</li>
</ul></li>
<li>Controlling how the splitting is done
<ul>
<li><code>min_rows</code>: minimum number of observations for a leaf in order to split (default is 1)</li>
</ul></li>
</ol>
<div class="rmdtip">
<p>
There are additional tuning parameters in each of the above categories but their defaults are typically sufficient. You can read about the options <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html">here</a>.
</p>
</div>
<p>We can tune these hyperparameters individually; however, a major benefit of <code>h2o</code> is it provides two different approaches for hyperparameter grid searches:</p>
<ul>
<li><strong>Full cartesian grid search</strong>: examine every combination of hyperparameter settings that we specify,</li>
<li><strong>Random grid search</strong>: jump from one random combination to another and stop once a certain level of improvement has been made, certain amount of time has been exceeded, or a certain amount of models have been ran (or a combination of these have been met).</li>
</ul>
<div id="rf-h2o-regression-tune-full" class="section level5">
<h5><span class="header-section-number">4.4.2.2.1</span> Full cartesian grid search</h5>
<p>First, we can try a comprehensive (full cartesian) grid search, which means we will examine every combination of hyperparameter settings that we specify in <code>hyper_grid.h2o</code>. Here, we search across 320 hyperparameter combinations. You can include <code>ntrees</code> as a hyperparameter; however, its more efficient to set <code>ntrees</code> to a high value and then use early stopping to stop each model once improvement is no longer obtained.</p>
<div class="rmdtip">
<p>
This comprehensive grid search took <strong>56</strong> minutes.
</p>
</div>
<p>The results show a minimum RMSE of $23,792 (slightly less than our optimal <strong>ranger</strong> model), when <code>max_depth = 25</code>, <code>min_rows = 1</code>, <code>mtries = 25</code>, and <code>sample_rate = 80%</code>. Looking at the top 5 models it appears that the primary driving parameters for minimizing MSE are <code>min_rows</code> (smaller is better), <code>mtries</code> (smaller is better), and <code>sample_rate</code> (larger is better).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># hyperparameter grid</span>
hyper_grid.h2o &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">mtries      =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">40</span>, <span class="dt">by =</span> <span class="dv">5</span>),
  <span class="dt">max_depth   =</span> <span class="kw">seq</span>(<span class="dv">15</span>, <span class="dv">30</span>, <span class="dt">by =</span> <span class="dv">5</span>),
  <span class="dt">min_rows    =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dt">by =</span> <span class="dv">3</span>),
  <span class="dt">sample_rate =</span> <span class="kw">c</span>(.<span class="dv">55</span>, .<span class="dv">632</span>, .<span class="dv">70</span>, .<span class="dv">80</span>)
)

<span class="co"># build grid search </span>
grid &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(
  <span class="dt">algorithm =</span> <span class="st">&quot;randomForest&quot;</span>,
  <span class="dt">grid_id =</span> <span class="st">&quot;rf_full_grid&quot;</span>,
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> train_h2o,
  <span class="dt">hyper_params =</span> hyper_grid.h2o,
  <span class="dt">ntrees =</span> <span class="dv">500</span>,
  <span class="dt">seed =</span> <span class="dv">123</span>,
  <span class="dt">stopping_metric =</span> <span class="st">&quot;RMSE&quot;</span>,   
  <span class="dt">stopping_rounds =</span> <span class="dv">10</span>,         
  <span class="dt">stopping_tolerance =</span> <span class="fl">0.005</span>, 
  <span class="dt">search_criteria =</span> <span class="kw">list</span>(<span class="dt">strategy =</span> <span class="st">&quot;Cartesian&quot;</span>)
  )

<span class="co"># collect the results and sort by our model performance metric of choice</span>
full_grid_perf &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(
  <span class="dt">grid_id =</span> <span class="st">&quot;rf_full_grid&quot;</span>, 
  <span class="dt">sort_by =</span> <span class="st">&quot;mse&quot;</span>, 
  <span class="dt">decreasing =</span> <span class="ot">FALSE</span>
  )
<span class="kw">print</span>(full_grid_perf)
## H2O Grid Details
## ================
## 
## Grid ID: rf_full_grid 
## Used hyper parameters: 
##   -  max_depth 
##   -  min_rows 
##   -  mtries 
##   -  sample_rate 
## Number of models: 291 
## Number of failed models: 29 
## 
## Hyper-Parameter Search Summary: ordered by increasing mse
##   max_depth min_rows mtries sample_rate              model_ids                 mse
## 1        25      1.0     25         0.8 rf_full_grid_model_258 5.660696269742714E8
## 2        30      1.0     25         0.8 rf_full_grid_model_259  5.66075155855145E8
## 3        20      1.0     25         0.8 rf_full_grid_model_257  5.66146259929908E8
## 4        30      1.0     20         0.8 rf_full_grid_model_243 5.665494562778755E8
## 5        25      1.0     20         0.8 rf_full_grid_model_242 5.665555943619757E8
## 
## ---
##     max_depth min_rows mtries sample_rate              model_ids                 mse
## 286        25     10.0     35        0.55  rf_full_grid_model_62 8.195309220382509E8
## 287        20     10.0     35        0.55  rf_full_grid_model_61 8.195309220382509E8
## 288        30     10.0     30       0.632 rf_full_grid_model_127 8.266536241339123E8
## 289        25     10.0     30       0.632 rf_full_grid_model_126 8.266536241339123E8
## 290        20     10.0     30       0.632 rf_full_grid_model_125 8.266536241339123E8
## 291        15     10.0     30       0.632 rf_full_grid_model_124 8.266536241339123E8</code></pre></div>
</div>
<div id="rf-h2o-regression-tune-random" class="section level5">
<h5><span class="header-section-number">4.4.2.2.2</span> Random discrete grid search</h5>
<p>Because of the combinatorial explosion, each additional hyperparameter that gets added to our grid search has a huge effect on the time to complete. Consequently, <code>h2o</code> provides an additional grid search path called <strong><em>“RandomDiscrete”</em></strong>, which will jump from one random combination to another and stop once a certain level of improvement has been made, certain amount of time has been exceeded, or a certain amount of models have been ran (or a combination of these have been met). Although using a random discrete search path will likely not find the optimal model, it typically does a good job of finding a very good model.</p>
<div class="rmdtip">
<p>
This comprehensive grid search took <strong>30</strong> minutes.
</p>
</div>
<p>For example, the following code searches the same grid search performed above. We create a random grid search that will stop if none of the last 10 models have managed to have a 0.1% improvement in MSE compared to the best model before that. If we continue to find improvements then I cut the grid search off after 1800 seconds (30 minutes). Our grid search assessed 191 models before stopping due to time. The best model (<code>max_depth = 25</code>, <code>min_rows = 1</code>, <code>mtries = 40</code>, and <code>sample_rate = 0.8</code>) achived an RMSE <span class="math inline">\(\approx \$23,751\)</span>. So although our random search on assessed about half the number of models as the full grid search, the more efficient random search found a near-optimal model relatively speaking.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># random grid search criteria</span>
search_criteria &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">strategy =</span> <span class="st">&quot;RandomDiscrete&quot;</span>,
  <span class="dt">stopping_metric =</span> <span class="st">&quot;mse&quot;</span>,
  <span class="dt">stopping_tolerance =</span> <span class="fl">0.001</span>,
  <span class="dt">stopping_rounds =</span> <span class="dv">10</span>,
  <span class="dt">max_runtime_secs =</span> <span class="dv">60</span><span class="op">*</span><span class="dv">30</span>
  )

<span class="co"># build grid search </span>
random_grid &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(
  <span class="dt">algorithm =</span> <span class="st">&quot;randomForest&quot;</span>,
  <span class="dt">grid_id =</span> <span class="st">&quot;rf_random_grid&quot;</span>,
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> train_h2o,
  <span class="dt">hyper_params =</span> hyper_grid.h2o,
  <span class="dt">ntrees =</span> <span class="dv">500</span>,
  <span class="dt">seed =</span> <span class="dv">123</span>,
  <span class="dt">stopping_metric =</span> <span class="st">&quot;RMSE&quot;</span>,   
  <span class="dt">stopping_rounds =</span> <span class="dv">10</span>,         
  <span class="dt">stopping_tolerance =</span> <span class="fl">0.005</span>, 
  <span class="dt">search_criteria =</span> search_criteria
  )

<span class="co"># collect the results and sort by our model performance metric of choice</span>
random_grid_perf &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(
  <span class="dt">grid_id =</span> <span class="st">&quot;rf_random_grid&quot;</span>, 
  <span class="dt">sort_by =</span> <span class="st">&quot;mse&quot;</span>, 
  <span class="dt">decreasing =</span> <span class="ot">FALSE</span>
  )
<span class="kw">print</span>(random_grid_perf)
## H2O Grid Details
## ================
## 
## Grid ID: rf_random_grid 
## Used hyper parameters: 
##   -  max_depth 
##   -  min_rows 
##   -  mtries 
##   -  sample_rate 
## Number of models: 191 
## Number of failed models: 0 
## 
## Hyper-Parameter Search Summary: ordered by increasing mse
##   max_depth min_rows mtries sample_rate                model_ids                 mse
## 1        25      1.0     40         0.8 rf_random_grid_model_131 5.624310085353142E8
## 2        15      1.0     40         0.8 rf_random_grid_model_180  5.63276905670922E8
## 3        25      1.0     25         0.8 rf_random_grid_model_174 5.660696269742714E8
## 4        20      1.0     25         0.8  rf_random_grid_model_17  5.66146259929908E8
## 5        20      1.0     20         0.8 rf_random_grid_model_144  5.66631854910229E8
## 
## ---
##     max_depth min_rows mtries sample_rate                model_ids                  mse
## 186        20     10.0     40        0.55  rf_random_grid_model_52  8.163555317753098E8
## 187        30     10.0     30         0.8  rf_random_grid_model_50  8.182002205674793E8
## 188        20     10.0     35        0.55  rf_random_grid_model_23  8.195309220382509E8
## 189        30     10.0     35        0.55  rf_random_grid_model_97  8.195309220382509E8
## 190        20     10.0     30       0.632  rf_random_grid_model_44  8.266536241339123E8
## 191        30      7.0     30         0.8 rf_random_grid_model_190 1.3296523023487797E9</code></pre></div>
<p>Once we’ve identifed the best model we can extract it with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Grab the model_id for the top model, chosen by validation error</span>
best_model_id &lt;-<span class="st"> </span>random_grid_perf<span class="op">@</span>model_ids[[<span class="dv">1</span>]]
best_model &lt;-<span class="st"> </span><span class="kw">h2o.getModel</span>(best_model_id)</code></pre></div>
</div>
</div>
<div id="rf-h2o-regression-viz" class="section level4">
<h4><span class="header-section-number">4.4.2.3</span> Visualizing results</h4>
<div id="rf-h2o-regression-vip" class="section level5">
<h5><span class="header-section-number">4.4.2.3.1</span> Variable importance</h5>
<p>Once you’ve identified and selected the optimally tuned model, you can visualize variable importance with <code>h2o.varimp_plot</code>. <code>h2o.varimp_plot</code> computes variable importance <strong><em>“by calculating the relative influence of each variable: whether that variable was selected during splitting in the tree building process and how much the squared error (over all trees) improved as a result.”</em></strong><a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> This is equivalent to the impurity approach used by <code>ranger</code>. The most important variables are relatively similar to those found with the ranger model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.varimp_plot</span>(best_model, <span class="dt">num_of_features =</span> <span class="dv">25</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:h2o-varimp-plot"></span>
<img src="04-random-forest_files/figure-html/h2o-varimp-plot-1.png" alt="Variable importance plot provided by the __h2o__ package." width="672" />
<p class="caption">
Figure 4.6: Variable importance plot provided by the <strong>h2o</strong> package.
</p>
</div>
<p>If you prefer the plotting provided by the <code>vip</code> package, you can also use <code>vip::vip</code> on any <code>h2o</code> model as well.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">vip</span>(best_model, <span class="dt">num_features =</span> <span class="dv">25</span>, <span class="dt">bar =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:h2o-rf-vip"></span>
<img src="04-random-forest_files/figure-html/h2o-rf-vip-1.png" alt="Variable importance plot provided by the __vip__ package." width="672" />
<p class="caption">
Figure 4.7: Variable importance plot provided by the <strong>vip</strong> package.
</p>
</div>
</div>
<div id="rh-h2o-regression-pdp" class="section level5">
<h5><span class="header-section-number">4.4.2.3.2</span> Partial dependence plots</h5>
<p>As with <strong>ranger</strong>, we can also assess PDP plots. <code>h2o</code> provides the <code>h2o.partialPlot</code> function to plot PDPs. Although it does not allow you to plot individual ICE curves, it does plot the standard error of the mean response across all observations along with automatically showing you the values of the predictor variable (by default it selects 20 values but can be adjusted with <code>nbins</code>), mean response, and standard error of the response. The partial dependence plot for <code>Gr_Liv_Area</code> follows a similar non-linear trend as we saw with the <strong>ranger</strong> model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.partialPlot</span>(best_model, <span class="dt">data =</span> train_h2o, <span class="dt">cols =</span> <span class="st">&quot;Gr_Liv_Area&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:h2o-pdp-rf"></span>
<img src="04-random-forest_files/figure-html/h2o-pdp-rf-1.png" alt="__h2o__'s partial dependence plot of the `Gr_Liv_Area` predictor variable based on the optimal __h2o__ model." width="672" />
<p class="caption">
Figure 4.8: <strong>h2o</strong>’s partial dependence plot of the <code>Gr_Liv_Area</code> predictor variable based on the optimal <strong>h2o</strong> model.
</p>
</div>
<pre><code>## PartialDependence: Partial Dependence Plot of model rf_random_grid_model_131 on column &#39;Gr_Liv_Area&#39;
##    Gr_Liv_Area mean_response stddev_response
## 1   334.000000 161930.609931    63443.765820
## 2   613.368421 162062.529779    63315.589233
## 3   892.736842 162452.265339    63060.091227
## 4  1172.105263 167315.601270    61620.417433
## 5  1451.473684 176012.418557    59599.978531
## 6  1730.842105 185785.468561    64362.546404
## 7  2010.210526 195264.075938    71031.464662
## 8  2289.578947 201998.046236    73740.380295
## 9  2568.947368 206241.151641    74596.263303
## 10 2848.315789 209652.185877    75251.557070
## 11 3127.684211 210836.830736    74650.327138
## 12 3407.052632 211658.584116    75789.811261
## 13 3686.421053 211833.145557    76111.081331
## 14 3965.789474 211755.931914    75912.587977
## 15 4245.157895 211461.025415    75172.912270
## 16 4524.526316 211422.033670    75065.495828
## 17 4803.894737 211373.627191    74921.530746
## 18 5083.263158 211373.486977    74921.244177
## 19 5362.631579 211369.474903    74913.694244
## 20 5642.000000 211369.474903    74913.694244</code></pre>
<p>If you prefer getting actual ICE curves, we can use the <code>pdp</code> package. However, since <code>pdp</code> does not have an explicit method for <code>h2o</code> objects we need to create a prediction function and use the <code>pred.fun</code> argument:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># build custom prediction function</span>
pfun &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata) {
  <span class="kw">as.data.frame</span>(<span class="kw">predict</span>(object, <span class="dt">newdata =</span> <span class="kw">as.h2o</span>(newdata)))[[1L]]
}

<span class="co"># compute ICE curves </span>
prod.ice &lt;-<span class="st"> </span><span class="kw">partial</span>(
  best_model, 
  <span class="dt">pred.var =</span> <span class="st">&quot;Gr_Liv_Area&quot;</span>, 
  <span class="dt">train =</span> ames_train,
  <span class="dt">pred.fun =</span> pfun,
  <span class="dt">grid.resolution =</span> <span class="dv">20</span>
)

p1 &lt;-<span class="st"> </span><span class="kw">autoplot</span>(prod.ice, <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Non-centered ICE curves&quot;</span>)
p2 &lt;-<span class="st"> </span><span class="kw">autoplot</span>(prod.ice, <span class="dt">alpha =</span> <span class="fl">0.2</span>, <span class="dt">center =</span> <span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Centered ICE curves&quot;</span>)
gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p1, p2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:h2o-ice"></span>
<img src="04-random-forest_files/figure-html/h2o-ice-1.png" alt="__pdp__'s ICE curves of the `Gr_Liv_Area` predictor variable based on the optimal __h2o__ model." width="768" />
<p class="caption">
Figure 4.9: <strong>pdp</strong>’s ICE curves of the <code>Gr_Liv_Area</code> predictor variable based on the optimal <strong>h2o</strong> model.
</p>
</div>
</div>
</div>
<div id="rf-h2o-regression-predict" class="section level4">
<h4><span class="header-section-number">4.4.2.4</span> Predicting</h4>
<p>Finally, if you are satisfied with your final model we can predict values for an unseen data set a couple different ways. We can also quickly assess the model’s performance on our test set with <code>h2o.performance</code>. We see a similar generalizable error as we saw with the <strong>ranger</strong> model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict new values with base R predict()</span>
<span class="kw">predict</span>(best_model, test_h2o)
##    predict
## 1 129214.6
## 2 155571.0
## 3 224196.0
## 4 250114.6
## 5 359731.0
## 6 362031.2
## 
## [876 rows x 1 column]

<span class="co"># predict new values with h2o.predict()</span>
<span class="kw">h2o.predict</span>(best_model, <span class="dt">newdata =</span> test_h2o)
##    predict
## 1 129214.6
## 2 155571.0
## 3 224196.0
## 4 250114.6
## 5 359731.0
## 6 362031.2
## 
## [876 rows x 1 column]

<span class="co"># assess performance on test data</span>
<span class="kw">h2o.performance</span>(best_model, <span class="dt">newdata =</span> test_h2o)
## H2ORegressionMetrics: drf
## 
## MSE:  661358432
## RMSE:  25716.89
## MAE:  15628.89
## RMSLE:  0.1249999
## Mean Residual Deviance :  661358432</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># shut down h2o</span>
<span class="kw">h2o.shutdown</span>(<span class="dt">prompt =</span> <span class="ot">FALSE</span>)
## [1] TRUE</code></pre></div>
</div>
</div>
</div>
<div id="rf-binary-classification" class="section level2">
<h2><span class="header-section-number">4.5</span> Implementation: Binary Classification</h2>
<p>To illustrate random forests concepts for a binary classification problem we will continue with the employee attrition data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">attrition &lt;-<span class="st"> </span>rsample<span class="op">::</span>attrition <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.ordered, factor, <span class="dt">ordered =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Attrition =</span> <span class="kw">relevel</span>(Attrition, <span class="dt">ref =</span> <span class="st">&quot;Yes&quot;</span>))

<span class="co"># Create training and testing sets</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)
split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(attrition, <span class="dt">prop =</span> .<span class="dv">8</span>, <span class="dt">strata =</span> <span class="st">&quot;Attrition&quot;</span>)
attrit_train &lt;-<span class="st"> </span><span class="kw">training</span>(split)
attrit_test  &lt;-<span class="st"> </span><span class="kw">testing</span>(split)</code></pre></div>
<div class="rmdtip">
<p>
Tree-based algorithms typically perform very well without preprocessing the data (i.e. one-hot encoding, normalizing, standardizing).
</p>
</div>
<div id="ranger-rf-binary-classification" class="section level3">
<h3><span class="header-section-number">4.5.1</span> <code>ranger</code></h3>
<div id="ranger-binary-classification-basic" class="section level4">
<h4><span class="header-section-number">4.5.1.1</span> Basic implementation</h4>
<p>We apply <code>ranger::ranger</code> just as we did in the regression setting. However, note that the default <code>mtry</code> is <span class="math inline">\(\texttt{floor}(\sqrt{\texttt{number of features}})\)</span>, which is a good starting point for classification problems (we changed it to <span class="math inline">\(mtry = \texttt{floor}(\frac{\texttt{number of features}}{3})\)</span> in the regression setting).</p>
<div class="rmdtip">
<p>
As long as your response variable is encoded as a character or factor, <code>ranger</code> will automatically perform a classification random forest model.
</p>
</div>
<p>As the model results show, majority voting across all 500 trees provides an OOB error rate of 13.59%.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform basic random forest model</span>
m1_ranger &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula    =</span> Attrition <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data       =</span> attrit_train, 
  <span class="dt">num.trees  =</span> <span class="dv">500</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose    =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed       =</span> <span class="dv">123</span>
  )

<span class="co"># look at results</span>
m1_ranger
## Ranger result
## 
## Call:
##  ranger(formula = Attrition ~ ., data = attrit_train, num.trees = 500,      respect.unordered.factors = &quot;order&quot;, verbose = FALSE, seed = 123) 
## 
## Type:                             Classification 
## Number of trees:                  500 
## Sample size:                      1177 
## Number of independent variables:  30 
## Mtry:                             5 
## Target node size:                 1 
## Variable importance mode:         none 
## Splitrule:                        gini 
## OOB prediction error:             13.59 %

<span class="co"># look at confusion matrix</span>
m1_ranger<span class="op">$</span>confusion.matrix
##      predicted
## true  Yes  No
##   Yes  36 154
##   No    6 981</code></pre></div>
<div class="rmdtip">
<p>
The default <code>ranger</code> classification model does not provide probability estimates. If you want to predict the probabilities then use <code>probability = TRUE</code>. When using this option, the OOB prediction error changes from misclassification rate to MSE.
</p>
</div>
<p>One of the benefits of tree-based methods is they do not require preprocessing steps such as normalization and standardization of the response and/or predictor variables. However, because these methods do not require these steps does not mean you should not assess their impact. Sometimes normalizing and standardizing the data can improve performance. In the following code we compare a basic random forest probability model with unprocessed features to one with processed features (normalized, standardized, and zero variance features removed).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create validation set</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)
split2 &lt;-<span class="st"> </span><span class="kw">initial_split</span>(attrit_train, <span class="dt">prop =</span> .<span class="dv">8</span>, <span class="dt">strata =</span> <span class="st">&quot;Attrition&quot;</span>)
train_tran &lt;-<span class="st"> </span><span class="kw">training</span>(split2)
validation &lt;-<span class="st"> </span><span class="kw">testing</span>(split2)


<span class="co">#-------------------------Unprocessed variables-------------------------#</span>

<span class="co"># perform basic random forest model on unprocessed data</span>
m1_ranger_unprocessed &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula    =</span> Attrition <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data       =</span> train_tran, 
  <span class="dt">num.trees  =</span> <span class="dv">500</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose    =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed       =</span> <span class="dv">123</span>,
  <span class="dt">probability =</span> <span class="ot">TRUE</span>
  )


<span class="co">#--------------------------Processed variables--------------------------#</span>

features &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">names</span>(attrit_train), <span class="st">&quot;Attrition&quot;</span>)

<span class="co"># preprocess features</span>
feature_process &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">preProcess</span>(
  train_tran[, features],
  <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;BoxCox&quot;</span>, <span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>, <span class="st">&quot;zv&quot;</span>)
)

train_tran &lt;-<span class="st"> </span><span class="kw">predict</span>(feature_process, train_tran)

<span class="co"># perform basic random forest model on processed data</span>
m1_ranger_processed &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula    =</span> Attrition <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data       =</span> train_tran, 
  <span class="dt">num.trees  =</span> <span class="dv">500</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose    =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed       =</span> <span class="dv">123</span>,
  <span class="dt">probability =</span> <span class="ot">TRUE</span>
  )</code></pre></div>
<p>We can now apply each model to the validation set and we see that the feature processing has no impact on our area under the curve.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># apply unpreprocessed model</span>
m1_pred &lt;-<span class="st"> </span><span class="kw">predict</span>(m1_ranger_unprocessed, validation)
roc &lt;-<span class="st"> </span>pROC<span class="op">::</span><span class="kw">roc</span>(validation<span class="op">$</span>Attrition, m1_pred<span class="op">$</span>predictions[, <span class="dv">1</span>])
pROC<span class="op">::</span><span class="kw">auc</span>(roc)
## Area under the curve: 0.8586

<span class="co"># preprocess features</span>
valid_tran &lt;-<span class="st"> </span><span class="kw">predict</span>(feature_process, validation)

<span class="co"># apply preprocessed model</span>
m1_tran_pred &lt;-<span class="st"> </span><span class="kw">predict</span>(m1_ranger_processed, valid_tran)
roc &lt;-<span class="st"> </span>pROC<span class="op">::</span><span class="kw">roc</span>(validation<span class="op">$</span>Attrition, m1_tran_pred<span class="op">$</span>predictions[, <span class="dv">1</span>])
pROC<span class="op">::</span><span class="kw">auc</span>(roc)
## Area under the curve: 0.8591</code></pre></div>
</div>
<div id="ranger-rf-binary-classification-tune" class="section level4">
<h4><span class="header-section-number">4.5.1.2</span> Tuning</h4>
<p>With the <code>ranger</code> function we can tune various hyperparameters mentioned in the general <a href="random-forest.html#rf-tune">tuning</a> section. For example, the following model adjusts:</p>
<ul>
<li><code>num.trees</code>: increase number of trees to 750</li>
<li><code>mtry</code>: increase the number of predictor variables to randomly select at each split to 20</li>
<li><code>min.node.size</code>: increase minimum node size to 3 (default is 1 for classification)</li>
<li><code>sample.fraction</code>: increase training set to 70%</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2_ranger &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> Attrition <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> attrit_train, 
  <span class="dt">num.trees       =</span> <span class="dv">750</span>,
  <span class="dt">mtry            =</span> <span class="dv">20</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">3</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">70</span>
  )

<span class="co"># misclassification rate</span>
m2_ranger<span class="op">$</span>prediction.error
## [1] 0.1393373

<span class="co"># model results</span>
m2_ranger
## Ranger result
## 
## Call:
##  ranger(formula = Attrition ~ ., data = attrit_train, num.trees = 750,      mtry = 20, respect.unordered.factors = &quot;order&quot;, verbose = FALSE,      seed = 123, min.node.size = 3, sample.fraction = 0.7) 
## 
## Type:                             Classification 
## Number of trees:                  750 
## Sample size:                      1177 
## Number of independent variables:  30 
## Mtry:                             20 
## Target node size:                 3 
## Variable importance mode:         none 
## Splitrule:                        gini 
## OOB prediction error:             13.93 %</code></pre></div>
<p>We can continue to adjust these settings individually to identify the optimal combination; however, this become tedious when you want to explore a larger grid search. Similar to the regression setting, to perform a larger grid search across several hyperparameters we need to create a grid and loop through each hyperparameter combination and evaluate the model. First we want to construct our grid of hyperparameters. We’re going to search across 200 different models with varying number of trees, <code>mtry</code>, minimum node size, and sample size. I also vary the split rule, which determines when and how to split into branches.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># hyperparameter grid search</span>
hyper_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(
  <span class="dt">num.trees  =</span> <span class="kw">seq</span>(<span class="dv">250</span>, <span class="dv">500</span>, <span class="dv">750</span>),
  <span class="dt">mtry       =</span> <span class="kw">seq</span>(<span class="dv">5</span>, <span class="dv">25</span>, <span class="dt">by =</span> <span class="dv">5</span>),
  <span class="dt">node_size  =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dt">by =</span> <span class="dv">3</span>),
  <span class="dt">sample_size =</span> <span class="kw">c</span>(.<span class="dv">55</span>, .<span class="dv">632</span>, .<span class="dv">70</span>, .<span class="dv">80</span>, <span class="dv">1</span>),
  <span class="dt">splitrule  =</span> <span class="kw">c</span>(<span class="st">&quot;gini&quot;</span>, <span class="st">&quot;extratrees&quot;</span>),
  <span class="dt">OOB_error  =</span> <span class="dv">0</span>
)

<span class="co"># total number of combinations</span>
<span class="kw">nrow</span>(hyper_grid)
## [1] 200

<span class="co"># hyperparameter grid</span>
<span class="kw">head</span>(hyper_grid)
##   num.trees mtry node_size sample_size splitrule OOB_error
## 1       250    5         1        0.55      gini         0
## 2       250   10         1        0.55      gini         0
## 3       250   15         1        0.55      gini         0
## 4       250   20         1        0.55      gini         0
## 5       250   25         1        0.55      gini         0
## 6       250    5         4        0.55      gini         0</code></pre></div>
<p>We can now loop through each hyperparameter combination. Note that we set the random number generator seed. This allows us to consistently sample the same observations for each sample size and make it more clear the impact that each change makes.</p>
<div class="rmdtip">
<p>
This full grid search took about <strong>90 seconds</strong> to compute.
</p>
</div>
<p>Our OOB classification error ranges between ~0.1308-0.1487. Our top 10 performing models all have classification error rates in the lower 0.13 range. The results show that all the top 10 models use less trees, larger <code>mtry</code> than the default (<span class="math inline">\(\text{floor}\big(\sqrt{\text{number of features}}\big) = 5\)</span>, and a sample size less than 100. However, no definitive patterns are observed with the other hyperparameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(hyper_grid)) {
  
  <span class="co"># train model</span>
  model &lt;-<span class="st"> </span><span class="kw">ranger</span>(
    <span class="dt">formula         =</span> Attrition <span class="op">~</span><span class="st"> </span>., 
    <span class="dt">data            =</span> attrit_train,
    <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
    <span class="dt">seed            =</span> <span class="dv">123</span>,
    <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
    <span class="dt">mtry            =</span> hyper_grid<span class="op">$</span>mtry[i],
    <span class="dt">min.node.size   =</span> hyper_grid<span class="op">$</span>node_size[i],
    <span class="dt">sample.fraction =</span> hyper_grid<span class="op">$</span>sample_size[i],
    <span class="dt">splitrule       =</span> hyper_grid<span class="op">$</span>splitrule[i]
  )
  
  <span class="co"># add OOB error to grid</span>
  hyper_grid<span class="op">$</span>OOB_error[i] &lt;-<span class="st"> </span>model<span class="op">$</span>prediction.error
}

hyper_grid <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">arrange</span>(OOB_error) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>(<span class="dv">10</span>)
##    num.trees mtry node_size sample_size  splitrule OOB_error
## 1        250   25         1       0.800       gini 0.1308411
## 2        250   20         7       0.632       gini 0.1325404
## 3        250   25        10       0.800 extratrees 0.1325404
## 4        250   25         4       0.700       gini 0.1333900
## 5        250   25         7       0.700       gini 0.1333900
## 6        250   20         7       0.550 extratrees 0.1333900
## 7        250   25        10       0.700 extratrees 0.1333900
## 8        250   25         4       0.800 extratrees 0.1333900
## 9        250   25         1       0.700       gini 0.1342396
## 10       250   10         7       1.000       gini 0.1342396</code></pre></div>
<p>The above grid search helps to focus where we can further refine our model tuning. As a next step, we would perform additional grid searches; however, for brevity we will leave this as an exercise for the reader.</p>
</div>
<div id="ranger-rf-binary-classification-viz" class="section level4">
<h4><span class="header-section-number">4.5.1.3</span> Visualizing results</h4>
<div id="ranger-rf-binary-classification-vip" class="section level5">
<h5><span class="header-section-number">4.5.1.3.1</span> Variable importance</h5>
<p>As in the regression setting, once we’ve found our optimal hyperparameter settings we can re-run our model and set the <code>importance</code> argument to “impurity” and/or “permutation”. The following applies both settings so that we can compare and contrast the influential variables each method identifies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3_ranger_impurity &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> Attrition <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> attrit_train, 
  <span class="dt">num.trees       =</span> <span class="dv">250</span>,
  <span class="dt">mtry            =</span> <span class="dv">25</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">1</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">80</span>,
  <span class="dt">importance =</span> <span class="st">&#39;impurity&#39;</span>
  )

m3_ranger_permutation &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> Attrition <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> attrit_train, 
  <span class="dt">num.trees       =</span> <span class="dv">250</span>,
  <span class="dt">mtry            =</span> <span class="dv">25</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">1</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">80</span>,
  <span class="dt">importance =</span> <span class="st">&#39;permutation&#39;</span>
  )</code></pre></div>
<p>Plotting the top 25 influential variables using both variable importance methods results in a common theme among the top 3 variables - <code>MonthlyIncome</code>, <code>Age</code>, and <code>OverTime</code> appear to have strong influence on our results. We also saw <code>OverTime</code> as an influential variable using <a href="glm-binary-classification">regularized regression</a>. Looking at the next dozen important variables, we see similar results across variable importance approaches but just in different order (i.e. <code>TotalWorkingYears</code>, <code>JobRole</code>, <code>NumCompaniesWorked</code>). Some of these were influential variables in the regularized regression models and some were not; suggesting our random forest model is picking up different patterns and logic in our data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p1 &lt;-<span class="st"> </span><span class="kw">vip</span>(m3_ranger_impurity, <span class="dt">num_features =</span> <span class="dv">25</span>, <span class="dt">bar =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Impurity-based variable importance&quot;</span>)
p2 &lt;-<span class="st"> </span><span class="kw">vip</span>(m3_ranger_permutation, <span class="dt">num_features =</span> <span class="dv">25</span>, <span class="dt">bar =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Permutation-based variable importance&quot;</span>)

gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p1, p2, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ranger-binary-classification-vip-plots"></span>
<img src="04-random-forest_files/figure-html/ranger-binary-classification-vip-plots-1.png" alt="Top 25 most important variables based on impurity (left) and permutation (right)." width="960" />
<p class="caption">
Figure 4.10: Top 25 most important variables based on impurity (left) and permutation (right).
</p>
</div>
</div>
<div id="ranger-rf-binary-classification-pdp" class="section level5">
<h5><span class="header-section-number">4.5.1.3.2</span> Partial dependence plots</h5>
<p>After the most relevant variables have been identified, the next step is to attempt to understand how the response variable changes based on these variables. This is important considering random forests allow us to pick up non-linear, non-monotonic relationships. For this we can use partial dependence plots (PDPs) and individual conditional expectation (ICE) curves. However, to generate PDPs and ICE curves we need to run a probability model (<code>probability = TRUE</code>) so that we can extract the class probabilities.</p>
<div class="rmdnote">
<p>
To produce a PDP with binary classification problems, we need to create a custom prediction function that will return a vector of the <strong><em>mean predicted probability</em></strong> for the response class of interest (in this example we want the probabilities for <code>Attrition = “Yes”</code>). We supply this custom prediction function within the <code>pdp::partial</code> function call.
</p>
</div>
<p>Our PDPs illustrate a strong increase in the probability of attrition for employees that work overtime. Also, note that non-linear relationship between the probability of attrition and monthly income and age. The <code>MonthlyIncome</code> plot shows an increase in probability as monthly income reaches $10,000 but then flatlines until employees make about $20,000 per month. Similiarly with age, as employees get older they tend to become more stable; however, this changes after the age of 45 where an increase of age tends to increase the probablity of attrition (recall in Section <a href="regularized-regression.html#glm-h2o-classification-binary-viz">3.5.2.3</a> that we saw how the regularized models assumed a constantly decreasing relationships between <code>Age</code> and the probability of attrition).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># probability model</span>
m3_ranger_prob &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> Attrition <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> attrit_train, 
  <span class="dt">num.trees       =</span> <span class="dv">250</span>,
  <span class="dt">mtry            =</span> <span class="dv">25</span>,
  <span class="dt">respect.unordered.factors =</span> <span class="st">&#39;order&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">1</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">80</span>,
  <span class="dt">probability     =</span> <span class="ot">TRUE</span>,
  <span class="dt">importance      =</span> <span class="st">&#39;impurity&#39;</span>
  )

<span class="co"># custom prediction function</span>
custom_pred &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata) {
  pred &lt;-<span class="st"> </span><span class="kw">predict</span>(object, newdata)
  avg &lt;-<span class="st"> </span><span class="kw">mean</span>(pred<span class="op">$</span>predictions[, <span class="dv">1</span>])
  <span class="kw">return</span>(avg)
}

<span class="co"># partial dependence of OverTime</span>
p1 &lt;-<span class="st"> </span>m3_ranger_prob <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;OverTime&quot;</span>, <span class="dt">pred.fun =</span> custom_pred, <span class="dt">train =</span> attrit_train) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> attrit_train)

<span class="co"># partial dependence of MonthlyIncome</span>
p2 &lt;-<span class="st"> </span>m3_ranger_prob <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;MonthlyIncome&quot;</span>, <span class="dt">pred.fun =</span> custom_pred, <span class="dt">train =</span> attrit_train) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> attrit_train)

<span class="co"># partial dependence of Age</span>
p3 &lt;-<span class="st"> </span>m3_ranger_prob <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Age&quot;</span>, <span class="dt">pred.fun =</span> custom_pred, <span class="dt">train =</span> attrit_train) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> attrit_train)

gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p1, p2, p3, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:rf-ranger-binary-classification-pdp"></span>
<img src="04-random-forest_files/figure-html/rf-ranger-binary-classification-pdp-1.png" alt="Partial dependence plots of our top 3 influential variables. Note the non-linear, non-monotonic relationship our random forest model is picking up for `MonthlyIncome` and `Age`." width="960" />
<p class="caption">
Figure 4.11: Partial dependence plots of our top 3 influential variables. Note the non-linear, non-monotonic relationship our random forest model is picking up for <code>MonthlyIncome</code> and <code>Age</code>.
</p>
</div>
<p>We can extract more insights with centered ICE curves. Although the PDP illustrates an increase in the average probability of attrition for employees who work overtime, the ICE curves illustrate that this is not the case for all employees. A fair amount of the observations actually experience a decrease in probability when they work overtime. This likely suggests an intereaction effect with other variables (we will discuss how to tease out interactions in the <strong><em>Model Interpretability</em></strong> chapter).</p>
<div class="rmdnote">
<p>
To produce ICE curves with binary classification problems, we need to create a custom prediction function that will return a vector of the <strong><em>predicted probabilities</em></strong> for the response class of interest.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># custom prediction function</span>
custom_pred &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata) {
  pred &lt;-<span class="st"> </span><span class="kw">predict</span>(object, newdata)
  avg &lt;-<span class="st"> </span>pred<span class="op">$</span>predictions[, <span class="dv">1</span>]
  <span class="kw">return</span>(avg)
}

<span class="co"># ICE curves for top 3 influential variables</span>
p1 &lt;-<span class="st"> </span>m3_ranger_prob <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;OverTime&quot;</span>, <span class="dt">ice =</span> <span class="ot">TRUE</span>, <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">pred.fun =</span> custom_pred, <span class="dt">train =</span> attrit_train) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> attrit_train, <span class="dt">alpha =</span> <span class="fl">0.2</span>)

p2 &lt;-<span class="st"> </span>m3_ranger_prob <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;MonthlyIncome&quot;</span>, <span class="dt">ice =</span> <span class="ot">TRUE</span>, <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">pred.fun =</span> custom_pred, <span class="dt">train =</span> attrit_train) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> attrit_train, <span class="dt">alpha =</span> <span class="fl">0.2</span>)

p3 &lt;-<span class="st"> </span>m3_ranger_prob <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Age&quot;</span>, <span class="dt">ice =</span> <span class="ot">TRUE</span>, <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">pred.fun =</span> custom_pred, <span class="dt">train =</span> attrit_train) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">rug =</span> <span class="ot">TRUE</span>, <span class="dt">train =</span> attrit_train, <span class="dt">alpha =</span> <span class="fl">0.2</span>)

gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p1, p2, p3, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ranger-binary-classification-ice"></span>
<img src="04-random-forest_files/figure-html/ranger-binary-classification-ice-1.png" alt="Centered ICE curves for our top 3 influential variables." width="960" />
<p class="caption">
Figure 4.12: Centered ICE curves for our top 3 influential variables.
</p>
</div>
</div>
<div id="ranger-rf-binary-classification-roc" class="section level5">
<h5><span class="header-section-number">4.5.1.3.3</span> ROC curve</h5>
<p>As in the regularize regression chapter, we can visualize the ROC curve with the <code>ROCR</code> and <code>pROC</code> packages. Both packages compare the predicted probability output to the actual observed class so we need to use our probability ranger model <code>m3_ranger_prob</code>. The predicted probabilities for our model are accessible at <code>ranger_model$predictions</code> and we want to index for the class of interest.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ROCR)
<span class="kw">library</span>(pROC)

<span class="co"># plot structure</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))

<span class="co"># ROCR plot</span>
<span class="kw">prediction</span>(m3_ranger_prob<span class="op">$</span>predictions[, <span class="dv">1</span>], attrit_train<span class="op">$</span>Attrition) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">performance</span>(<span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>(<span class="dt">main =</span> <span class="st">&quot;ROCR ROC curve&quot;</span>)

<span class="co">#pROC plot</span>
<span class="kw">roc</span>(attrit_train<span class="op">$</span>Attrition, m3_ranger_prob<span class="op">$</span>predictions[, <span class="dv">1</span>]) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>(<span class="dt">main =</span> <span class="st">&quot;pROC ROC curve&quot;</span>, <span class="dt">legacy.axes =</span> <span class="ot">TRUE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ranger-classification-roc"></span>
<img src="04-random-forest_files/figure-html/ranger-classification-roc-1.png" alt="ROC curve for our __ranger__ random forest model based on the training data." width="864" />
<p class="caption">
Figure 4.13: ROC curve for our <strong>ranger</strong> random forest model based on the training data.
</p>
</div>
</div>
</div>
<div id="ranger-rf-binary-classification-predict" class="section level4">
<h4><span class="header-section-number">4.5.1.4</span> Predicting</h4>
<p>Once you have identified your preferred model, you can simply use <code>predict</code> to predict the same model on a new data set. If you use a probability model, the predicted values will be probabilities for each class. If you use a non-probability model, the predicted values will be the class.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict a probability model</span>
pred_probs &lt;-<span class="st"> </span><span class="kw">predict</span>(m3_ranger_prob, attrit_test)
<span class="kw">head</span>(pred_probs<span class="op">$</span>predictions)
##        Yes    No
## [1,] 0.124 0.876
## [2,] 0.472 0.528
## [3,] 0.056 0.944
## [4,] 0.064 0.936
## [5,] 0.296 0.704
## [6,] 0.124 0.876

<span class="co"># predict a non-probability model</span>
pred_class &lt;-<span class="st"> </span><span class="kw">predict</span>(m3_ranger_impurity, attrit_test)
<span class="kw">head</span>(pred_class<span class="op">$</span>predictions)
## [1] No No No No No No
## Levels: Yes No</code></pre></div>
<p>Lastly, to assess various performance metrics on our test data we use <code>caret::confusionMatrix</code>, which provides the majority of the performance measures we are typically concerned with in classification models. If you compare the results to the regularized regression model you will notice that our random forest model does not provide additional predictive performance.</p>
<div class="rmdwarning">
<p>
You need to supply <code>caret::confusionMatrix</code> with the predicted class. Consequently, if you use the probability model which predicts probabilities then you will need perform an extract step that creates a predicted class based on the probabilities (i.e. <code>ifelse(probability &gt;= .5, “Yes”, “No”)</code>).
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(<span class="kw">factor</span>(pred_class<span class="op">$</span>predictions), attrit_test<span class="op">$</span>Attrition, <span class="dt">positive =</span> <span class="st">&quot;Yes&quot;</span>)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Yes  No
##        Yes  13   5
##        No   34 241
##                                           
##                Accuracy : 0.8669          
##                  95% CI : (0.8226, 0.9036)
##     No Information Rate : 0.8396          
##     P-Value [Acc &gt; NIR] : 0.1145          
##                                           
##                   Kappa : 0.3415          
##  Mcnemar&#39;s Test P-Value : 7.34e-06        
##                                           
##             Sensitivity : 0.27660         
##             Specificity : 0.97967         
##          Pos Pred Value : 0.72222         
##          Neg Pred Value : 0.87636         
##              Prevalence : 0.16041         
##          Detection Rate : 0.04437         
##    Detection Prevalence : 0.06143         
##       Balanced Accuracy : 0.62814         
##                                           
##        &#39;Positive&#39; Class : Yes             
## </code></pre></div>
</div>
</div>
<div id="h2o-rf-binary-classification" class="section level3">
<h3><span class="header-section-number">4.5.2</span> <code>h20</code></h3>
<p>To perform a binary classification random forest with <strong>h2o</strong>, we first need to initiate our <strong>h2o</strong> session.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># launch h2o</span>
h2o<span class="op">::</span><span class="kw">h2o.no_progress</span>()
<span class="kw">h2o.init</span>(<span class="dt">max_mem_size =</span> <span class="st">&quot;5g&quot;</span>)
##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         3 seconds 828 milliseconds 
##     H2O cluster timezone:       America/New_York 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.18.0.11 
##     H2O cluster version age:    2 months and 13 days  
##     H2O cluster name:           H2O_started_from_R_bradboehmke_ply740 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   4.39 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.5.1 (2018-07-02)</code></pre></div>
<p>Next, we need to convert our training and test data to <strong>h2o</strong> objects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># convert training data to h2o object</span>
attrit_train_h2o &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(attrit_train)

<span class="co"># convert test data to h2o object</span>
attrit_test_h2o &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(attrit_test)

<span class="co"># set the response column to Attrition</span>
response &lt;-<span class="st"> &quot;Attrition&quot;</span>

<span class="co"># set the predictor names</span>
predictors &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">colnames</span>(attrit_train), <span class="st">&quot;Attrition&quot;</span>)</code></pre></div>
<div id="h2o-rf-binary-classification-basic" class="section level4">
<h4><span class="header-section-number">4.5.2.1</span> Basic implementation</h4>
<p>Similar to our regression problem, we use <code>h2o::h2o.randomForest</code> to perform a random forest model with <strong>h2o</strong>. Most of the default parameter settings in <code>h2o.randomForest</code> do not change between a regression and classification problem. However, <code>mtries</code> (how many predictor variables are randomly selected at each split) defaults to <span class="math inline">\(\texttt{floor}(\sqrt{p})\)</span>.</p>
<div class="rmdtip">
<p>
As long as your response variable is encoded as a character or factor, <code>h2o</code> will apply a binomial or multinomial classification model. Alternatively, you can specify the response distribution with the <code>distribution</code> argument.
</p>
</div>
<p>The following performs a default <code>h2o.randomForest</code> model with 250 trees and a 10 fold cross validation. As the model results show, averaging across all 250 trees provides an OOB <span class="math inline">\(AUC = 0.8\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform basic random forest model</span>
m1_h2o &lt;-<span class="st"> </span><span class="kw">h2o.randomForest</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response,
  <span class="dt">training_frame =</span> attrit_train_h2o, 
  <span class="dt">ntrees =</span> <span class="dv">250</span>,
  <span class="dt">seed =</span> <span class="dv">123</span>, 
  <span class="dt">nfolds =</span> <span class="dv">10</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>
  )

<span class="co"># look at results</span>
<span class="kw">h2o.performance</span>(m1_h2o, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## H2OBinomialMetrics: drf
## ** Reported on cross-validation data. **
## ** 10-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.1076479
## RMSE:  0.3280973
## LogLoss:  0.3600018
## Mean Per-Class Error:  0.2996321
## AUC:  0.795918
## Gini:  0.591836
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No      915  72 0.072948    =72/987
## Yes     100  90 0.526316   =100/190
## Totals 1015 162 0.146134  =172/1177
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold    value idx
## 1                       max f1  0.304000 0.511364  81
## 2                       max f2  0.164000 0.607055 130
## 3                 max f0point5  0.352000 0.579365  65
## 4                 max accuracy  0.356000 0.869159  64
## 5                max precision  0.754667 1.000000   0
## 6                   max recall  0.016000 1.000000 177
## 7              max specificity  0.754667 1.000000   0
## 8             max absolute_mcc  0.352000 0.438268  65
## 9   max min_per_class_accuracy  0.180000 0.727457 124
## 10 max mean_per_class_accuracy  0.220000 0.741097 108
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre></div>
<p>The results above used all 250 trees but to make sure we are providing enough trees to stabilize the OOB error we can include automatic stopping. Also, when dealing with classification problems, if your response variable is significantly imbalanced, you can achieve additional predictive accuracy by over/under sampling. We can over/under sample our classes to achieved balanced class counts by incorporating the <code>balance_classes</code> argument. However, we do not achieve any performance improvement by balancing our attrition classes.</p>
<div class="rmdnote">
<p>
You will, typically, achieve performance improvements by over/under sampling when you binary response variable has a 90/10 or worse class imbalance.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform basic random forest model</span>
m2_h2o &lt;-<span class="st"> </span><span class="kw">h2o.randomForest</span>(
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response,
  <span class="dt">training_frame =</span> attrit_train_h2o, 
  <span class="dt">ntrees =</span> <span class="dv">500</span>,
  <span class="dt">seed =</span> <span class="dv">123</span>,
  <span class="dt">nfolds =</span> <span class="dv">10</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">balance_classes =</span> <span class="ot">TRUE</span>,
  <span class="dt">stopping_metric =</span> <span class="st">&quot;AUC&quot;</span>,  <span class="co"># stopping mechanism</span>
  <span class="dt">stopping_rounds =</span> <span class="dv">10</span>,     <span class="co"># number of rounds</span>
  <span class="dt">stopping_tolerance =</span> <span class="dv">0</span>    <span class="co"># stops after trees add no improvement</span>
  )

<span class="co"># look at results</span>
<span class="kw">h2o.performance</span>(m2_h2o, <span class="dt">xval =</span> <span class="ot">TRUE</span>)
## H2OBinomialMetrics: drf
## ** Reported on cross-validation data. **
## ** 10-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.129077
## RMSE:  0.3592728
## LogLoss:  0.4325378
## Mean Per-Class Error:  0.2804218
## AUC:  0.7969045
## Gini:  0.593809
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##         No Yes    Error       Rate
## No     875 112 0.113475   =112/987
## Yes     85 105 0.447368    =85/190
## Totals 960 217 0.167375  =197/1177
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold    value idx
## 1                       max f1  0.086292 0.515971 143
## 2                       max f2  0.044498 0.602837 239
## 3                 max f0point5  0.135658 0.574205  78
## 4                 max accuracy  0.135658 0.869159  78
## 5                max precision  0.570324 1.000000   0
## 6                   max recall  0.008554 1.000000 383
## 7              max specificity  0.570324 1.000000   0
## 8             max absolute_mcc  0.135658 0.424441  78
## 9   max min_per_class_accuracy  0.052971 0.721378 216
## 10 max mean_per_class_accuracy  0.056358 0.730742 207
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre></div>
</div>
<div id="h2o-rf-multi-classification-tune" class="section level4">
<h4><span class="header-section-number">4.5.2.2</span> Tuning</h4>
<p>As discussed in the regression section of this chapter, <code>h2o.randomForest</code> provides several tunable hyperparameters, for which we can perform a full (aka full cartesian) or stochastic (aka random discrete) grid search across.</p>
<div id="rf-h2o-classification-tune-full" class="section level5">
<h5><span class="header-section-number">4.5.2.2.1</span> Full cartesian grid search</h5>
<p>First, we can try a comprehensive (full cartesian) grid search, which means we will examine every combination of hyperparameter settings that we specify in <code>hyper_grid.h2o</code>. Here, we search across 360 models.</p>
<div class="rmdnote">
<p>
To speed up the grid search I dropped it down to 5-fold cross validation; however, this grid search still took <strong>30 minutes</strong>. As an alternative, you could create a single validation frame (see <code>validation_frame</code> in <code>?h2o.grid</code>) to score against rather than perform <em>k</em>-fold cross validation.
</p>
</div>
<p>The results show a maximum AUC of 1 but don’t get too excited about this. When you over/under sample with <code>balance_classes = TRUE</code>, we are essentially bootstrapping extra samples of the observations with <code>Attrition = Yes</code>. This means our up-sampled observations will have many of the same values across the features. This makes it easier to over exaggerate the predictive performance during our training. A few characteristics we notice from our results suggest that predictive accuracy is maximized when <code>balance_classes = TRUE</code>, <code>max_depth</code> is larger, <code>min_rows</code> is smaller, and <code>sample_rate</code> <span class="math inline">\(&lt; 1\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># hyperparameter grid</span>
hyper_grid.h2o &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">mtries      =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>),
  <span class="dt">max_depth   =</span> <span class="kw">seq</span>(<span class="dv">10</span>, <span class="dv">30</span>, <span class="dt">by =</span> <span class="dv">5</span>),
  <span class="dt">min_rows    =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>),
  <span class="dt">sample_rate =</span> <span class="kw">c</span>(.<span class="dv">632</span>, .<span class="dv">8</span>, .<span class="dv">95</span>),
  <span class="dt">balance_classes =</span> <span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>)
)

<span class="co"># build grid search </span>
grid &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(
  <span class="dt">algorithm =</span> <span class="st">&quot;randomForest&quot;</span>,
  <span class="dt">grid_id =</span> <span class="st">&quot;rf_full_grid&quot;</span>,
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> attrit_train_h2o,
  <span class="dt">hyper_params =</span> hyper_grid.h2o,
  <span class="dt">search_criteria =</span> <span class="kw">list</span>(<span class="dt">strategy =</span> <span class="st">&quot;Cartesian&quot;</span>),
  <span class="dt">ntrees =</span> <span class="dv">500</span>,
  <span class="dt">seed =</span> <span class="dv">123</span>,
  <span class="dt">nfolds =</span> <span class="dv">5</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">stopping_metric =</span> <span class="st">&quot;AUC&quot;</span>,     
  <span class="dt">stopping_rounds =</span> <span class="dv">10</span>,        
  <span class="dt">stopping_tolerance =</span> <span class="dv">0</span> 
  )

<span class="co"># collect the results and sort by our model performance metric of choice</span>
full_grid_perf &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(
  <span class="dt">grid_id =</span> <span class="st">&quot;rf_full_grid&quot;</span>, 
  <span class="dt">sort_by =</span> <span class="st">&quot;auc&quot;</span>, 
  <span class="dt">decreasing =</span> <span class="ot">TRUE</span>
  )
<span class="kw">print</span>(full_grid_perf)
## H2O Grid Details
## ================
## 
## Grid ID: rf_full_grid 
## Used hyper parameters: 
##   -  balance_classes 
##   -  max_depth 
##   -  min_rows 
##   -  mtries 
##   -  sample_rate 
## Number of models: 720 
## Number of failed models: 0 
## 
## Hyper-Parameter Search Summary: ordered by decreasing auc
##   balance_classes max_depth min_rows mtries sample_rate              model_ids auc
## 1            true        25      1.0      2       0.632   rf_full_grid_model_6 1.0
## 2            true        30      1.0     10        0.95 rf_full_grid_model_308 1.0
## 3            true        30      1.0      2       0.632   rf_full_grid_model_8 1.0
## 4            true        30      1.0      5         0.8 rf_full_grid_model_158 1.0
## 5            true        15      1.0     10         0.8 rf_full_grid_model_182 1.0
## 
## ---
##     balance_classes max_depth min_rows mtries sample_rate              model_ids                auc
## 715           false        10      1.0     10        0.95 rf_full_grid_model_301 0.6200193262072915
## 716           false        25      3.0      5        0.95 rf_full_grid_model_287 0.6037350054525626
## 717           false        10      1.0     15        0.95 rf_full_grid_model_331 0.6013023735068234
## 718           false        10      1.0      2        0.95 rf_full_grid_model_241 0.5981035997865863
## 719           false        25      1.0     10        0.95 rf_full_grid_model_307 0.5896310022558814
## 720           false        15      1.0      2        0.95 rf_full_grid_model_243 0.5875399042298484</code></pre></div>
</div>
<div id="rf-h2o-binary-class-tune-random" class="section level5">
<h5><span class="header-section-number">4.5.2.2.2</span> Random discrete grid search</h5>
<p>Rather than perform a full grid search, we could’ve sped up the search process by using the random discrete grid search. The following performs a random search across the same <strong>360</strong> hyperparameter combinations, stopping if none of the last 10 models have managed to have a 0.01% improvement in AUC compared to the best model before that. I cut the grid search off after 1200 seconds (20 minutes) if a final approximately optimal model is not found. Our grid search assessed 171 of the 360 models before stopping and the best model achieved an AUC of 0.812.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># random grid search criteria</span>
search_criteria &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">strategy =</span> <span class="st">&quot;RandomDiscrete&quot;</span>,
  <span class="dt">stopping_metric =</span> <span class="st">&quot;AUC&quot;</span>,
  <span class="dt">stopping_tolerance =</span> <span class="fl">0.0001</span>,
  <span class="dt">stopping_rounds =</span> <span class="dv">10</span>,
  <span class="dt">max_runtime_secs =</span> <span class="dv">60</span><span class="op">*</span><span class="dv">20</span>
  )

<span class="co"># build grid search </span>
random_grid &lt;-<span class="st"> </span><span class="kw">h2o.grid</span>(
  <span class="dt">algorithm =</span> <span class="st">&quot;randomForest&quot;</span>,
  <span class="dt">grid_id =</span> <span class="st">&quot;rf_random_grid&quot;</span>,
  <span class="dt">x =</span> predictors, 
  <span class="dt">y =</span> response, 
  <span class="dt">training_frame =</span> attrit_train_h2o,
  <span class="dt">hyper_params =</span> hyper_grid.h2o,
  <span class="dt">search_criteria =</span> search_criteria,
  <span class="dt">ntrees =</span> <span class="dv">500</span>,
  <span class="dt">seed =</span> <span class="dv">123</span>,
  <span class="dt">nfolds =</span> <span class="dv">5</span>,
  <span class="dt">keep_cross_validation_predictions =</span> <span class="ot">TRUE</span>,
  <span class="dt">stopping_metric =</span> <span class="st">&quot;AUC&quot;</span>,     
  <span class="dt">stopping_rounds =</span> <span class="dv">10</span>,        
  <span class="dt">stopping_tolerance =</span> <span class="dv">0</span>
  )

<span class="co"># collect the results and sort by our model performance metric of choice</span>
random_grid_perf &lt;-<span class="st"> </span><span class="kw">h2o.getGrid</span>(
  <span class="dt">grid_id =</span> <span class="st">&quot;rf_random_grid&quot;</span>, 
  <span class="dt">sort_by =</span> <span class="st">&quot;auc&quot;</span>, 
  <span class="dt">decreasing =</span> <span class="ot">TRUE</span>
  )
<span class="kw">print</span>(random_grid_perf)
## H2O Grid Details
## ================
## 
## Grid ID: rf_random_grid 
## Used hyper parameters: 
##   -  balance_classes 
##   -  max_depth 
##   -  min_rows 
##   -  mtries 
##   -  sample_rate 
## Number of models: 171 
## Number of failed models: 0 
## 
## Hyper-Parameter Search Summary: ordered by decreasing auc
##   balance_classes max_depth min_rows mtries sample_rate                model_ids                auc
## 1           false        30      3.0      2        0.95  rf_random_grid_model_39 0.8121580547112462
## 2           false        10      3.0      2        0.95 rf_random_grid_model_163 0.8115421532554791
## 3           false        20      1.0      5        0.95 rf_random_grid_model_101 0.7974137471337919
## 4           false        30      3.0      2       0.632  rf_random_grid_model_73 0.7966458699941342
## 5           false        15      5.0      2         0.8   rf_random_grid_model_9 0.7965312216711993
## 
## ---
##     balance_classes max_depth min_rows mtries sample_rate                model_ids                auc
## 166            true        20      3.0     15        0.95 rf_random_grid_model_113 0.7474084146536555
## 167            true        30      3.0     15         0.8  rf_random_grid_model_83 0.7469284914413694
## 168            true        10      1.0     15        0.95 rf_random_grid_model_107   0.74409961072895
## 169            true        25      1.0     15        0.95  rf_random_grid_model_63 0.7314962939263051
## 170            true        20      1.0     15        0.95 rf_random_grid_model_142 0.7314962939263051
## 171            true        30      1.0     15        0.95  rf_random_grid_model_61 0.7290326881032368</code></pre></div>
<p>Once we’ve identifed the best set of hyperparameters, we can extract the model. For the remaining examples I will use the optimal model from the random grid search.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Grab the model_id for the top model, chosen by validation error</span>
best_model_id &lt;-<span class="st"> </span>random_grid_perf<span class="op">@</span>model_ids[[<span class="dv">1</span>]]
best_model &lt;-<span class="st"> </span><span class="kw">h2o.getModel</span>(best_model_id)</code></pre></div>
</div>
</div>
<div id="h2o-rf-binary-classification-viz" class="section level4">
<h4><span class="header-section-number">4.5.2.3</span> Visualizing results</h4>
<div id="h2o-rf-binary-classification-vip" class="section level5">
<h5><span class="header-section-number">4.5.2.3.1</span> Variable importance</h5>
<p>Assessing the variable importance, we see similar results as with the <strong>ranger</strong> model with the most influential variables including <code>OverTime</code>, <code>MonthlyIncome</code>, <code>Age</code>, and <code>JobRole</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot top 25 influential variables</span>
<span class="kw">vip</span>(best_model, <span class="dt">num_features =</span> <span class="dv">25</span>, <span class="dt">bar =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="04-random-forest_files/figure-html/rf-h2o-binary-classification-vip-plot-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="h2o-rf-multi-classification-pdp" class="section level5">
<h5><span class="header-section-number">4.5.2.3.2</span> Partial dependence plots</h5>
<p>As with <code>ranger</code>, we can also assess PDPs and ICE curves. The following looks at three of the most influential variables in our model (<code>OverTime</code>, <code>MonthlyIncome</code> and <code>Age</code>). Our centered ICE curves help to illustrate the marginal increasing or decreasing effect on the predicted probability of attrition. In all three plots we see groups of observations going in opposite directions (i.e. at age 35 many employees experience an increase in the probability of attrition while many others a decrease). This indicates interaction effects with other features, which we will explore more in the <strong><em>Model Interpretability</em></strong> chapter.</p>
<div class="rmdnote">
<p>
These plots illustrate similar attributes that we saw in the <strong>ranger</strong> PDP/ICE curve plots.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pfun &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata) {
  <span class="kw">as.data.frame</span>(<span class="kw">predict</span>(object, <span class="dt">newdata =</span> <span class="kw">as.h2o</span>(newdata)))[[3L]]
}

<span class="co"># JobRole partial dependencies</span>
ot.ice &lt;-<span class="st"> </span><span class="kw">partial</span>(
  best_model, 
  <span class="dt">pred.var =</span> <span class="st">&quot;OverTime&quot;</span>, 
  <span class="dt">train =</span> attrit_train,
  <span class="dt">pred.fun =</span> pfun
)

<span class="co"># MonthlyIncome partial dependencies</span>
income.ice &lt;-<span class="st"> </span><span class="kw">partial</span>(
  best_model, 
  <span class="dt">pred.var =</span> <span class="st">&quot;MonthlyIncome&quot;</span>, 
  <span class="dt">train =</span> attrit_train,
  <span class="dt">pred.fun =</span> pfun,
  <span class="dt">grid.resolution =</span> <span class="dv">20</span>
)

<span class="co"># Age partial dependencies</span>
age.ice &lt;-<span class="st"> </span><span class="kw">partial</span>(
  best_model, 
  <span class="dt">pred.var =</span> <span class="st">&quot;Age&quot;</span>, 
  <span class="dt">train =</span> attrit_train,
  <span class="dt">pred.fun =</span> pfun,
  <span class="dt">grid.resolution =</span> <span class="dv">20</span>
)

p1 &lt;-<span class="st"> </span><span class="kw">autoplot</span>(ot.ice, <span class="dt">alpha =</span> <span class="fl">0.1</span>, <span class="dt">center =</span> <span class="ot">TRUE</span>) 
p2 &lt;-<span class="st"> </span><span class="kw">autoplot</span>(income.ice, <span class="dt">alpha =</span> <span class="fl">0.1</span>, <span class="dt">center =</span> <span class="ot">TRUE</span>) 
p3 &lt;-<span class="st"> </span><span class="kw">autoplot</span>(age.ice, <span class="dt">alpha =</span> <span class="fl">0.1</span>, <span class="dt">center =</span> <span class="ot">TRUE</span>)
gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p1, p2, p3, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:rf-h2o-binary-classification-ice"></span>
<img src="04-random-forest_files/figure-html/rf-h2o-binary-classification-ice-1.png" alt="ICE curves for `OverTime`, `MonthlyIncome`, and `Age`." width="960" />
<p class="caption">
Figure 4.14: ICE curves for <code>OverTime</code>, <code>MonthlyIncome</code>, and <code>Age</code>.
</p>
</div>
</div>
<div id="roc-curve-2" class="section level5">
<h5><span class="header-section-number">4.5.2.3.3</span> ROC curve</h5>
<p>Visualizing our ROC curve helps to illustrate our cross-validated AUC of 0.812.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.performance</span>(best_model, <span class="dt">xval =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:rf-h2o-binary-classification-roc"></span>
<img src="04-random-forest_files/figure-html/rf-h2o-binary-classification-roc-1.png" alt="ROC curve for our __ranger__ random forest model based on the training data." width="528" />
<p class="caption">
Figure 4.15: ROC curve for our <strong>ranger</strong> random forest model based on the training data.
</p>
</div>
</div>
</div>
<div id="h2o-rf-binary-classification-predict" class="section level4">
<h4><span class="header-section-number">4.5.2.4</span> Predicting</h4>
<p>Finally, if you are satisfied with your final model we can predict values for an unseen data set a couple different ways. Both <code>predict</code> and <code>h2o.predict</code> will provide the predicted class and the probability of each class. We can also quickly assess the model’s performance on our test set with <code>h2o.performance</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict new values with base R predict()</span>
<span class="kw">predict</span>(best_model, attrit_test_h2o)
##   predict        No        Yes
## 1      No 0.9205128 0.07948718
## 2     Yes 0.6083333 0.39166666
## 3      No 0.9163170 0.08368298
## 4      No 0.8282505 0.17174950
## 5      No 0.7910256 0.20897436
## 6      No 0.9775641 0.02243590
## 
## [293 rows x 3 columns]

<span class="co"># predict new values with h2o.predict()</span>
<span class="kw">h2o.predict</span>(best_model, <span class="dt">newdata =</span> attrit_test_h2o)
##   predict        No        Yes
## 1      No 0.9205128 0.07948718
## 2     Yes 0.6083333 0.39166666
## 3      No 0.9163170 0.08368298
## 4      No 0.8282505 0.17174950
## 5      No 0.7910256 0.20897436
## 6      No 0.9775641 0.02243590
## 
## [293 rows x 3 columns]

<span class="co"># assess performance on test data</span>
<span class="kw">h2o.performance</span>(best_model, <span class="dt">newdata =</span> attrit_test_h2o)
## H2OBinomialMetrics: drf
## 
## MSE:  0.1017999
## RMSE:  0.319061
## LogLoss:  0.3423053
## Mean Per-Class Error:  0.2296316
## AUC:  0.8374849
## Gini:  0.6749697
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##         No Yes    Error     Rate
## No     222  24 0.097561  =24/246
## Yes     17  30 0.361702   =17/47
## Totals 239  54 0.139932  =41/293
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold    value idx
## 1                       max f1  0.254258 0.594059  53
## 2                       max f2  0.160211 0.667752 118
## 3                 max f0point5  0.382280 0.646259  24
## 4                 max accuracy  0.382280 0.883959  24
## 5                max precision  0.739642 1.000000   0
## 6                   max recall  0.022436 1.000000 286
## 7              max specificity  0.739642 1.000000   0
## 8             max absolute_mcc  0.254258 0.511808  53
## 9   max min_per_class_accuracy  0.194833 0.744681  94
## 10 max mean_per_class_accuracy  0.160211 0.777634 118
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.shutdown</span>(<span class="dt">prompt =</span> <span class="ot">FALSE</span>)
## [1] TRUE</code></pre></div>
</div>
</div>
</div>
<div id="rf-multi" class="section level2">
<h2><span class="header-section-number">4.6</span> Implementation: Multinomial Classification</h2>
<p>To illustrate various random forest concepts for a multinomial classification problem we will continue with the mnist data, where the goal is to predict handwritten numbers ranging from 0-9.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># import mnist training and testing data</span>
train &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(<span class="st">&quot;../data/mnist_train.csv&quot;</span>, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)
test &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(<span class="st">&quot;../data/mnist_test.csv&quot;</span>, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div id="rf-ranger-multi" class="section level3">
<h3><span class="header-section-number">4.6.1</span> <code>ranger</code></h3>
<p>To use <strong>ranger</strong> on a multiclassification problem we need our response variable to be encoded as a character or factor. Since our response variable for the mnist data (<code>V785</code>) contains numeric responses (integers ranging from 0-9), we need to convert these to a factor.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># convert response variable to a factor</span>
train &lt;-<span class="st"> </span><span class="kw">mutate</span>(train, <span class="dt">V785 =</span> <span class="kw">factor</span>(V785))
test &lt;-<span class="st"> </span><span class="kw">mutate</span>(test, <span class="dt">V785 =</span> <span class="kw">factor</span>(V785))</code></pre></div>
<div id="ranger-multi-basic" class="section level4">
<h4><span class="header-section-number">4.6.1.1</span> Basic implementation</h4>
<p>Once our response variable is properly encoded as a factor or character, <code>ranger::ranger</code> will automatically apply a random forest model with multinomial terminal nodes without you having to specify. Consequently, the following applies a default random forest model with 500 trees. Since all the predictors in the mnist data set are numeric we do not need to worry about setting the <code>respect.unordered.factors</code> parameter.</p>
<p>As your data set grows in size, random forests can become slow. Parallel processing can speed up the process and, by default, <strong>ranger</strong> will use the number of CPUs available (you can manually set the number of CPUs to use with <code>num.threads</code>). However, even so, on the mnist data the default <strong>ranger</strong> model takes three minutes to train. The results show an OOB error of 2.98%, which is already more accurate than the tuned regularized regression results (see Section <a href="regularized-regression.html#glm-multinomial-classification">3.6</a>).</p>
<div class="rmdnote">
<p>
This basic default model took a little over 3 minutes to train.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform basic random forest model</span>
m1_ranger &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula    =</span> V785 <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data       =</span> train, 
  <span class="dt">num.trees  =</span> <span class="dv">500</span>,
  <span class="dt">verbose    =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed       =</span> <span class="dv">123</span>
  )

<span class="co"># look at results</span>
m1_ranger
## Ranger result
## 
## Call:
##  ranger(formula = V785 ~ ., data = train, num.trees = 500, seed = 123) 
## 
## Type:                             Classification 
## Number of trees:                  500 
## Sample size:                      60000 
## Number of independent variables:  784 
## Mtry:                             28 
## Target node size:                 1 
## Variable importance mode:         none 
## Splitrule:                        gini 
## OOB prediction error:             2.98 %

<span class="co"># look at confusion matrix</span>
m1_ranger<span class="op">$</span>confusion.matrix
##     predicted
## true    0    1    2    3    4    5    6    7    8    9
##    0 5855    1    7    2    3    6   18    0   28    3
##    1    1 6646   36   11    9    4    5   13    9    8
##    2   24    9 5787   23   22    2   14   37   36    4
##    3    9    6   73 5840    1   62    8   44   62   26
##    4    8   11    9    0 5683    0   23   10   12   86
##    5   21    5    8   61    9 5223   41    5   27   21
##    6   20   11    5    1    9   30 5824    0   18    0
##    7    3   22   55    6   28    0    0 6069   10   72
##    8    8   27   30   32   20   36   26    4 5610   58
##    9   21    9   13   65   55   19    4   45   42 5676</code></pre></div>
</div>
<div id="ranger-multi-tune" class="section level4">
<h4><span class="header-section-number">4.6.1.2</span> Tuning</h4>
<p>As in the binary classification section, we will tune the various hyperparameters of the <code>ranger</code> function. The following creates a hyperparameter grid of 160 model combinations with varying number of trees (<code>num_trees</code>), number of variables to possibly split at (<code>mtry</code>), terminal node size (<code>node_size</code>), sample size (<code>sample_size</code>), and the split rule (<code>splitrule</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hyper_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(
  <span class="dt">num_trees   =</span> <span class="kw">c</span>(<span class="dv">250</span>, <span class="dv">500</span>),
  <span class="dt">mtry        =</span> <span class="kw">seq</span>(<span class="dv">15</span>, <span class="dv">35</span>, <span class="dt">by =</span> <span class="dv">5</span>),
  <span class="dt">node_size   =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dt">by =</span> <span class="dv">3</span>),
  <span class="dt">sample_size =</span> <span class="kw">c</span>(.<span class="dv">632</span>, .<span class="dv">80</span>),
  <span class="dt">splitrule   =</span> <span class="kw">c</span>(<span class="st">&quot;gini&quot;</span>, <span class="st">&quot;extratrees&quot;</span>),
  <span class="dt">OOB_error   =</span> <span class="dv">0</span>
)

<span class="kw">nrow</span>(hyper_grid)</code></pre></div>
<p>Our OOB classification error ranges between 0.0302-0.0383. Our top 10 performing models all have classification error rates in the low 0.03 range. The results show that most of the top 10 models use higher <code>mtry</code> values, smaller <code>min.node.size</code>, and include a stochastic nature with <code>sample.fraction</code> <span class="math inline">\(&gt; 1\)</span>. We also see that the two top models use the <code>extratrees</code> split rule versus the <code>gini</code>; however, the improvement is marginal.</p>
<div class="rmdtip">
<p>
This grid search took 5 hours and 38 minutes!
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(hyper_grid)) {
  
  <span class="co"># train model</span>
  model &lt;-<span class="st"> </span><span class="kw">ranger</span>(
    <span class="dt">formula         =</span> V785 <span class="op">~</span><span class="st"> </span>., 
    <span class="dt">data            =</span> train,
    <span class="dt">seed            =</span> <span class="dv">123</span>,
    <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
    <span class="dt">num.trees       =</span> hyper_grid<span class="op">$</span>num_trees[i],
    <span class="dt">mtry            =</span> hyper_grid<span class="op">$</span>mtry[i],
    <span class="dt">min.node.size   =</span> hyper_grid<span class="op">$</span>node_size[i],
    <span class="dt">sample.fraction =</span> hyper_grid<span class="op">$</span>sample_size[i],
    <span class="dt">splitrule       =</span> hyper_grid<span class="op">$</span>splitrule[i]
  )
  
  <span class="co"># add OOB error to grid</span>
  hyper_grid<span class="op">$</span>OOB_error[i] &lt;-<span class="st"> </span>model<span class="op">$</span>prediction.error
}

hyper_grid <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">arrange</span>(OOB_error) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>(<span class="dv">10</span>)
##    num.trees mtry node_size sample_size  splitrule  OOB_error
## 1        250   35         1         0.8 extratrees 0.03021667
## 2        500   35         1         0.8 extratrees 0.03021667
## 3        250   35         1         0.8       gini 0.03046667
## 4        500   35         1         0.8       gini 0.03046667
## 5        250   35         4         0.8       gini 0.03061667
## 6        500   35         4         0.8       gini 0.03061667
## 7        250   30         1         0.8       gini 0.03065000
## 8        500   30         1         0.8       gini 0.03065000
## 9        250   20         1         0.8       gini 0.03078333
## 10       500   20         1         0.8       gini 0.03078333</code></pre></div>
<p>The above grid search helps to focus where we can further refine our model tuning. As a next step, we could perform additional grid searches focusing on additional ranges of these parameters. However, for brevity we leave this as an exercise for the reader.</p>
</div>
<div id="ranger-multi-viz" class="section level4">
<h4><span class="header-section-number">4.6.1.3</span> Visual interpretation</h4>
<div id="variable-importance-ranger-multi-vip" class="section level5">
<h5><span class="header-section-number">4.6.1.3.1</span> Variable importance {ranger-multi-vip}</h5>
<p>As in the regression and binary classification setting, once we’ve found our optimal hyperparameter settings we can re-run our model and set the <code>importance</code> argument to “impurity” and/or “permutation”. The following applies both settings so that we can compare and contrast the influential variables each method identifies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># re-run model with impurity-based variable importance</span>
m3_ranger_impurity &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> V785 <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> train, 
  <span class="dt">num.trees       =</span> <span class="dv">250</span>,
  <span class="dt">mtry            =</span> <span class="dv">35</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">1</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">80</span>,
  <span class="dt">splitrule       =</span> <span class="st">&quot;extratrees&quot;</span>,
  <span class="dt">importance      =</span> <span class="st">&#39;impurity&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>
  )

<span class="co"># re-run model with permutation-based variable importance</span>
m3_ranger_permutation &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> V785 <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> train, 
  <span class="dt">num.trees       =</span> <span class="dv">250</span>,
  <span class="dt">mtry            =</span> <span class="dv">35</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">1</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">80</span>,
  <span class="dt">splitrule       =</span> <span class="st">&quot;extratrees&quot;</span>,
  <span class="dt">importance      =</span> <span class="st">&#39;permutation&#39;</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>
  )</code></pre></div>
<p>In the regularized regression chapter, we saw that 67 predictors were not used because they contained zero variance. For random forests, we can assess how many and which variables were not used for any splits within our random forest model to improve impurtiy. This signals those variables that do not provide any increase in the accuracy within each terminal node. For our <code>m3_ranger_impurity</code> model there are 102 variables not used for any splits. We can do the same with the <code>m3_ranger_permutation</code> model; however, variables with zero importance represent those variables that when scrambled, still do not hurt the performance of our model. We see there are 153 variables that have zero importance for the permutation-based approach.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># how many variables not used for a split</span>
<span class="kw">which</span>(m3_ranger_impurity<span class="op">$</span>variable.importance <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">length</span>()
## [1] 95

<span class="co"># how many variables where randomizing their values does not hurt performance</span>
<span class="kw">which</span>(m3_ranger_permutation<span class="op">$</span>variable.importance <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">length</span>()
## [1] 153</code></pre></div>
<p>Alternatively, to find important variables we can extract the top 10 influential variables as we did in the regression and binary classification problems. Unlike, in the regularized regression chapter, we cannot extract the most influential variables for each class. This is due to how variable importance is calculated differently between the two. However, shortly we will see how to understand the relationship an influential variable and the different classes of our response variable.</p>
<p>Figure <a href="random-forest.html#fig:rf-multi-classification-ranger-top10-vip">4.16</a> illustrates the top 25 influential variables in our random forest model. We see many of the same variables towards the top albeit in differing order (i.e. <code>V379</code>, <code>V351</code>, <code>V462</code>, <code>V407</code>) signaling that these variables appear influential regardless of the importance measure used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p1 &lt;-<span class="st"> </span><span class="kw">vip</span>(m3_ranger_impurity, <span class="dt">num_features =</span> <span class="dv">25</span>, <span class="dt">bar =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Impurity-based variable importance&quot;</span>)
p2 &lt;-<span class="st"> </span><span class="kw">vip</span>(m3_ranger_permutation, <span class="dt">num_features =</span> <span class="dv">25</span>, <span class="dt">bar =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Permutation-based variable importance&quot;</span>)

gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p1, p2, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:rf-multi-classification-ranger-top10-vip"></span>
<img src="04-random-forest_files/figure-html/rf-multi-classification-ranger-top10-vip-1.png" alt="Top 25 most important variables based on impurity (left) and permutation (right)." width="960" />
<p class="caption">
Figure 4.16: Top 25 most important variables based on impurity (left) and permutation (right).
</p>
</div>
</div>
<div id="partial-dependence-plots-ranger-multi-pdp" class="section level5">
<h5><span class="header-section-number">4.6.1.3.2</span> Partial dependence plots {ranger-multi-pdp}</h5>
<p>After the most relevant variables have been identified, we can assess the relationship between these influential predictors and the response variable with PDP plots and ICE curves. As with the binary classification model, to generate PDPs and ICE curves we need to use the probability model (<code>probability = TRUE</code>) so that can extract the class probabilities.</p>
<div class="rmdnote">
<p>
To produce a PDP with multi-classification problems, we need to create a custom prediction function that will return a data frame of the <strong><em>mean predicted probability</em></strong> for each response class. We supply this custom prediction function
</p>
</div>
<p>In this example, we assess the PDP of each response category with variable <code>V379</code>, which ranked first as the most influential variable. We can see those response categories where this variable has a large impact (stronger changes in the predicted value <span class="math inline">\(\hat y\)</span> as <code>V379</code> changes) versus those that are less influnced by this predictor (mostly flat-lined plots).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># probability model</span>
m3_ranger_prob &lt;-<span class="st"> </span><span class="kw">ranger</span>(
  <span class="dt">formula         =</span> V785 <span class="op">~</span><span class="st"> </span>., 
  <span class="dt">data            =</span> train, 
  <span class="dt">num.trees       =</span> <span class="dv">250</span>,
  <span class="dt">mtry            =</span> <span class="dv">35</span>,
  <span class="dt">min.node.size   =</span> <span class="dv">1</span>,
  <span class="dt">sample.fraction =</span> .<span class="dv">80</span>,
  <span class="dt">importance      =</span> <span class="st">&#39;impurity&#39;</span>,
  <span class="dt">probability     =</span> <span class="ot">TRUE</span>,
  <span class="dt">verbose         =</span> <span class="ot">FALSE</span>,
  <span class="dt">seed            =</span> <span class="dv">123</span>,
  )

<span class="co"># custom prediction function</span>
custom_pred &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata) {
  pred &lt;-<span class="st"> </span><span class="kw">predict</span>(object, newdata)<span class="op">$</span>predictions
  avg &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map_df</span>(<span class="kw">as.data.frame</span>(pred), mean)
  <span class="kw">return</span>(avg)
}

<span class="co"># partial dependence of V379</span>
pd &lt;-<span class="st"> </span><span class="kw">partial</span>(m3_ranger_prob, <span class="dt">pred.var =</span> <span class="st">&quot;V379&quot;</span>, <span class="dt">pred.fun =</span> custom_pred, <span class="dt">train =</span> train)
<span class="kw">ggplot</span>(pd, <span class="kw">aes</span>(V379, yhat, <span class="dt">color =</span> <span class="kw">factor</span>(yhat.id))) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>yhat.id, <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">expand_limits</span>(<span class="dt">y =</span> <span class="dv">0</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:rf-ranger-multi-classification-pdp"></span>
<img src="04-random-forest_files/figure-html/rf-ranger-multi-classification-pdp-1.png" alt="Partial dependence plots of our most influential variable (`V379`) across the 10 response levels. This variable appears to be most influential in predicting the number 0, 1, 3, and 7." width="960" />
<p class="caption">
Figure 4.17: Partial dependence plots of our most influential variable (<code>V379</code>) across the 10 response levels. This variable appears to be most influential in predicting the number 0, 1, 3, and 7.
</p>
</div>
</div>
</div>
<div id="ranger-multi-predict" class="section level4">
<h4><span class="header-section-number">4.6.1.4</span> Predicting</h4>
<p>Finally, if you are satisfied with your final model we can predict values for an unseen data set with <code>predict</code>. If using a non-probability model then your predicted outputs will be a vector containing the predicted class for each observation. If using a probability model then your predicted outputs will be the probability of each class. In both cases, the result of <code>predict</code> is a list with the actual predictions contained in <code>object$predictions</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict class as the output</span>
pred_class &lt;-<span class="st"> </span><span class="kw">predict</span>(m3_ranger_impurity, test)
<span class="kw">head</span>(pred_class<span class="op">$</span>predictions)
## [1] 8 3 8 0 1 5
## Levels: 0 1 2 3 4 5 6 7 8 9

<span class="co"># predict probability as the output</span>
pred_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(m3_ranger_prob, test)
pred_prob<span class="op">$</span>predictions[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, ]
##          0     1     2     3     4     5     6     7     8     9
## [1,] 0.000 0.000 0.004 0.000 0.004 0.004 0.000 0.000 0.988 0.000
## [2,] 0.000 0.012 0.000 0.868 0.020 0.024 0.004 0.024 0.008 0.040
## [3,] 0.140 0.000 0.052 0.120 0.004 0.168 0.088 0.000 0.400 0.028
## [4,] 0.912 0.004 0.004 0.000 0.000 0.024 0.040 0.000 0.008 0.008
## [5,] 0.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000</code></pre></div>
<p>Lastly, to assess various performance metrics on our test data we can use <code>caret::confusionMatrix</code>, which provides the majority of the performance measures we are typically concerned with in classification models. We can see that the overall accuracy rate of 0.9702 is significantly higher than our accuracy of <span class="math inline">\(\approx 0.93\)</span> for both regularized regression models. We also see our model is doing a much better job of predicting “2”, “3”, “5”, “8”, and “9” which were all poorly predicted by the regularized regression models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(<span class="kw">factor</span>(pred_class<span class="op">$</span>predictions), <span class="kw">factor</span>(test<span class="op">$</span>V785))
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1    2    3    4    5    6    7    8    9
##          0  969    0    6    0    1    3    7    1    3    6
##          1    0 1123    0    0    0    0    3    4    0    5
##          2    1    2  996    7    2    0    0   20    4    2
##          3    0    4    8  974    0   10    0    1    9    8
##          4    0    0    3    0  955    0    2    1    5    8
##          5    2    1    0   10    0  863    4    0    5    1
##          6    4    3    3    0    6    6  940    0    1    1
##          7    1    0   10   10    1    1    0  983    3    6
##          8    3    1    6    7    2    6    2    2  935    8
##          9    0    1    0    2   15    3    0   16    9  964
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9702          
##                  95% CI : (0.9667, 0.9734)
##     No Information Rate : 0.1135          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9669          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: 0 Class: 1 Class: 2 Class: 3 Class: 4 Class: 5
## Sensitivity            0.9888   0.9894   0.9651   0.9644   0.9725   0.9675
## Specificity            0.9970   0.9986   0.9958   0.9956   0.9979   0.9975
## Pos Pred Value         0.9729   0.9894   0.9632   0.9606   0.9805   0.9740
## Neg Pred Value         0.9988   0.9986   0.9960   0.9960   0.9970   0.9968
## Prevalence             0.0980   0.1135   0.1032   0.1010   0.0982   0.0892
## Detection Rate         0.0969   0.1123   0.0996   0.0974   0.0955   0.0863
## Detection Prevalence   0.0996   0.1135   0.1034   0.1014   0.0974   0.0886
## Balanced Accuracy      0.9929   0.9940   0.9804   0.9800   0.9852   0.9825
##                      Class: 6 Class: 7 Class: 8 Class: 9
## Sensitivity            0.9812   0.9562   0.9600   0.9554
## Specificity            0.9973   0.9964   0.9959   0.9949
## Pos Pred Value         0.9751   0.9685   0.9619   0.9545
## Neg Pred Value         0.9980   0.9950   0.9957   0.9950
## Prevalence             0.0958   0.1028   0.0974   0.1009
## Detection Rate         0.0940   0.0983   0.0935   0.0964
## Detection Prevalence   0.0964   0.1015   0.0972   0.1010
## Balanced Accuracy      0.9893   0.9763   0.9779   0.9751</code></pre></div>
</div>
</div>
<div id="rf-h2o-multi" class="section level3">
<h3><span class="header-section-number">4.6.2</span> <code>h2o</code></h3>
<div id="rf-h2o-multi-basic" class="section level4">
<h4><span class="header-section-number">4.6.2.1</span> Basic implementation</h4>
</div>
<div id="rf-h2o-multi-tune" class="section level4">
<h4><span class="header-section-number">4.6.2.2</span> Tuning</h4>
</div>
<div id="rf-h2o-multi-viz" class="section level4">
<h4><span class="header-section-number">4.6.2.3</span> Visual interpretation</h4>
</div>
<div id="rf-h2o-multi-predict" class="section level4">
<h4><span class="header-section-number">4.6.2.4</span> Predicting</h4>
</div>
</div>
</div>
<div id="rf-learn" class="section level2">
<h2><span class="header-section-number">4.7</span> Learning More</h2>
<p>Random forests provide a very powerful out-of-the-box algorithm that often has great predictive accuracy. Because of their more simplistic tuning nature and the fact that they require very little, if any, feature pre-processing they are often one of the first go-to algorithms when facing a predictive modeling problem. To learn more I would start with the following resources listed in order of complexity:</p>
<ul>
<li><a href="https://www.amazon.com/Practical-Machine-Learning-H2O-Techniques-ebook/dp/B01MQST5Y5">Practical Machine Learning with H2O</a></li>
<li><a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning</a></li>
<li><a href="http://appliedpredictivemodeling.com/">Applied Predictive Modeling</a></li>
<li><a href="https://www.amazon.com/Computer-Age-Statistical-Inference-Mathematical/dp/1107149894">Computer Age Statistical Inference</a></li>
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a></li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-breiman2001random">
<p>Breiman, Leo. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1). Springer: 5–32.</p>
</div>
<div id="ref-R-ranger">
<p>Wright, Marvin N., and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” <em>Journal of Statistical Software</em> 77 (1): 1–17. doi:<a href="https://doi.org/10.18637/jss.v077.i01">10.18637/jss.v077.i01</a>.</p>
</div>
<div id="ref-harrison1978hedonic">
<p>Harrison Jr, David, and Daniel L Rubinfeld. 1978. “Hedonic Housing Prices and the Demand for Clean Air.” <em>Journal of Environmental Economics and Management</em> 5 (1). Elsevier: 81–102.</p>
</div>
<div id="ref-esl">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2001. <em>The Elements of Statistical Learning</em>. Vol. 1. 10. Springer series in statistics New York, NY, USA:</p>
</div>
<div id="ref-goldstein2015peeking">
<p>Goldstein, Alex, Adam Kapelner, Justin Bleich, and Emil Pitkin. 2015. “Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation.” <em>Journal of Computational and Graphical Statistics</em> 24 (1). Taylor &amp; Francis: 44–65.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>See the Random Forest section in the <a href="https://CRAN.R-project.org/view=MachineLearning">Machine Learning Task View</a> on CRAN and Erin LeDell’s <a href="https://koalaverse.github.io/machine-learning-in-R/random-forest.html#random-forest-software-in-r">useR! Machine Learning Tutorial</a> for a non-comprehensive list.<a href="random-forest.html#fnref3">↩</a></p></li>
<li id="fn4"><p>The features highlighted for each package were originally identified by Erin LeDell in her <a href="https://github.com/ledell/useR-machine-learning-tutorial">useR! 2016 tutorial</a>.<a href="random-forest.html#fnref4">↩</a></p></li>
<li id="fn5"><p>H2O documentation <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html">link</a><a href="random-forest.html#fnref5">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regularized-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-random-forest.rmd",
"text": "Edit"
},
"download": ["hands-on-machine-learning-with-R.pdf", "hands-on-machine-learning-with-R.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
