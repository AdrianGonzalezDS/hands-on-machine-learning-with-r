[
["index.html", "Hands-on Machine Learning with R Preface Who should read this Why R Structure of the book Conventions used in this book Additional resources Feedback Acknowledgments Software information", " Hands-on Machine Learning with R 2018-07-04 Preface Welcome to Hands-on Machine Learning with R. This book provides hands-on modules for many of the most common machine learning methods to include: Generalized low rank models Clustering algorithms Autoencoders Regularized models Random forests Gradient boosting machines Deep neural networks Stacking / super learner and more! You will learn how to build and tune these various models with R packages that have been tested and approved due to their ability to scale well. However, my motivation in almost every case is to describe the techniques in a way that helps develop intuition for its strengths and weaknesses. For the most part, I minimize mathematical complexity when possible but also provide resources to get deeper into the details if desired. Who should read this I intend this work to be a practitioner’s guide to the machine learning process and a place where one can come to learn about the approach and to gain intuition about the many commonly used, modern, and powerful methods accepted in the machine learning community. If you are familiar with the analytic methodologies, this book may still serve as a reference for how to work with the various R packages for implementation. While an abundance of videos, blog posts, and tutorials exist online, I’ve long been frustrated by the lack of consistency, completeness, and bias towards singular packages for implementation. This is what inspired this book. This book is not meant to be an introduction to R or to programming in general; as I assume the reader has familiarity with the R language to include defining functions, managing R objects, controlling the flow of a program, and other basic tasks. If not, I would refer you to R for Data Science (Wickham and Grolemund 2016) to learn the fundamentals of data science with R such as importing, cleaning, transforming, visualizing, and exploring your data. For those looking to advance their R programming skills and knowledge of the languge, I would refer you to Advanced R (Wickham 2014). Instead, this book is meant to help R users learn to use the machine learning stack within R, which includes using various R packages such as glmnet, h20, ranger, xgboost, lime, and others to effectively model and gain insight from your data. The book favors a hands-on approach, growing an intuitive understanding of machine learning through concrete examples and just a little bit of theory. While you can read this book without opening R, I highly recommend you experiment with the code examples provided throughout. Why R R has emerged over the last couple decades as a first-class tool for scientific computing tasks, and has been a consistent leader in implementing statistical methodologies for analyzing data. The usefulness of R for data science stems from the large, active, and growing ecosystem of third-party packages: tidyverse for common data analysis activities; h2o, ranger, xgboost, and others for fast and scalable machine learning; lime, pdp, DALEX, and others for machine learning interpretability; and many more tools will be mentioned throughout the pages that follow. Structure of the book Each chapter of this book focuses on a particular part of the machine learning process along with various packages to perform that process. TBD… Conventions used in this book The following typographical conventions are used in this book: strong italic: indicates new terms, bold: indicates package &amp; file names, inline code: indicates commands or other text that could be typed literally by the user, code chunk: indicates commands or other text that could be typed literally by the user 1 + 2 ## [1] 3 In addition to the general text used throughout, you will notice the following code chunks with images, which signify: Signifies a tip or suggestion Signifies a general note Signifies a warning or caution Additional resources There are many great resources available to learn about machine learning. At the end of each chapter I provide a Learn More section that lists resources that I have found extremely useful for digging deeper into the methodology and applying with code. Feedback Reader comments are greatly appreciated. To report errors or bugs please post an issue at https://github.com/bradleyboehmke/hands-on-machine-learning-with-r/issues. Acknowledgments TBD Software information An online version of this book is available at https://bradleyboehmke.github.io/hands-on-machine-learning-with-r/. The source of the book is available at https://github.com/bradleyboehmke/hands-on-machine-learning-with-r. The book is powered by https://bookdown.org which makes it easy to turn R markdown files into HTML, PDF, and EPUB. This book was built with the following packages and R version. All code was executed on 2013 MacBook Pro with a 2.4 GHz Intel Core i5 processor, 8 GB of memory, 1600MHz speed, and double data rate synchronous dynamic random access memory (DDR3). # packages used pkgs &lt;- c( &quot;AmesHousing&quot;, &quot;h2o&quot;, &quot;rsample&quot; ) # package &amp; session info devtools::session_info(pkgs) #&gt; Session info ------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.5.0 (2018-04-23) #&gt; system x86_64, darwin15.6.0 #&gt; ui X11 #&gt; language (EN) #&gt; collate en_US.UTF-8 #&gt; tz America/New_York #&gt; date 2018-07-04 #&gt; Packages ----------------------------------------------------------------- #&gt; package * version date source #&gt; abind 1.4-5 2016-07-21 CRAN (R 3.5.0) #&gt; AmesHousing 0.0.3 2017-12-17 CRAN (R 3.5.0) #&gt; assertthat 0.2.0 2017-04-11 CRAN (R 3.5.0) #&gt; BH 1.66.0-1 2018-02-13 CRAN (R 3.5.0) #&gt; bindr 0.1.1 2018-03-13 CRAN (R 3.5.0) #&gt; bindrcpp 0.2.2 2018-03-29 CRAN (R 3.5.0) #&gt; bitops 1.0-6 2013-08-17 CRAN (R 3.5.0) #&gt; broom 0.4.4 2018-03-29 CRAN (R 3.5.0) #&gt; class 7.3-14 2015-08-30 CRAN (R 3.5.0) #&gt; cli 1.0.0 2017-11-05 CRAN (R 3.5.0) #&gt; compiler 3.5.0 2018-04-24 local #&gt; crayon 1.3.4 2017-09-16 CRAN (R 3.5.0) #&gt; CVST 0.2-2 2018-05-26 CRAN (R 3.5.0) #&gt; ddalpha 1.3.3 2018-04-30 CRAN (R 3.5.0) #&gt; DEoptimR 1.0-8 2016-11-19 CRAN (R 3.5.0) #&gt; dimRed 0.1.0 2017-05-04 CRAN (R 3.5.0) #&gt; dplyr 0.7.5 2018-05-19 CRAN (R 3.5.0) #&gt; DRR 0.0.3 2018-01-06 CRAN (R 3.5.0) #&gt; foreign 0.8-70 2017-11-28 CRAN (R 3.5.0) #&gt; geometry 0.3-6 2015-09-09 CRAN (R 3.5.0) #&gt; glue 1.2.0 2017-10-29 CRAN (R 3.5.0) #&gt; gower 0.1.2 2017-02-23 CRAN (R 3.5.0) #&gt; graphics * 3.5.0 2018-04-24 local #&gt; grDevices * 3.5.0 2018-04-24 local #&gt; grid 3.5.0 2018-04-24 local #&gt; h2o 3.18.0.11 2018-05-24 CRAN (R 3.5.0) #&gt; ipred 0.9-6 2017-03-01 CRAN (R 3.5.0) #&gt; jsonlite 1.5 2017-06-01 CRAN (R 3.5.0) #&gt; kernlab 0.9-26 2018-04-30 CRAN (R 3.5.0) #&gt; KernSmooth 2.23-15 2015-06-29 CRAN (R 3.5.0) #&gt; lattice 0.20-35 2017-03-25 CRAN (R 3.5.0) #&gt; lava 1.6.1 2018-03-28 CRAN (R 3.5.0) #&gt; lubridate 1.7.4 2018-04-11 CRAN (R 3.5.0) #&gt; magic 1.5-8 2018-01-26 CRAN (R 3.5.0) #&gt; magrittr 1.5 2014-11-22 CRAN (R 3.5.0) #&gt; MASS 7.3-49 2018-02-23 CRAN (R 3.5.0) #&gt; Matrix 1.2-14 2018-04-13 CRAN (R 3.5.0) #&gt; methods * 3.5.0 2018-04-24 local #&gt; mnormt 1.5-5 2016-10-15 CRAN (R 3.5.0) #&gt; nlme 3.1-137 2018-04-07 CRAN (R 3.5.0) #&gt; nnet 7.3-12 2016-02-02 CRAN (R 3.5.0) #&gt; numDeriv 2016.8-1 2016-08-27 CRAN (R 3.5.0) #&gt; parallel 3.5.0 2018-04-24 local #&gt; pillar 1.2.3 2018-05-25 CRAN (R 3.5.0) #&gt; pkgconfig 2.0.1 2017-03-21 CRAN (R 3.5.0) #&gt; plogr 0.2.0 2018-03-25 CRAN (R 3.5.0) #&gt; plyr 1.8.4 2016-06-08 CRAN (R 3.5.0) #&gt; prodlim 2018.04.18 2018-04-18 CRAN (R 3.5.0) #&gt; psych 1.8.4 2018-05-06 CRAN (R 3.5.0) #&gt; purrr 0.2.5 2018-05-29 CRAN (R 3.5.0) #&gt; R6 2.2.2 2017-06-17 CRAN (R 3.5.0) #&gt; Rcpp 0.12.17 2018-05-18 CRAN (R 3.5.0) #&gt; RcppRoll 0.2.2 2015-04-05 CRAN (R 3.5.0) #&gt; RCurl 1.95-4.10 2018-01-04 CRAN (R 3.5.0) #&gt; recipes 0.1.2 2018-01-11 CRAN (R 3.5.0) #&gt; reshape2 1.4.3 2017-12-11 CRAN (R 3.5.0) #&gt; rlang 0.2.1 2018-05-30 CRAN (R 3.5.0) #&gt; robustbase 0.93-0 2018-04-24 CRAN (R 3.5.0) #&gt; rpart 4.1-13 2018-02-23 CRAN (R 3.5.0) #&gt; rsample 0.0.2 2017-11-12 CRAN (R 3.5.0) #&gt; sfsmisc 1.1-2 2018-03-05 CRAN (R 3.5.0) #&gt; splines 3.5.0 2018-04-24 local #&gt; SQUAREM 2017.10-1 2017-10-07 CRAN (R 3.5.0) #&gt; stats * 3.5.0 2018-04-24 local #&gt; stringi 1.2.2 2018-05-02 CRAN (R 3.5.0) #&gt; stringr 1.3.1 2018-05-10 CRAN (R 3.5.0) #&gt; survival 2.41-3 2017-04-04 CRAN (R 3.5.0) #&gt; tibble 1.4.2 2018-01-22 CRAN (R 3.5.0) #&gt; tidyr 0.8.1 2018-05-18 CRAN (R 3.5.0) #&gt; tidyselect 0.2.4 2018-02-26 CRAN (R 3.5.0) #&gt; timeDate 3043.102 2018-02-21 CRAN (R 3.5.0) #&gt; tools 3.5.0 2018-04-24 local #&gt; utf8 1.1.4 2018-05-24 CRAN (R 3.5.0) #&gt; utils * 3.5.0 2018-04-24 local References "],
["introduction.html", "Chapter 1 Introduction 1.1 Supervised Learning 1.2 Unsupervised Learning 1.3 Machine learning interpretability 1.4 The data sets", " Chapter 1 Introduction Machine learning continues to grow in importance for many organizations across nearly all domains. Examples include: predicting the likelihood of a patient returning to the hospital (readmission) within 30 days of discharge, segmenting customers based on common attributes or purchasing behavior for target marketing, predicting coupon redemption rates for a given marketing campaign, predicting customer churn so an organization can perform preventative intervention, and many more! In essence, these tasks all seek to learn from data. To address each scenario, we use a given set of features to train an algorithm and extract insights. These algorithms, or learners, can be classified according to the amount and type of supervision provided during training. The two main groups this book focuses on includes: supervised learners that are used to construct predictive models, and unsupervised learners that are used to build descriptive models. Which type you will need to use depends on the learning task you hope to accomplish. 1.1 Supervised Learning A predictive model is used for tasks that involve the prediction of a given output using other variables and their values (features) in the data set. Or as stated by Kuhn and Johnson (2013), predictive modeling is _“the process of developing a mathematical tool or model that generates an accurate prediction_ (p. 2). The learning algorithm in a predictive attempts to discover and model the relationship among the target response (the variable being predicted) and the other features (aka predictor variables). Examples of predictive modeling include: using customer attributes to predict the probability of the customer churning in the next 6 weeks, using home attributes to predict the sales price, using employee attributes to predict the likelihood of attrition, using patient attributes and symptoms to predict the risk of readmission, using production attributes to predict time to market. Each of these examples have a defined learning task. They each inted to use attributes \\(X\\) to predict an outcome measurement \\(Y\\). Throughout this text I will use various terms interchangeably for: \\(X\\): “predictor variables”, “independent variables”, “attributes”, “features”, “predictors” \\(Y\\): “target variable”, “dependent variable”, “response”, “outcome measurement” The predictive modeling examples above describe what is known as supervised learning. The supervision refers to the fact that the target values provide a supervisory role, which indicates to the learner the task it needs to learn. Specifically, given a set of data, the learning algorithm attempts to optimize a function (the algorithmic steps) to find the combination of feature values that results in a predicted value that is as close to the actual target output as possible. In supervised learning, the training data you feed to the algorithm includes the desired solutions. Consequently, the solutions can be used to help supervise the training process to find the optimal algorithm parameters. Supervised learning problems revolve around two primary themes: regression and classification. 1.1.1 Regression problems When the objective of our supervised learning is to predict a numeric outcome, we refer to this as a regression problem (not to be confused with linear regression modeling). Regression problems revolve around predicting output that falls on a continuous numeric spectrum. In the examples above predicting home sales prices and time to market reflect a regression problem because the output is numeric and continuous. This means, given the combination of predictor values, the response value could fall anywhere along the continuous spectrum. The following illustrates average home sales prices as a function of two home features: year built and total square footage. Depending on the combination of these two features, the expected home sales price could fall anywhere along the plane. Figure 1.1: Average home sales price as a function of year built and total square footage. 1.1.2 Classification problems When the objective of our supervised learning is to predict a categorical response, we refer to this as a classification problem. Classification problems most commonly revolve around predicting a binary or multinomial response measure such as: did a customer redeem a coupon (yes/no, 1/0), did a customer churn (yes/no, 1/0), did a customer click on our online ad (yes/no, 1/0), classifying customer reviews: binary: positive vs negative multinomial: extremely negative to extremely positive on a 0-5 Likert scale However, when we apply machine learning models for classification problems, rather than predict a particular class (i.e. “yes” or “no”), we often predict the probability of a particular class (i.e. yes: .65, no: .35). Then the class with the highest probability becomes the predicted class. Consequently, even though we are performing a classification problem, we are still predicting a numeric output (probability). However, the essence of the problem still makes is a classification problem. 1.1.3 Algorithm Comparison Guide TODO: keep this here or move reference guide to back??? Although there are machine learning algorithms that can be applied to regression problems but not classification and vice versa, the supervised learning algorithms I cover in this both can be applied to both. These algorithms have become the most popular machine learning applications in recent years. Although the chapters that follow will go into detail on each algorithm, the following provides a quick reference guide that compares and contrasts some of their features. Moreover, I provide recommended base learner packages that I have found to scale well with typical rectangular data analyzed by organizations. Characteristics Regularized GLM Random Forest Gradient Boosting Machine Deep Learning Allows n &lt; p Provides automatic feature selection Handles missing values No feature pre-processing required Robust to outliers Easy to tune Computational speed Predictive power Preferred regression base learner glmnet h2o.glm ranger h2o.randomForest xgboost h2o.gbm keras h2o.deeplearning Preferred classifciation base learner glmnet h2o.glm ranger h2o.randomForest xgboost h2o.gbm keras h2o.deeplearning 1.2 Unsupervised Learning Unsupervised learning, in contrast to supervised learning, includes a set of statistical tools to better understand and describe your data but performs the analysis without a target variable. In essence, unsupervised learning is concerned with identifying groups in a data set. The groups may be defined by the rows (i.e., clustering) or the columns (i.e., dimension reduction); however, the motive in each case is quite different. The goal of clustering is to segment observations into similar groups based on the observed variables. For example, to divide consumers into different homogeneous groups, a process known as market segmentation. In dimension reduction, we are often concerned with reducing the number of variables in a data set. For example, classical regression models break down in the presence of highly correlated features. Dimension reduction techniques provide a method to reduce the feature set to a potentially smaller set of uncorrelated variables. These variables are often used as the input variables to downstream supervised models like. Unsupervised learning is often performed as part of an exploratory data analysis. However, the exercise tends to be more subjective, and there is no simple goal for the analysis, such as prediction of a response. Furthermore, it can be hard to assess the quality of results obtained from unsupervised learning methods. The reason for this is simple. If we fit a predictive model using a supervised learning technique (i.e. linear regression), then it is possible to check our work by seeing how well our model predicts the response Y on observations not used in fitting the model. However, in unsupervised learning, there is no way to check our work because we don’t know the true answer—the problem is unsupervised. However, the importance of unsupervised learning should not be overlooked and techniques for unsupervised learning are used in organizations to: Divide consumers into different homogeneous groups so that tailored marketing strategies can be developed and deployed for each segment. Identify groups of online shoppers with similar browsing and purchase histories, as well as items that are of particular interest to the shoppers within each group. Then an individual shopper can be preferentially shown the items in which he or she is particularly likely to be interested, based on the purchase histories of similar shoppers. Identify products that have similar purchasing behavior so that managers can manage them as product groups. These questions, and many more, can be addressed with unsupervised learning. Moreover, often the results of an unsupervised model can be used as inputs to downstream supervised learning models. 1.2.1 Algorithm Decision Guide TBD 1.3 Machine learning interpretability In his seminal 2001 paper, Leo Breiman popularized the phrase: “the multiplicity of good models.” The phrase means that for the same set of input variables and prediction targets, complex machine learning algorithms can produce multiple accurate models with very similar, but not the exact same, internal architectures. Figure 1.2 is a depiction of a non-convex error surface that is representative of the error function for a machine learning algorithm with two inputs — say, a customer’s income and a customer’s age, and an output, such as the same customer’s probability of redeeming a coupon. This non-convex error surface with no obvious global minimum implies there are many different ways complex machine learning algorithms could learn to weigh a customer’s income and age to make a good decision about if they are likely to redeem a coupon. Each of these different weightings would create a different function for making coupon redemption (and therefore marketing) decisions, and each of these different functions would have different explanations. Figure 1.2: Non-convex error surface with many local minimas. All of this is an obstacle to data scientists. On one hand, different models can have widely different predictions based on the same feature set. Even models built from the same algorithm but with different hyperparameters can lead to different results. Consequently, practitioners should understand how different implementations of algorithms differ, which can cause variance in their results (i.e. a default xgboost model can produce very different results from a default gbm model, even though they both implement gradient boosting machines). Alternatively, data scientists can experience very similar predictions from different models based on the same feature set. However, these models will have very different logic and structure leading to different interpretations. Consequently, practitioners should understand how to interpret different types of models. This book will provide you with a fundamental understanding to compare and contrast models and even package implementations of similiar algorithms. Several machine learning interpretability techniques will be demonstrated to help you understand what is driving model and prediction performance. This will allow you to be more effective and efficient in applying and understanding mutliple good models. 1.4 The data sets The XX data sets chosen for this book allow us to illustrate the different features of our machine learning algorithms. They are all freely available and include: Property sales information as described in De Cock (2011). problem type: supervised regression response variable: sale price (i.e. $195,000, $215,000) features: 81 observations: 2,930 objective: use property attributes to predict the sale price of a home access: provided by the AmesHousing package more details: See ?AmesHousing::ames_raw # access data ames &lt;- AmesHousing::ames_raw # initial dimension dim(ames) ## [1] 2930 82 # response variable head(ames$SalePrice) ## [1] 215000 105000 172000 244000 189900 195500 Employee attrition information originally provided by IBM Watson Analytics Lab. problem type: supervised binomial classification response variable: Attrition (i.e. “Yes”, “No”) features: 30 observations: 1,470 objective: use employee attributes to predict if they will attrit (leave the company) access: provided by the rsample package more details: See ?rsample::attrition # access data attrition &lt;- rsample::attrition # initial dimension dim(attrition) ## [1] 1470 31 # response variable head(attrition$Attrition) ## [1] Yes No Yes No No No ## Levels: No Yes Image information for handwritten numbers originally presented to AT&amp;T Bell Lab’s to help build automatic mail-sorting machines for the USPS. Has been used since early 1990s to compare machine learning performance on pattern recognition (i.e. LeCun et al. (1990); LeCun et al. (1998); Cireşan, Meier, and Schmidhuber (2012)). Problem type: supervised multinomial classification response variable: V785 (i.e. numbers to predict: 0, 1, …, 9) features: 784 observations: 60,000 (train) / 10,000 (test) objective: use attributes about the “darkness” of each of the 784 pixels in images of handwritten numbers to predict if the number is 0, 1, …, or 9. access: see the code chunk that follows for download instructions more details: See online MNIST documentation # load training data https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz train &lt;- data.table::fread(&quot;../data/mnist_train.csv&quot;, data.table = FALSE) # load test data https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/test.csv.gz test &lt;- data.table::fread(&quot;../data/mnist_test.csv&quot;, data.table = FALSE) # initial dimension dim(train) ## [1] 60000 785 # response variable head(train$V785) ## [1] 2 3 0 0 2 7 TODO: get unsupervised data sets for clustering and dimension reduction examples References "],
["references.html", "References", " References "]
]
